import React, { useState, useRef, useEffect } from 'react';
import { appWindow, LogicalPosition, LogicalSize } from '@tauri-apps/api/window';
import { invoke } from '@tauri-apps/api/tauri';
import { listen } from '@tauri-apps/api/event';
import './MacOSVoiceInput.css';

interface ActiveAppInfo {
  name: string;
  icon?: string;
  bundleId?: string;
}

type InputState = 'idle' | 'listening' | 'processing' | 'injecting';

const MacOSVoiceInput: React.FC = () => {
  const [state, setState] = useState<InputState>('idle');
  const [transcribedText, setTranscribedText] = useState('');
  const [activeApp, setActiveApp] = useState<ActiveAppInfo>({ name: 'æœªçŸ¥åº”ç”¨' });
  const [audioLevel, setAudioLevel] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [hasAudioInput, setHasAudioInput] = useState(false);
  const [debugInfo, setDebugInfo] = useState<string[]>([]);
  const [showDebug, setShowDebug] = useState(true); // é»˜è®¤æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
  const [currentModel, setCurrentModel] = useState<string>('loading...'); // å½“å‰ä½¿ç”¨çš„æ¨¡å‹
  const [isProcessing, setIsProcessing] = useState(false); // é˜²æ­¢é‡å¤å¤„ç†
  const [isProcessingTrigger, setIsProcessingTrigger] = useState(false); // é˜²æ­¢é‡å¤è§¦å‘äº‹ä»¶
  
  const containerRef = useRef<HTMLDivElement>(null);
  const animationRef = useRef<number>();
  const noSoundTimeoutRef = useRef<number | null>(null);
  const silenceTimeoutRef = useRef<number | null>(null);
  const autoCloseTimeoutRef = useRef<number | null>(null);
  const processingTimeoutRef = useRef<number | null>(null);  // å¤„ç†è¶…æ—¶
  const retryCountRef = useRef<number>(0);  // é‡è¯•è®¡æ•°
  
  // æ™ºèƒ½VADçŠ¶æ€è¿½è¸ª
  const lastSoundTimeRef = useRef<number>(Date.now());
  const recordingStartTimeRef = useRef<number>(0);
  const continuousSilenceDurationRef = useRef<number>(0);
  
  // éŸ³é¢‘åˆ†æå’Œè‡ªé€‚åº”å‚æ•°
  const audioLevelHistoryRef = useRef<number[]>([]);
  const noiseFloorRef = useRef<number>(0.03);  // åˆå§‹å™ªéŸ³åŸºçº¿è®¾ä¸º0.03ï¼ˆé€‚åº”æ–°çš„èŒƒå›´ï¼‰
  const smoothedLevelRef = useRef<number>(0);
  const vadStateRef = useRef<'waiting' | 'speech' | 'silence'>('waiting');
  const speechDetectedRef = useRef<boolean>(false);
  
  // æ·»åŠ è°ƒè¯•æ—¥å¿—å‡½æ•°
  const addDebugLog = (message: string) => {
    const timestamp = new Date().toLocaleTimeString();
    const logMessage = `[${timestamp}] ${message}`;
    console.log(`[DEBUG MacOSVoiceInput] ${logMessage}`);
    setDebugInfo(prev => [...prev.slice(-9), logMessage]); // ä¿ç•™æœ€è¿‘10æ¡
  };

  useEffect(() => {
    addDebugLog('ç»„ä»¶åˆå§‹åŒ–');
    
    // è·å–å½“å‰æ¨¡å‹ä¿¡æ¯
    const fetchModelInfo = async () => {
      try {
        const model = await invoke<string>('get_current_model_info');
        setCurrentModel(model);
        addDebugLog(`å½“å‰ä½¿ç”¨æ¨¡å‹: ${model}`);
      } catch (error) {
        console.error('è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥:', error);
        setCurrentModel('unknown');
      }
    };
    fetchModelInfo();
    
    // è®¾ç½®çª—å£å±æ€§ - æ¨¡æ‹Ÿ macOS åŸç”Ÿæ ·å¼
    const setupWindow = async () => {
      addDebugLog('å¼€å§‹è®¾ç½®çª—å£å±æ€§');
      
      await appWindow.setAlwaysOnTop(true);
      await appWindow.setDecorations(false);
      await appWindow.setResizable(false);
      await appWindow.setSkipTaskbar(true);
      
      // è®¾ç½®çª—å£å¤§å°å’Œä½ç½® - åƒ macOS è¯­éŸ³è¾“å…¥ä¸€æ ·å°å·§
      await appWindow.setSize(new LogicalSize(600, showDebug ? 300 : 120)); // è°ƒè¯•æ¨¡å¼ä¸‹çª—å£æ›´å¤§
      
      // å±…ä¸­æ˜¾ç¤ºåœ¨å±å¹•åº•éƒ¨
      try {
        const screenWidth = window.screen.width;
        const screenHeight = window.screen.height;
        const x = Math.floor((screenWidth - 600) / 2);
        const y = Math.floor(screenHeight - (showDebug ? 400 : 200)); // å±å¹•åº•éƒ¨ä½ç½®
        await appWindow.setPosition(new LogicalPosition(x, y));
        addDebugLog(`çª—å£ä½ç½®è®¾ç½®: x=${x}, y=${y}`);
      } catch (error) {
        console.error('è®¾ç½®çª—å£ä½ç½®å¤±è´¥:', error);
        addDebugLog(`çª—å£ä½ç½®è®¾ç½®å¤±è´¥: ${error}`);
      }

      // åˆå§‹åŒ–æ—¶ä¸è·å–æ´»åŠ¨åº”ç”¨ï¼Œç­‰å¾…äº‹ä»¶è§¦å‘æ—¶ä¼ é€’
      // æ´»åŠ¨åº”ç”¨ä¿¡æ¯å°†ç”±å¿«æ·é”®è§¦å‘æ—¶ä¼ é€’
    };
    
    setupWindow();

    // ç›‘å¬è¯­éŸ³è¾“å…¥è§¦å‘äº‹ä»¶
    const unlistenTrigger = listen<ActiveAppInfo>('voice_input_triggered', async (event) => {
      // é˜²æ­¢é‡å¤è§¦å‘
      if (isProcessingTrigger) {
        console.log('å¿½ç•¥é‡å¤çš„è§¦å‘äº‹ä»¶');
        addDebugLog('âš ï¸ å¿½ç•¥é‡å¤è§¦å‘äº‹ä»¶');
        return;
      }
      
      setIsProcessingTrigger(true);
      console.log('è¯­éŸ³è¾“å…¥è¢«è§¦å‘', event);
      addDebugLog('æ”¶åˆ° voice_input_triggered äº‹ä»¶');
      
      setState('idle');
      setTranscribedText('');
      setHasAudioInput(false);
      
      // ä½¿ç”¨äº‹ä»¶ä¸­ä¼ é€’çš„æ´»åŠ¨åº”ç”¨ä¿¡æ¯ï¼ˆè¿™æ˜¯è§¦å‘å‰çš„åŸå§‹æ´»åŠ¨åº”ç”¨ï¼‰
      if (event.payload && event.payload.name) {
        setActiveApp(event.payload);
        addDebugLog(`åŸå§‹æ´»åŠ¨åº”ç”¨: ${event.payload.name}`);
      } else {
        // å¦‚æœæ²¡æœ‰ä¼ é€’æ´»åŠ¨åº”ç”¨ä¿¡æ¯ï¼Œåˆ™å°è¯•è·å–ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        try {
          const appInfo = await invoke<ActiveAppInfo>('get_active_app_info_for_voice');
          setActiveApp(appInfo);
          addDebugLog(`è·å–æ´»åŠ¨åº”ç”¨: ${appInfo.name}`);
        } catch (error) {
          console.error('è·å–æ´»åŠ¨åº”ç”¨ä¿¡æ¯å¤±è´¥:', error);
          addDebugLog(`è·å–æ´»åŠ¨åº”ç”¨å¤±è´¥: ${error}`);
        }
      }
      
      // æ˜¾ç¤ºçª—å£å¹¶è‡ªåŠ¨å¼€å§‹å½•éŸ³
      addDebugLog('å‡†å¤‡æ˜¾ç¤ºçª—å£');
      await appWindow.show();
      await appWindow.setFocus();
      addDebugLog('çª—å£å·²æ˜¾ç¤ºå¹¶è·å¾—ç„¦ç‚¹');
      
      // å»¶è¿Ÿä¸€ç‚¹å¼€å§‹å½•éŸ³ï¼Œç¡®ä¿çª—å£å·²ç»æ˜¾ç¤º
      setTimeout(() => {
        addDebugLog('100ms å»¶è¿Ÿåå¼€å§‹å½•éŸ³');
        startListening();
        // å½•éŸ³å¼€å§‹åé‡ç½®è§¦å‘æ ‡å¿—ï¼Œå…è®¸ä¸‹æ¬¡è§¦å‘
        setTimeout(() => {
          setIsProcessingTrigger(false);
        }, 1000); // 1ç§’åå…è®¸æ–°è§¦å‘
      }, 100);
    });

    // ç›‘å¬å®æ—¶è½¬å½•ç»“æœ
    const unlistenTranscription = listen<string>('realtime_transcription', (event) => {
      setTranscribedText(event.payload);
      if (event.payload && event.payload.trim()) {
        setHasAudioInput(true);
        resetSilenceTimeout();
      }
    });

    // æ™ºèƒ½VADéŸ³é¢‘ç”µå¹³ç›‘å¬ - å¤šå±‚æ£€æµ‹ç®—æ³•
    const unlistenAudioLevel = listen<number>('audio_level', (event) => {
      const rawLevel = event.payload;
      const now = Date.now();
      
      // ğŸ¯ VAD é…ç½®å‚æ•° - é€‚é…æ–°çš„éŸ³é¢‘ç”µå¹³èŒƒå›´
      const VAD_CONFIG = {
        // é˜ˆå€¼è®¾ç½®ï¼ˆæ ¹æ®æ–°çš„RMSè®¡ç®—æ–¹æ³•è°ƒæ•´ï¼‰
        SOUND_THRESHOLD: 0.15,        // ä¸»å£°éŸ³é˜ˆå€¼ï¼ˆæ­£å¸¸è¯´è¯çº¦0.1-0.3ï¼‰
        SILENCE_THRESHOLD: 0.05,      // é™éŸ³é˜ˆå€¼ï¼ˆç¯å¢ƒå™ªéŸ³é€šå¸¸<0.05ï¼‰
        NOISE_GATE: 0.02,             // å™ªéŸ³é—¨é™ï¼ˆæä½èƒŒæ™¯å™ªéŸ³ï¼‰
        
        // æ—¶é—´æ§åˆ¶
        MIN_SPEECH_DURATION: 500,     // æœ€çŸ­æœ‰æ•ˆè¯­éŸ³æ—¶é•¿ï¼ˆå‡å°‘åˆ°500msï¼Œæ›´çµæ•ï¼‰
        SILENCE_DURATION: 1500,       // é™éŸ³ç­‰å¾…æ—¶é—´ï¼ˆ1.5ç§’ï¼‰
        CONFIRMATION_DELAY: 200,      // ç¡®è®¤å»¶è¿Ÿï¼ˆ200msï¼‰
        
        // è‡ªé€‚åº”å‚æ•°
        LEVEL_SMOOTHING: 0.4,         // éŸ³é¢‘ç”µå¹³å¹³æ»‘ç³»æ•°ï¼ˆå¢åŠ å¹³æ»‘åº¦ï¼‰
        NOISE_FLOOR_SAMPLES: 50,      // å™ªéŸ³åŸºçº¿é‡‡æ ·æ•°é‡ï¼ˆå¢åŠ æ ·æœ¬æ•°ï¼‰
      };
      
      // ğŸ“ˆ éŸ³é¢‘ç”µå¹³å¹³æ»‘å¤„ç†
      smoothedLevelRef.current = smoothedLevelRef.current * (1 - VAD_CONFIG.LEVEL_SMOOTHING) + 
                                rawLevel * VAD_CONFIG.LEVEL_SMOOTHING;
      const level = smoothedLevelRef.current;
      setAudioLevel(level);
      
      // ğŸ“Š å™ªéŸ³åŸºçº¿è‡ªé€‚åº”å­¦ä¹ 
      audioLevelHistoryRef.current.push(level);
      if (audioLevelHistoryRef.current.length > VAD_CONFIG.NOISE_FLOOR_SAMPLES) {
        audioLevelHistoryRef.current.shift();
        // è®¡ç®—å™ªéŸ³åŸºçº¿ï¼ˆå–å†å²æ•°æ®çš„25%åˆ†ä½æ•°ï¼‰
        const sorted = [...audioLevelHistoryRef.current].sort((a, b) => a - b);
        noiseFloorRef.current = sorted[Math.floor(sorted.length * 0.25)];
      }
      
      // ğŸ¤ åŠ¨æ€é˜ˆå€¼è®¡ç®—ï¼ˆåŸºäºå™ªéŸ³åŸºçº¿ï¼‰
      const dynamicThreshold = Math.max(
        VAD_CONFIG.SOUND_THRESHOLD, 
        noiseFloorRef.current * 2.5  // è¯­éŸ³åº”è¯¥æ¯”å™ªéŸ³é«˜2.5å€
      );
      
      const dynamicSilenceThreshold = Math.max(
        VAD_CONFIG.SILENCE_THRESHOLD,
        noiseFloorRef.current * 1.2  // é™éŸ³é˜ˆå€¼ç•¥é«˜äºå™ªéŸ³åŸºçº¿
      );
      
      // ğŸ§  VAD çŠ¶æ€æœºé€»è¾‘
      const isSound = level > dynamicThreshold;
      const isSilence = level < dynamicSilenceThreshold;
      
      if (isSound) {
        // ğŸ”Š æ£€æµ‹åˆ°å£°éŸ³
        lastSoundTimeRef.current = now;
        
        // çŠ¶æ€è½¬æ¢ï¼šwaiting -> speech æˆ–ä¿æŒ speech
        if (vadStateRef.current !== 'speech') {
          vadStateRef.current = 'speech';
          speechDetectedRef.current = true;
          
          if (!hasAudioInput) {
            setHasAudioInput(true);
            addDebugLog(`ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ | çº§åˆ«: ${level.toFixed(3)} | é˜ˆå€¼: ${dynamicThreshold.toFixed(3)}`);
            
            // æ¸…é™¤æ— å£°éŸ³è¶…æ—¶
            if (noSoundTimeoutRef.current) {
              clearTimeout(noSoundTimeoutRef.current);
              noSoundTimeoutRef.current = null;
            }
          }
        }
        
        // æ¸…é™¤é™éŸ³æ£€æµ‹å®šæ—¶å™¨
        if (silenceTimeoutRef.current) {
          clearTimeout(silenceTimeoutRef.current);
          silenceTimeoutRef.current = null;
        }
        
        // é‡ç½®é™éŸ³è®¡æ—¶
        continuousSilenceDurationRef.current = 0;
        
      } else if (isSilence && speechDetectedRef.current) {
        // ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼ˆä½†ä¹‹å‰æœ‰è¿‡è¯­éŸ³ï¼‰
        const silenceDuration = now - lastSoundTimeRef.current;
        continuousSilenceDurationRef.current = silenceDuration;
        
        // çŠ¶æ€è½¬æ¢ï¼šspeech -> silence
        if (vadStateRef.current === 'speech') {
          vadStateRef.current = 'silence';
          addDebugLog(`ğŸ”‡ è¯­éŸ³ç»“æŸï¼Œå¼€å§‹é™éŸ³æ£€æµ‹ | çº§åˆ«: ${level.toFixed(3)}`);
        }
        
        // å½•éŸ³æ—¶é—´æ£€æŸ¥
        if (hasAudioInput && isRecording) {
          const recordingDuration = now - recordingStartTimeRef.current;
          
          // æ»¡è¶³æœ€çŸ­è¯­éŸ³æ—¶é•¿è¦æ±‚
          if (recordingDuration > VAD_CONFIG.MIN_SPEECH_DURATION) {
            // é™éŸ³æŒç»­è¶³å¤Ÿé•¿æ—¶é—´
            if (silenceDuration > VAD_CONFIG.SILENCE_DURATION && !silenceTimeoutRef.current) {
              addDebugLog(`â° é™éŸ³ ${(silenceDuration/1000).toFixed(1)}sï¼Œå‡†å¤‡ç»“æŸå½•éŸ³`);
              
              // ç¡®è®¤å»¶è¿Ÿï¼Œé¿å…è¯¯è§¦å‘
              silenceTimeoutRef.current = setTimeout(() => {
                const currentSilence = Date.now() - lastSoundTimeRef.current;
                if (isRecording && currentSilence > VAD_CONFIG.SILENCE_DURATION) {
                  addDebugLog(`âœ… é™éŸ³ç¡®è®¤ï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³`);
                  stopListening();
                }
              }, VAD_CONFIG.CONFIRMATION_DELAY);
            }
          }
        }
        
      } else {
        // ğŸ“Š ä¸­é—´çŠ¶æ€ï¼ˆä»‹äºå£°éŸ³å’Œé™éŸ³ä¹‹é—´ï¼‰
        // åœ¨ä¸­é—´çŠ¶æ€æ—¶ï¼Œå¦‚æœæ­£åœ¨è¯´è¯ä¸­ï¼Œåº”è¯¥é‡ç½®é™éŸ³è®¡æ—¶
        if (vadStateRef.current === 'speech') {
          // è¿˜åœ¨è¯´è¯èŒƒå›´å†…ï¼Œé‡ç½®é™éŸ³è®¡æ—¶
          lastSoundTimeRef.current = now;
          continuousSilenceDurationRef.current = 0;
          
          // æ¸…é™¤é™éŸ³æ£€æµ‹å®šæ—¶å™¨
          if (silenceTimeoutRef.current) {
            clearTimeout(silenceTimeoutRef.current);
            silenceTimeoutRef.current = null;
          }
        } else {
          // çœŸæ­£çš„é™éŸ³çŠ¶æ€
          const silenceDuration = now - lastSoundTimeRef.current;
          continuousSilenceDurationRef.current = silenceDuration;
        }
      }
      
      // ğŸ› è°ƒè¯•ä¿¡æ¯å¢å¼º
      if (showDebug && isRecording) {
        const silenceTime = (continuousSilenceDurationRef.current / 1000).toFixed(1);
        const recordingTime = ((now - recordingStartTimeRef.current) / 1000).toFixed(1);
        
        // æ¯ç§’è¾“å‡ºä¸€æ¬¡è¯¦ç»†è°ƒè¯•ä¿¡æ¯
        if (Date.now() % 1000 < 100) { // è¿‘ä¼¼æ¯ç§’
          addDebugLog(
            `ğŸ“Š VADçŠ¶æ€: ${vadStateRef.current} | ` +
            `çº§åˆ«: ${level.toFixed(3)} | ` +
            `é˜ˆå€¼: ${dynamicThreshold.toFixed(3)} | ` +
            `é™éŸ³: ${silenceTime}s | ` +
            `å½•éŸ³: ${recordingTime}s | ` +
            `å™ªéŸ³åŸºçº¿: ${noiseFloorRef.current.toFixed(3)}`
          );
        }
      }
    });

    // ç›‘å¬ ESC é”®å…³é—­çª—å£
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.key === 'Escape') {
        handleCancel();
      }
      // ç§»é™¤ Enter é”®è§¦å‘ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯å…¨è‡ªåŠ¨çš„
    };
    document.addEventListener('keydown', handleKeyDown);

    return () => {
      unlistenTrigger.then(fn => fn());
      unlistenTranscription.then(fn => fn());
      unlistenAudioLevel.then(fn => fn());
      document.removeEventListener('keydown', handleKeyDown);
      clearAllTimeouts();
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, [hasAudioInput, isRecording]);

  // æ¸…ç†æ‰€æœ‰è¶…æ—¶
  const clearAllTimeouts = () => {
    if (noSoundTimeoutRef.current) {
      clearTimeout(noSoundTimeoutRef.current);
      noSoundTimeoutRef.current = null;
    }
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
    if (autoCloseTimeoutRef.current) {
      clearTimeout(autoCloseTimeoutRef.current);
      autoCloseTimeoutRef.current = null;
    }
    if (processingTimeoutRef.current) {
      clearTimeout(processingTimeoutRef.current);
      processingTimeoutRef.current = null;
    }
  };

  // é‡ç½®é™éŸ³è¶…æ—¶ï¼ˆä¿ç•™ä½†ç®€åŒ–ï¼Œä¸»è¦é€»è¾‘åœ¨éŸ³é¢‘ç”µå¹³ç›‘å¬ä¸­ï¼‰
  const resetSilenceTimeout = () => {
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
  };

  // å¼€å§‹ç›‘å¬è¯­éŸ³
  const startListening = async () => {
    addDebugLog('startListening å‡½æ•°è¢«è°ƒç”¨');
    try {
      clearAllTimeouts();
      setState('listening');
      setIsRecording(true);
      setHasAudioInput(false);
      
      // ğŸ”„ é‡ç½®VADçŠ¶æ€å’Œé”™è¯¯å¤„ç†çŠ¶æ€
      recordingStartTimeRef.current = Date.now();
      lastSoundTimeRef.current = Date.now();
      continuousSilenceDurationRef.current = 0;
      speechDetectedRef.current = false;
      vadStateRef.current = 'waiting';
      smoothedLevelRef.current = 0;
      audioLevelHistoryRef.current = [];
      noiseFloorRef.current = 0.03;  // é‡ç½®ä¸ºåˆç†çš„åˆå§‹å™ªéŸ³åŸºçº¿
      retryCountRef.current = 0;  // é‡ç½®é‡è¯•è®¡æ•°
      
      addDebugLog('ğŸ¬ å½•éŸ³å¼€å§‹ - æ‰€æœ‰VADçŠ¶æ€å·²é‡ç½®');
      
      // è°ƒç”¨åç«¯å¼€å§‹å½•éŸ³ï¼ˆå¯ç”¨å®æ—¶æ¨¡å¼ï¼‰
      addDebugLog('å‡†å¤‡è°ƒç”¨ start_voice_recording å‘½ä»¤');
      await invoke('start_voice_recording', {
        deviceId: 'default',  // ä¿®å¤ï¼šä½¿ç”¨é©¼å³°å‘½å deviceId è€Œä¸æ˜¯ device_id
        realtime: true
      });
      addDebugLog('start_voice_recording å‘½ä»¤è°ƒç”¨æˆåŠŸ');
      
      // è®¾ç½®æ— å£°éŸ³æ£€æµ‹è¶…æ—¶ï¼ˆ5ç§’å†…æ²¡æœ‰æ£€æµ‹åˆ°å£°éŸ³åˆ™è‡ªåŠ¨å…³é—­ï¼‰
      noSoundTimeoutRef.current = setTimeout(() => {
        console.log('æ£€æŸ¥å£°éŸ³è¾“å…¥çŠ¶æ€:', hasAudioInput);
        addDebugLog(`5ç§’è¶…æ—¶æ£€æŸ¥ - éŸ³é¢‘è¾“å…¥: ${hasAudioInput}`);
        if (!hasAudioInput) {
          console.log('5ç§’å†…æœªæ£€æµ‹åˆ°å£°éŸ³ï¼Œè‡ªåŠ¨å…³é—­çª—å£');
          addDebugLog('5ç§’å†…æœªæ£€æµ‹åˆ°å£°éŸ³ï¼Œå‡†å¤‡å…³é—­çª—å£');
          handleCancel();
        }
      }, 5000);
      addDebugLog('å·²è®¾ç½®3ç§’æ— å£°éŸ³æ£€æµ‹è¶…æ—¶');
      
      // å¼€å§‹éŸ³é¢‘æ³¢å½¢åŠ¨ç”»
      animateWaveform();
      addDebugLog('éŸ³é¢‘æ³¢å½¢åŠ¨ç”»å·²å¯åŠ¨');
    } catch (error) {
      console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error);
      addDebugLog(`å¼€å§‹å½•éŸ³å¤±è´¥: ${error}`);
      setState('idle');
      setIsRecording(false);
    }
  };

  // åœæ­¢ç›‘å¬å¹¶å¤„ç†
  const stopListening = async () => {
    // é˜²æ­¢é‡å¤è°ƒç”¨
    if (isProcessing) {
      addDebugLog('âš ï¸ å·²åœ¨å¤„ç†ä¸­ï¼Œå¿½ç•¥é‡å¤è°ƒç”¨');
      return;
    }
    
    addDebugLog('â¹ï¸ stopListening è¢«è°ƒç”¨');
    setIsProcessing(true);
    
    try {
      clearAllTimeouts();
      setIsRecording(false);
      
      // å¦‚æœæ²¡æœ‰éŸ³é¢‘è¾“å…¥ï¼Œç›´æ¥å…³é—­
      if (!hasAudioInput) {
        addDebugLog('âŒ æ²¡æœ‰æ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥ï¼Œå–æ¶ˆæ“ä½œ');
        await handleCancel();
        return;
      }
      
      setState('processing');
      addDebugLog('ğŸ”„ çŠ¶æ€åˆ‡æ¢åˆ° processingï¼Œå‡†å¤‡åœæ­¢å½•éŸ³');
      
      // è®¾ç½®å¤„ç†è¶…æ—¶ - 8ç§’åè‡ªåŠ¨é‡è¯•æˆ–å¤±è´¥
      processingTimeoutRef.current = setTimeout(async () => {
        addDebugLog('â° å¤„ç†è¶…æ—¶ï¼Œå°è¯•æ¢å¤æœºåˆ¶');
        retryCountRef.current++;
        
        if (retryCountRef.current <= 2) {
          // æœ€å¤šé‡è¯•2æ¬¡
          addDebugLog(`ğŸ”„ ç¬¬${retryCountRef.current}æ¬¡é‡è¯•è½¬å½•`);
          setTranscribedText(`é‡è¯•ä¸­... (${retryCountRef.current}/2)`);
          
          try {
            // å†æ¬¡å°è¯•åœæ­¢å½•éŸ³
            const retryText = await invoke<string>('stop_voice_recording');
            
            // æ¸…é™¤è¶…æ—¶
            if (processingTimeoutRef.current) {
              clearTimeout(processingTimeoutRef.current);
              processingTimeoutRef.current = null;
            }
            
            if (retryText && retryText.trim()) {
              setState('injecting');
              setTranscribedText(retryText);
              addDebugLog(`âœ… é‡è¯•æˆåŠŸ: "${retryText}"`);
              
              // å…ˆéšè—çª—å£ï¼Œæ¢å¤åŸå§‹åº”ç”¨ç„¦ç‚¹ï¼Œç„¶åæ³¨å…¥æ–‡æœ¬
              await appWindow.hide();
              addDebugLog('çª—å£å·²éšè—');
              await new Promise(resolve => setTimeout(resolve, 300));
              
              // å¦‚æœæœ‰åŸå§‹åº”ç”¨ä¿¡æ¯ï¼Œæ¿€æ´»å®ƒ
              if (activeApp && activeApp.bundleId) {
                addDebugLog(`æ¿€æ´»åŸå§‹åº”ç”¨: ${activeApp.name} (${activeApp.bundleId})`);
                await invoke('activate_app_by_bundle_id', { bundleId: activeApp.bundleId });
                await new Promise(resolve => setTimeout(resolve, 500));
              }
              
              await invoke('inject_text_to_active_app', { 
                text: retryText, 
                targetBundleId: activeApp.bundleId 
              });
              addDebugLog('âœ… æ–‡æœ¬æ³¨å…¥æˆåŠŸ');
              
              // çª—å£å·²éšè—ï¼Œç›´æ¥æ¸…ç†çŠ¶æ€
              setTimeout(() => {
                setTranscribedText('');
                setHasAudioInput(false);
                setState('idle');
                setIsProcessing(false);
                setIsProcessingTrigger(false);
              }, 100);
            } else {
              addDebugLog('âš ï¸ é‡è¯•åè½¬å½•ç»“æœä»ä¸ºç©º');
              closeWindow();
            }
          } catch (retryError) {
            addDebugLog(`âŒ é‡è¯•å¤±è´¥: ${retryError}`);
            // ç»§ç»­ç­‰å¾…ä¸‹ä¸€æ¬¡è¶…æ—¶é‡è¯•
          }
        } else {
          // é‡è¯•æ¬¡æ•°ç”¨å®Œï¼Œä¼˜é›…å¤±è´¥
          addDebugLog('âŒ é‡è¯•æ¬¡æ•°ç”¨å®Œï¼Œä¼˜é›…ç»“æŸ');
          setState('idle');
          setTranscribedText('å¤„ç†è¶…æ—¶ï¼Œæ“ä½œå·²å–æ¶ˆ');
          setTimeout(() => {
            closeWindow();
          }, 2000);
        }
      }, 8000); // 8ç§’è¶…æ—¶
      
      // å°è¯•åœæ­¢å½•éŸ³å¹¶è·å–è½¬å½•ç»“æœ
      const finalText = await invoke<string>('stop_voice_recording');
      
      // å¦‚æœæˆåŠŸå®Œæˆï¼Œæ¸…é™¤è¶…æ—¶
      if (processingTimeoutRef.current) {
        clearTimeout(processingTimeoutRef.current);
        processingTimeoutRef.current = null;
      }
      
      addDebugLog(`ğŸ“ è½¬å½•ç»“æœ: "${finalText}"`);
      
      if (finalText && finalText.trim()) {
        setState('injecting');
        setTranscribedText(finalText);
        addDebugLog(`ğŸ’‰ å‡†å¤‡æ³¨å…¥æ–‡æœ¬: "${finalText}"`);
        addDebugLog(`åŸå§‹åº”ç”¨ä¿¡æ¯: ${activeApp.name} (${activeApp.bundleId})`);
        
        // å…ˆéšè—çª—å£
        await appWindow.hide();
        addDebugLog('çª—å£å·²éšè—');
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿çª—å£å®Œå…¨éšè—
        await new Promise(resolve => setTimeout(resolve, 300));
        
        // å¦‚æœæœ‰åŸå§‹åº”ç”¨ä¿¡æ¯ï¼Œæ¿€æ´»å®ƒ
        if (activeApp && activeApp.bundleId) {
          addDebugLog(`ğŸ¯ å¼€å§‹æ¿€æ´»åŸå§‹åº”ç”¨: ${activeApp.name} (${activeApp.bundleId})`);
          try {
            await invoke('activate_app_by_bundle_id', { bundleId: activeApp.bundleId });
            addDebugLog('ğŸ“± åº”ç”¨æ¿€æ´»å‘½ä»¤å·²å‘é€');
            // å¢åŠ ç­‰å¾…æ—¶é—´ç¡®ä¿åº”ç”¨å®Œå…¨æ¿€æ´»
            await new Promise(resolve => setTimeout(resolve, 800));
            addDebugLog('â° åº”ç”¨æ¿€æ´»ç­‰å¾…å®Œæˆ');
          } catch (error) {
            addDebugLog(`âŒ æ¿€æ´»åº”ç”¨å¤±è´¥: ${error}`);
          }
        } else {
          addDebugLog('âš ï¸ æ²¡æœ‰åŸå§‹åº”ç”¨ä¿¡æ¯ï¼Œè·³è¿‡æ¿€æ´»æ­¥éª¤');
        }
        
        // æ³¨å…¥æ–‡æœ¬åˆ°å½“å‰æ´»åŠ¨åº”ç”¨
        addDebugLog(`ğŸ’‰ å¼€å§‹æ³¨å…¥æ–‡æœ¬: "${finalText}"`);
        try {
          await invoke('inject_text_to_active_app', { 
            text: finalText, 
            targetBundleId: activeApp.bundleId 
          });
          addDebugLog('âœ… æ–‡æœ¬æ³¨å…¥å‘½ä»¤æ‰§è¡ŒæˆåŠŸ');
          
          // é¢å¤–éªŒè¯ï¼šç­‰å¾…ä¸€ä¸‹çœ‹æ˜¯å¦çœŸçš„æˆåŠŸ
          await new Promise(resolve => setTimeout(resolve, 300));
          addDebugLog('ğŸ” æ–‡æœ¬æ³¨å…¥éªŒè¯ç­‰å¾…å®Œæˆ');
        } catch (error) {
          addDebugLog(`âŒ æ–‡æœ¬æ³¨å…¥å¤±è´¥: ${error}`);
          throw error; // é‡æ–°æŠ›å‡ºé”™è¯¯ä»¥ä¾¿ä¸Šå±‚å¤„ç†
        }
        
        // çª—å£å·²éšè—ï¼Œç›´æ¥æ¸…ç†çŠ¶æ€
        setTimeout(() => {
          setTranscribedText('');
          setHasAudioInput(false);
          setState('idle');
          setIsProcessing(false);
          setIsProcessingTrigger(false);
        }, 100);
      } else {
        // æ²¡æœ‰è¯†åˆ«åˆ°å†…å®¹ï¼Œæ˜¾ç¤ºå¤±è´¥
        addDebugLog('âš ï¸ è½¬å½•ç»“æœä¸ºç©º');
        setState('idle');
        setTranscribedText('æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹');
        
        // ä¸å†é‡è¯•stop_voice_recordingï¼Œå› ä¸ºå½•éŸ³å·²åœæ­¢
        setTimeout(() => {
          closeWindow();
        }, 2000);
            
        // åˆ é™¤é‡è¯•é€»è¾‘ï¼Œé¿å…é‡å¤è°ƒç”¨
      }
    } catch (error) {
      setIsProcessing(false);
      // æ¸…é™¤å¤„ç†è¶…æ—¶
      if (processingTimeoutRef.current) {
        clearTimeout(processingTimeoutRef.current);
        processingTimeoutRef.current = null;
      }
      
      console.error('å¤„ç†å½•éŸ³å¤±è´¥:', error);
      addDebugLog(`âŒ å¤„ç†å½•éŸ³å¤±è´¥: ${error}`);
      
      // å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œä¸ç›´æ¥å¤±è´¥
      retryCountRef.current++;
      if (retryCountRef.current <= 2) {
        addDebugLog(`ğŸ”„ é”™è¯¯åç¬¬${retryCountRef.current}æ¬¡é‡è¯•`);
        setState('processing');
        setTranscribedText(`é”™è¯¯æ¢å¤ä¸­... (${retryCountRef.current}/2)`);
        
        // å»¶è¿Ÿé‡è¯•
        setTimeout(() => {
          stopListening();
        }, 1000);
      } else {
        setState('idle');
        setTranscribedText('è½¬å½•å¤±è´¥ï¼Œè¯·é‡è¯•');
        setTimeout(() => {
          closeWindow();
        }, 2000);
      }
    }
  };

  // å–æ¶ˆæ“ä½œ
  const handleCancel = async () => {
    clearAllTimeouts();
    
    if (isRecording) {
      try {
        await invoke('stop_voice_recording');
      } catch (error) {
        console.error('åœæ­¢å½•éŸ³å¤±è´¥:', error);
      }
    }
    
    setIsRecording(false);
    setState('idle');
    closeWindow();
  };

  // å…³é—­çª—å£
  const closeWindow = async () => {
    clearAllTimeouts();
    setTranscribedText('');
    setHasAudioInput(false);
    setState('idle');
    setIsRecording(false);
    setIsProcessing(false);
    setIsProcessingTrigger(false); // é‡ç½®è§¦å‘æ ‡å¿—
    await appWindow.hide();
  };

  // éŸ³é¢‘æ³¢å½¢åŠ¨ç”»
  const animateWaveform = () => {
    if (!isRecording) return;
    
    // æ›´æ–°æ³¢å½¢åŠ¨ç”»
    const bars = containerRef.current?.querySelectorAll('.waveform-bar');
    if (bars) {
      bars.forEach((bar: any) => {
        const height = 20 + audioLevel * 30 + Math.random() * 10;
        bar.style.height = `${height}px`;
      });
    }
    
    animationRef.current = requestAnimationFrame(animateWaveform);
  };

  // è·å–åº”ç”¨å›¾æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
  const getAppIcon = () => {
    if (activeApp.icon) {
      return <img src={activeApp.icon} alt={activeApp.name} className="app-icon" />;
    }
    // é»˜è®¤å›¾æ ‡
    return <div className="app-icon-placeholder">ğŸ“</div>;
  };

  // è·å–çŠ¶æ€æ–‡æœ¬
  const getStatusText = () => {
    // åªæ˜¾ç¤ºçœŸå®çš„è½¬å½•æ–‡æœ¬ï¼Œä¸æ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®
    if (transcribedText && transcribedText !== 'ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„') {
      return transcribedText;
    }
    
    switch (state) {
      case 'listening':
        return hasAudioInput ? 'æ­£åœ¨è†å¬...' : 'è¯·å¼€å§‹è¯´è¯...';
      case 'processing':
        return 'æ­£åœ¨è½¬å½•...';
      case 'injecting':
        return 'æ­£åœ¨è¾“å…¥åˆ°ç›®æ ‡åº”ç”¨...';
      default:
        return '';
    }
  };

  return (
    <div className="macos-voice-input" ref={containerRef}>
      {/* è°ƒè¯•é¢æ¿ */}
      {showDebug && (
        <div style={{
          position: 'absolute',
          top: 0,
          left: 0,
          right: 0,
          background: 'rgba(0, 0, 0, 0.9)',
          color: '#00ff00',
          fontFamily: 'monospace',
          fontSize: '10px',
          padding: '10px',
          maxHeight: '150px',
          overflowY: 'auto',
          zIndex: 1000,
          borderBottom: '1px solid #00ff00'
        }}>
          <div style={{ marginBottom: '5px', color: '#ffff00' }}>
            ğŸ› DEBUG MODE | çŠ¶æ€: {state} | å½•éŸ³: {isRecording ? 'æ˜¯' : 'å¦'} | éŸ³é¢‘: {hasAudioInput ? 'æœ‰' : 'æ— '} | æ¨¡å‹: {currentModel}
          </div>
          <div style={{ marginBottom: '5px', color: '#00ffff' }}>
            çº§åˆ«: {audioLevel.toFixed(3)} | VAD: {vadStateRef.current} | é™éŸ³: {(continuousSilenceDurationRef.current/1000).toFixed(1)}s | åŸºçº¿: {noiseFloorRef.current.toFixed(3)}
          </div>
          <div style={{ marginBottom: '5px', color: '#ffaa00' }}>
            æ–‡æœ¬: "{transcribedText}" | è¯­éŸ³æ£€æµ‹: {speechDetectedRef.current ? 'æ˜¯' : 'å¦'}
          </div>
          <div style={{ borderTop: '1px solid #333', paddingTop: '5px' }}>
            {debugInfo.map((log, index) => (
              <div key={index} style={{ opacity: 1 - (index * 0.08) }}>
                {log}
              </div>
            ))}
          </div>
        </div>
      )}
      
      <div className="voice-input-container" style={{ marginTop: showDebug ? '160px' : '0' }}>
        {/* å·¦ä¾§ - åº”ç”¨å›¾æ ‡å’Œä¿¡æ¯ */}
        <div className="app-info-section">
          <div className="app-icon-wrapper">
            {getAppIcon()}
          </div>
          <div className="app-name">{activeApp.name}</div>
        </div>

        {/* ä¸­é—´ - æ³¢å½¢å’Œæ–‡å­—æ˜¾ç¤º */}
        <div className="voice-content-section">
          {state === 'listening' && (
            <div className="waveform-container">
              <div className="waveform-bars">
                {[...Array(20)].map((_, i) => (
                  <div 
                    key={i} 
                    className="waveform-bar"
                    style={{
                      animationDelay: `${i * 0.05}s`
                    }}
                  />
                ))}
              </div>
              <div className={transcribedText ? 'realtime-text' : 'listening-hint'}>
                {getStatusText()}
              </div>
            </div>
          )}

          {state === 'processing' && (
            <div className="processing-container">
              <div className="processing-spinner" />
              <div className="processing-text">å¤„ç†ä¸­...</div>
            </div>
          )}

          {state === 'injecting' && (
            <div className="success-container">
              <div className="success-icon">âœ“</div>
              <div className="final-text">{transcribedText}</div>
            </div>
          )}
        </div>

        {/* å³ä¾§ - æ§åˆ¶æŒ‰é’® */}
        <div className="control-section">
          <button 
            className="close-button"
            onClick={handleCancel}
            title="å–æ¶ˆ (ESC)"
          >
            Ã—
          </button>
        </div>
      </div>

      {/* åº•éƒ¨æç¤º */}
      <div className="bottom-hint">
        <span className="hint-text">
          {hasAudioInput 
            ? 'æ­£åœ¨è†å¬ï¼Œè¯´å®Œè¯·ç¨å€™...' 
            : 'è¯·å¼€å§‹è¯´è¯'}
        </span>
      </div>
    </div>
  );
};

export default MacOSVoiceInput;
