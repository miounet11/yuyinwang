import React, { useState, useRef, useEffect } from 'react';
import { appWindow, LogicalPosition, LogicalSize } from '@tauri-apps/api/window';
import { invoke } from '@tauri-apps/api/tauri';
import { listen } from '@tauri-apps/api/event';
import './MacOSVoiceInput.css';

interface ActiveAppInfo {
  name: string;
  icon?: string;
  bundleId?: string;
}

type InputState = 'idle' | 'listening' | 'processing' | 'injecting';

const MacOSVoiceInput: React.FC = () => {
  const [state, setState] = useState<InputState>('idle');
  const [transcribedText, setTranscribedText] = useState('');
  const [activeApp, setActiveApp] = useState<ActiveAppInfo>({ name: 'æœªçŸ¥åº”ç”¨' });
  const [audioLevel, setAudioLevel] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [hasAudioInput, setHasAudioInput] = useState(false);
  
  const containerRef = useRef<HTMLDivElement>(null);
  const animationRef = useRef<number>();
  const noSoundTimeoutRef = useRef<number | null>(null);
  const silenceTimeoutRef = useRef<number | null>(null);
  const autoCloseTimeoutRef = useRef<number | null>(null);

  useEffect(() => {
    // è®¾ç½®çª—å£å±æ€§ - æ¨¡æ‹Ÿ macOS åŸç”Ÿæ ·å¼
    const setupWindow = async () => {
      await appWindow.setAlwaysOnTop(true);
      await appWindow.setDecorations(false);
      await appWindow.setResizable(false);
      await appWindow.setSkipTaskbar(true);
      
      // è®¾ç½®çª—å£å¤§å°å’Œä½ç½® - åƒ macOS è¯­éŸ³è¾“å…¥ä¸€æ ·å°å·§
      await appWindow.setSize(new LogicalSize(380, 120));
      
      // å±…ä¸­æ˜¾ç¤ºåœ¨å±å¹•åº•éƒ¨
      try {
        const screenWidth = window.screen.width;
        const screenHeight = window.screen.height;
        const x = Math.floor((screenWidth - 380) / 2);
        const y = Math.floor(screenHeight - 200); // å±å¹•åº•éƒ¨ä½ç½®
        await appWindow.setPosition(new LogicalPosition(x, y));
      } catch (error) {
        console.error('è®¾ç½®çª—å£ä½ç½®å¤±è´¥:', error);
      }

      // è·å–å½“å‰æ´»åŠ¨åº”ç”¨ä¿¡æ¯
      try {
        const appInfo = await invoke<ActiveAppInfo>('get_active_app_info_for_voice');
        setActiveApp(appInfo);
      } catch (error) {
        console.error('è·å–æ´»åŠ¨åº”ç”¨ä¿¡æ¯å¤±è´¥:', error);
      }
    };
    
    setupWindow();

    // ç›‘å¬è¯­éŸ³è¾“å…¥è§¦å‘äº‹ä»¶
    const unlistenTrigger = listen('voice_input_triggered', async () => {
      console.log('è¯­éŸ³è¾“å…¥è¢«è§¦å‘');
      setState('idle');
      setTranscribedText('');
      setHasAudioInput(false);
      
      // é‡æ–°è·å–æ´»åŠ¨åº”ç”¨ä¿¡æ¯
      try {
        const appInfo = await invoke<ActiveAppInfo>('get_active_app_info_for_voice');
        setActiveApp(appInfo);
      } catch (error) {
        console.error('è·å–æ´»åŠ¨åº”ç”¨ä¿¡æ¯å¤±è´¥:', error);
      }
      
      // æ˜¾ç¤ºçª—å£å¹¶è‡ªåŠ¨å¼€å§‹å½•éŸ³
      await appWindow.show();
      await appWindow.setFocus();
      
      // å»¶è¿Ÿä¸€ç‚¹å¼€å§‹å½•éŸ³ï¼Œç¡®ä¿çª—å£å·²ç»æ˜¾ç¤º
      setTimeout(() => {
        startListening();
      }, 100);
    });

    // ç›‘å¬å®æ—¶è½¬å½•ç»“æœ
    const unlistenTranscription = listen<string>('realtime_transcription', (event) => {
      setTranscribedText(event.payload);
      if (event.payload && event.payload.trim()) {
        setHasAudioInput(true);
        resetSilenceTimeout();
      }
    });

    // ç›‘å¬éŸ³é¢‘ç”µå¹³
    const unlistenAudioLevel = listen<number>('audio_level', (event) => {
      setAudioLevel(event.payload);
      
      // å¦‚æœæ£€æµ‹åˆ°å£°éŸ³
      if (event.payload > 0.1) {
        if (!hasAudioInput) {
          setHasAudioInput(true);
          // æ¸…é™¤æ— å£°éŸ³è¶…æ—¶
          if (noSoundTimeoutRef.current) {
            clearTimeout(noSoundTimeoutRef.current);
            noSoundTimeoutRef.current = null;
          }
        }
        // é‡ç½®é™éŸ³è¶…æ—¶
        resetSilenceTimeout();
      }
    });

    // ç›‘å¬ ESC é”®å…³é—­çª—å£
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.key === 'Escape') {
        handleCancel();
      } else if (e.key === 'Enter' && isRecording) {
        stopListening();
      }
    };
    document.addEventListener('keydown', handleKeyDown);

    return () => {
      unlistenTrigger.then(fn => fn());
      unlistenTranscription.then(fn => fn());
      unlistenAudioLevel.then(fn => fn());
      document.removeEventListener('keydown', handleKeyDown);
      clearAllTimeouts();
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, [hasAudioInput, isRecording]);

  // æ¸…ç†æ‰€æœ‰è¶…æ—¶
  const clearAllTimeouts = () => {
    if (noSoundTimeoutRef.current) {
      clearTimeout(noSoundTimeoutRef.current);
      noSoundTimeoutRef.current = null;
    }
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
    if (autoCloseTimeoutRef.current) {
      clearTimeout(autoCloseTimeoutRef.current);
      autoCloseTimeoutRef.current = null;
    }
  };

  // é‡ç½®é™éŸ³è¶…æ—¶
  const resetSilenceTimeout = () => {
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
    }
    
    // 2ç§’é™éŸ³åè‡ªåŠ¨å®Œæˆ
    silenceTimeoutRef.current = setTimeout(() => {
      if (hasAudioInput && isRecording) {
        console.log('æ£€æµ‹åˆ°é™éŸ³ï¼Œè‡ªåŠ¨å®Œæˆè½¬å½•');
        stopListening();
      }
    }, 2000);
  };

  // å¼€å§‹ç›‘å¬è¯­éŸ³
  const startListening = async () => {
    try {
      clearAllTimeouts();
      setState('listening');
      setIsRecording(true);
      setHasAudioInput(false);
      
      // è°ƒç”¨åç«¯å¼€å§‹å½•éŸ³ï¼ˆå¯ç”¨å®æ—¶æ¨¡å¼ï¼‰
      await invoke('start_voice_recording', {
        device_id: 'default',
        realtime: true
      });
      
      // è®¾ç½®æ— å£°éŸ³æ£€æµ‹è¶…æ—¶ï¼ˆ3ç§’å†…æ²¡æœ‰æ£€æµ‹åˆ°å£°éŸ³åˆ™è‡ªåŠ¨å…³é—­ï¼‰
      noSoundTimeoutRef.current = setTimeout(() => {
        console.log('æ£€æŸ¥å£°éŸ³è¾“å…¥çŠ¶æ€:', hasAudioInput);
        if (!hasAudioInput) {
          console.log('3ç§’å†…æœªæ£€æµ‹åˆ°å£°éŸ³ï¼Œè‡ªåŠ¨å…³é—­çª—å£');
          handleCancel();
        }
      }, 3000);
      
      // å¼€å§‹éŸ³é¢‘æ³¢å½¢åŠ¨ç”»
      animateWaveform();
    } catch (error) {
      console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error);
      setState('idle');
      setIsRecording(false);
    }
  };

  // åœæ­¢ç›‘å¬å¹¶å¤„ç†
  const stopListening = async () => {
    try {
      clearAllTimeouts();
      setIsRecording(false);
      
      // å¦‚æœæ²¡æœ‰éŸ³é¢‘è¾“å…¥ï¼Œç›´æ¥å…³é—­
      if (!hasAudioInput) {
        await handleCancel();
        return;
      }
      
      setState('processing');
      
      // åœæ­¢å½•éŸ³å¹¶è·å–è½¬å½•ç»“æœ
      const finalText = await invoke<string>('stop_voice_recording');
      
      if (finalText && finalText.trim()) {
        setState('injecting');
        setTranscribedText(finalText);
        
        // æ³¨å…¥æ–‡æœ¬åˆ°å½“å‰åº”ç”¨
        await invoke('inject_text_to_active_app', { text: finalText });
        
        // æ˜¾ç¤ºæˆåŠŸçŠ¶æ€åè‡ªåŠ¨å…³é—­
        autoCloseTimeoutRef.current = setTimeout(() => {
          closeWindow();
        }, 800);
      } else {
        // æ²¡æœ‰è¯†åˆ«åˆ°å†…å®¹ï¼Œç›´æ¥å…³é—­
        closeWindow();
      }
    } catch (error) {
      console.error('å¤„ç†å½•éŸ³å¤±è´¥:', error);
      setState('idle');
      closeWindow();
    }
  };

  // å–æ¶ˆæ“ä½œ
  const handleCancel = async () => {
    clearAllTimeouts();
    
    if (isRecording) {
      try {
        await invoke('stop_voice_recording');
      } catch (error) {
        console.error('åœæ­¢å½•éŸ³å¤±è´¥:', error);
      }
    }
    
    setIsRecording(false);
    setState('idle');
    closeWindow();
  };

  // å…³é—­çª—å£
  const closeWindow = async () => {
    clearAllTimeouts();
    setTranscribedText('');
    setHasAudioInput(false);
    setState('idle');
    setIsRecording(false);
    await appWindow.hide();
  };

  // éŸ³é¢‘æ³¢å½¢åŠ¨ç”»
  const animateWaveform = () => {
    if (!isRecording) return;
    
    // æ›´æ–°æ³¢å½¢åŠ¨ç”»
    const bars = containerRef.current?.querySelectorAll('.waveform-bar');
    if (bars) {
      bars.forEach((bar: any) => {
        const height = 20 + audioLevel * 30 + Math.random() * 10;
        bar.style.height = `${height}px`;
      });
    }
    
    animationRef.current = requestAnimationFrame(animateWaveform);
  };

  // è·å–åº”ç”¨å›¾æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
  const getAppIcon = () => {
    if (activeApp.icon) {
      return <img src={activeApp.icon} alt={activeApp.name} className="app-icon" />;
    }
    // é»˜è®¤å›¾æ ‡
    return <div className="app-icon-placeholder">ğŸ“</div>;
  };

  // è·å–çŠ¶æ€æ–‡æœ¬
  const getStatusText = () => {
    if (transcribedText) return transcribedText;
    
    switch (state) {
      case 'listening':
        return hasAudioInput ? 'æ­£åœ¨è†å¬...' : 'è¯·å¼€å§‹è¯´è¯...';
      case 'processing':
        return 'å¤„ç†ä¸­...';
      case 'injecting':
        return 'æ­£åœ¨è¾“å…¥...';
      default:
        return 'å‡†å¤‡å°±ç»ª';
    }
  };

  return (
    <div className="macos-voice-input" ref={containerRef}>
      <div className="voice-input-container">
        {/* å·¦ä¾§ - åº”ç”¨å›¾æ ‡å’Œä¿¡æ¯ */}
        <div className="app-info-section">
          <div className="app-icon-wrapper">
            {getAppIcon()}
          </div>
          <div className="app-name">{activeApp.name}</div>
        </div>

        {/* ä¸­é—´ - æ³¢å½¢å’Œæ–‡å­—æ˜¾ç¤º */}
        <div className="voice-content-section">
          {state === 'listening' && (
            <div className="waveform-container">
              <div className="waveform-bars">
                {[...Array(20)].map((_, i) => (
                  <div 
                    key={i} 
                    className="waveform-bar"
                    style={{
                      animationDelay: `${i * 0.05}s`
                    }}
                  />
                ))}
              </div>
              <div className={transcribedText ? 'realtime-text' : 'listening-hint'}>
                {getStatusText()}
              </div>
            </div>
          )}

          {state === 'processing' && (
            <div className="processing-container">
              <div className="processing-spinner" />
              <div className="processing-text">å¤„ç†ä¸­...</div>
            </div>
          )}

          {state === 'injecting' && (
            <div className="success-container">
              <div className="success-icon">âœ“</div>
              <div className="final-text">{transcribedText}</div>
            </div>
          )}
        </div>

        {/* å³ä¾§ - æ§åˆ¶æŒ‰é’® */}
        <div className="control-section">
          {state === 'listening' && isRecording && hasAudioInput && (
            <button 
              className="done-button"
              onClick={stopListening}
              title="å®Œæˆ (Enter)"
            >
              å®Œæˆ
            </button>
          )}
          
          <button 
            className="close-button"
            onClick={handleCancel}
            title="å…³é—­ (ESC)"
          >
            Ã—
          </button>
        </div>
      </div>

      {/* åº•éƒ¨æç¤º */}
      <div className="bottom-hint">
        <span className="hint-text">
          {hasAudioInput 
            ? 'è¯´å®Œåç‚¹å‡»"å®Œæˆ"æˆ–ç­‰å¾…è‡ªåŠ¨è¯†åˆ«' 
            : 'è¯·å¼€å§‹è¯´è¯ï¼Œ3ç§’å†…æ— å£°éŸ³å°†è‡ªåŠ¨å…³é—­'}
        </span>
      </div>
    </div>
  );
};

export default MacOSVoiceInput;