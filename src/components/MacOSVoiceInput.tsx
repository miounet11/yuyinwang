import React, { useState, useRef, useEffect } from 'react';
import { appWindow, LogicalPosition, LogicalSize } from '@tauri-apps/api/window';
import { invoke } from '@tauri-apps/api/tauri';
import { listen } from '@tauri-apps/api/event';
// Removed complex framer-motion dependencies for better performance
import { 
  startPerformanceMonitoring, 
  stopPerformanceMonitoring, 
  measureVoiceInputLatency 
} from '../utils/performanceMonitor';
import './MacOSVoiceInput.css';

interface ActiveAppInfo {
  name: string;
  icon?: string;
  bundleId?: string;
}

type InputState = 'idle' | 'listening' | 'processing' | 'injecting';

const MacOSVoiceInput: React.FC = () => {
  const [state, setState] = useState<InputState>('idle');
  const [transcribedText, setTranscribedText] = useState('');
  const [activeApp, setActiveApp] = useState<ActiveAppInfo>({ name: 'æœªçŸ¥åº”ç”¨' });
  const [audioLevel, setAudioLevel] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [hasAudioInput, setHasAudioInput] = useState(false);
  const [currentModel, setCurrentModel] = useState<string>('loading...'); // å½“å‰ä½¿ç”¨çš„æ¨¡å‹
  const [isProcessing, setIsProcessing] = useState(false); // é˜²æ­¢é‡å¤å¤„ç†
  const [isProcessingTrigger, setIsProcessingTrigger] = useState(false); // é˜²æ­¢é‡å¤è§¦å‘äº‹ä»¶
  
  const containerRef = useRef<HTMLDivElement>(null);
  const animationRef = useRef<number>();
  const noSoundTimeoutRef = useRef<number | null>(null);
  const silenceTimeoutRef = useRef<number | null>(null);
  const autoCloseTimeoutRef = useRef<number | null>(null);
  const processingTimeoutRef = useRef<number | null>(null);  // å¤„ç†è¶…æ—¶
  const retryCountRef = useRef<number>(0);  // é‡è¯•è®¡æ•°
  
  // æ™ºèƒ½VADçŠ¶æ€è¿½è¸ª
  const lastSoundTimeRef = useRef<number>(Date.now());
  const recordingStartTimeRef = useRef<number>(0);
  const continuousSilenceDurationRef = useRef<number>(0);
  
  // éŸ³é¢‘åˆ†æå’Œè‡ªé€‚åº”å‚æ•°
  const audioLevelHistoryRef = useRef<number[]>([]);
  const noiseFloorRef = useRef<number>(0.03);  // åˆå§‹å™ªéŸ³åŸºçº¿è®¾ä¸º0.03ï¼ˆé€‚åº”æ–°çš„èŒƒå›´ï¼‰
  const smoothedLevelRef = useRef<number>(0);
  const vadStateRef = useRef<'waiting' | 'speech' | 'silence'>('waiting');
  const speechDetectedRef = useRef<boolean>(false);
  

  useEffect(() => {
      // Simplified audio level handling without complex animator
    
    // è·å–å½“å‰æ¨¡å‹ä¿¡æ¯
    const fetchModelInfo = async () => {
      try {
        const model = await invoke<string>('get_current_model_info');
        setCurrentModel(model);
      } catch (error) {
        setCurrentModel('unknown');
      }
    };
    fetchModelInfo();
    
    // è®¾ç½®çª—å£å±æ€§ - æ¨¡æ‹Ÿ macOS åŸç”Ÿæ ·å¼
    const setupWindow = async () => {
      
      await appWindow.setAlwaysOnTop(true);
      await appWindow.setDecorations(false);
      await appWindow.setResizable(false);
      await appWindow.setSkipTaskbar(true);
      
      // è®¾ç½®çª—å£å¤§å°å’Œä½ç½® - åƒ macOS è¯­éŸ³è¾“å…¥ä¸€æ ·å°å·§
      await appWindow.setSize(new LogicalSize(280, 60));
      
      // å±…ä¸­æ˜¾ç¤ºåœ¨å±å¹•åº•éƒ¨
      try {
        const screenWidth = window.screen.width;
        const screenHeight = window.screen.height;
        const x = Math.floor((screenWidth - 280) / 2);
        const y = Math.floor(screenHeight - 100); // å±å¹•åº•éƒ¨ä½ç½®
        await appWindow.setPosition(new LogicalPosition(x, y));
      } catch (error) {
      }

      // åˆå§‹åŒ–æ—¶ä¸è·å–æ´»åŠ¨åº”ç”¨ï¼Œç­‰å¾…äº‹ä»¶è§¦å‘æ—¶ä¼ é€’
      // æ´»åŠ¨åº”ç”¨ä¿¡æ¯å°†ç”±å¿«æ·é”®è§¦å‘æ—¶ä¼ é€’
    };
    
    setupWindow();

    // ç›‘å¬è¯­éŸ³è¾“å…¥è§¦å‘äº‹ä»¶
    const unlistenTrigger = listen<ActiveAppInfo>('voice_input_triggered', async (event) => {
      // é˜²æ­¢é‡å¤è§¦å‘
      if (isProcessingTrigger) {
        return;
      }
      
      setIsProcessingTrigger(true);
      
      setState('idle');
      setTranscribedText('');
      setHasAudioInput(false);
      
      // ä½¿ç”¨äº‹ä»¶ä¸­ä¼ é€’çš„æ´»åŠ¨åº”ç”¨ä¿¡æ¯ï¼ˆè¿™æ˜¯è§¦å‘å‰çš„åŸå§‹æ´»åŠ¨åº”ç”¨ï¼‰
      if (event.payload && event.payload.name) {
        setActiveApp(event.payload);
      } else {
        // å¦‚æœæ²¡æœ‰ä¼ é€’æ´»åŠ¨åº”ç”¨ä¿¡æ¯ï¼Œåˆ™å°è¯•è·å–ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        try {
          const appInfo = await invoke<ActiveAppInfo>('get_active_app_info_for_voice');
          setActiveApp(appInfo);
        } catch (error) {
        }
      }
      
      // æ˜¾ç¤ºçª—å£å¹¶è‡ªåŠ¨å¼€å§‹å½•éŸ³ï¼ˆæŒ‰ä½äº‹ä»¶åˆ°æ¥æ—¶å†çœŸæ­£å¼€å§‹ï¼‰
      await appWindow.show();
      await appWindow.setFocus();
      
      // å…è®¸åç»­è§¦å‘
      setTimeout(() => {
        setIsProcessingTrigger(false);
      }, 300);
    });

    // æ–°å¢ï¼šç›‘å¬é•¿æŒ‰å¼€å§‹/ç»“æŸäº‹ä»¶ï¼ˆæ¥è‡ªåŸç”Ÿ Fn/F1 ç›‘å¬ï¼‰
    const unlistenHoldStart = listen('voice_input_hold_start', () => {
      if (!isRecording) {
        startListening();
      }
    });
    const unlistenHoldEnd = listen('voice_input_hold_end', () => {
      if (isRecording) {
        stopListening();
      }
    });

    // ç›‘å¬å®æ—¶è½¬å½•ç»“æœï¼ˆæ¸è¿›å¼éƒ¨åˆ†ï¼‰
    const unlistenStreaming = listen<any>('streaming_transcription', (event) => {
      const payload: any = event.payload || {};
      const text: string = payload.text || '';
      setTranscribedText(text);
      if (text && text.trim()) {
        setHasAudioInput(true);
        resetSilenceTimeout();
      }
    });

    // ç›‘å¬æµå¼å®Œæˆï¼ˆå¯ç”¨äºæ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€ï¼‰
    const unlistenStreamingComplete = listen<string>('streaming_complete', () => {
      // ä¿æŒ stopListening é€»è¾‘ä¸»å¯¼ï¼Œå®Œæˆäº‹ä»¶ä»…ç”¨äº UI æç¤º
    });

    // æ™ºèƒ½VADéŸ³é¢‘ç”µå¹³ç›‘å¬ - å¤šå±‚æ£€æµ‹ç®—æ³• + åŠ¨ç”»é›†æˆ
    const unlistenAudioLevel = listen<number>('audio_level', (event) => {
      const rawLevel = event.payload;
      const now = Date.now();
      
      // Direct audio level update for better performance
      
      // ğŸ¯ VAD é…ç½®å‚æ•° - é€‚é…æ–°çš„éŸ³é¢‘ç”µå¹³èŒƒå›´
      const VAD_CONFIG = {
        // é˜ˆå€¼è®¾ç½®ï¼ˆæ ¹æ®æ–°çš„RMSè®¡ç®—æ–¹æ³•è°ƒæ•´ï¼‰
        SOUND_THRESHOLD: 0.15,        // ä¸»å£°éŸ³é˜ˆå€¼ï¼ˆæ­£å¸¸è¯´è¯çº¦0.1-0.3ï¼‰
        SILENCE_THRESHOLD: 0.05,      // é™éŸ³é˜ˆå€¼ï¼ˆç¯å¢ƒå™ªéŸ³é€šå¸¸<0.05ï¼‰
        NOISE_GATE: 0.02,             // å™ªéŸ³é—¨é™ï¼ˆæä½èƒŒæ™¯å™ªéŸ³ï¼‰
        
        // æ—¶é—´æ§åˆ¶
        MIN_SPEECH_DURATION: 500,     // æœ€çŸ­æœ‰æ•ˆè¯­éŸ³æ—¶é•¿ï¼ˆå‡å°‘åˆ°500msï¼Œæ›´çµæ•ï¼‰
        SILENCE_DURATION: 1500,       // é™éŸ³ç­‰å¾…æ—¶é—´ï¼ˆ1.5ç§’ï¼‰
        CONFIRMATION_DELAY: 200,      // ç¡®è®¤å»¶è¿Ÿï¼ˆ200msï¼‰
        
        // è‡ªé€‚åº”å‚æ•°
        LEVEL_SMOOTHING: 0.4,         // éŸ³é¢‘ç”µå¹³å¹³æ»‘ç³»æ•°ï¼ˆå¢åŠ å¹³æ»‘åº¦ï¼‰
        NOISE_FLOOR_SAMPLES: 50,      // å™ªéŸ³åŸºçº¿é‡‡æ ·æ•°é‡ï¼ˆå¢åŠ æ ·æœ¬æ•°ï¼‰
      };
      
      // ğŸ“ˆ éŸ³é¢‘ç”µå¹³å¹³æ»‘å¤„ç†
      smoothedLevelRef.current = smoothedLevelRef.current * (1 - VAD_CONFIG.LEVEL_SMOOTHING) + 
                                rawLevel * VAD_CONFIG.LEVEL_SMOOTHING;
      const level = smoothedLevelRef.current;
      setAudioLevel(level);
      
      // ğŸ“Š å™ªéŸ³åŸºçº¿è‡ªé€‚åº”å­¦ä¹ 
      audioLevelHistoryRef.current.push(level);
      if (audioLevelHistoryRef.current.length > VAD_CONFIG.NOISE_FLOOR_SAMPLES) {
        audioLevelHistoryRef.current.shift();
        // è®¡ç®—å™ªéŸ³åŸºçº¿ï¼ˆå–å†å²æ•°æ®çš„25%åˆ†ä½æ•°ï¼‰
        const sorted = [...audioLevelHistoryRef.current].sort((a, b) => a - b);
        noiseFloorRef.current = sorted[Math.floor(sorted.length * 0.25)];
      }
      
      // ğŸ¤ åŠ¨æ€é˜ˆå€¼è®¡ç®—ï¼ˆåŸºäºå™ªéŸ³åŸºçº¿ï¼‰
      const dynamicThreshold = Math.max(
        VAD_CONFIG.SOUND_THRESHOLD, 
        noiseFloorRef.current * 2.5  // è¯­éŸ³åº”è¯¥æ¯”å™ªéŸ³é«˜2.5å€
      );
      
      const dynamicSilenceThreshold = Math.max(
        VAD_CONFIG.SILENCE_THRESHOLD,
        noiseFloorRef.current * 1.2  // é™éŸ³é˜ˆå€¼ç•¥é«˜äºå™ªéŸ³åŸºçº¿
      );
      
      // ğŸ§  VAD çŠ¶æ€æœºé€»è¾‘
      const isSound = level > dynamicThreshold;
      const isSilence = level < dynamicSilenceThreshold;
      
      if (isSound) {
        // ğŸ”Š æ£€æµ‹åˆ°å£°éŸ³
        lastSoundTimeRef.current = now;
        
        // çŠ¶æ€è½¬æ¢ï¼šwaiting -> speech æˆ–ä¿æŒ speech
        if (vadStateRef.current !== 'speech') {
          vadStateRef.current = 'speech';
          speechDetectedRef.current = true;
          
          if (!hasAudioInput) {
            setHasAudioInput(true);
            
            // æ¸…é™¤æ— å£°éŸ³è¶…æ—¶
            if (noSoundTimeoutRef.current) {
              clearTimeout(noSoundTimeoutRef.current);
              noSoundTimeoutRef.current = null;
            }
          }
        }
        
        // æ¸…é™¤é™éŸ³æ£€æµ‹å®šæ—¶å™¨
        if (silenceTimeoutRef.current) {
          clearTimeout(silenceTimeoutRef.current);
          silenceTimeoutRef.current = null;
        }
        
        // é‡ç½®é™éŸ³è®¡æ—¶
        continuousSilenceDurationRef.current = 0;
        
      } else if (isSilence && speechDetectedRef.current) {
        // ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼ˆä½†ä¹‹å‰æœ‰è¿‡è¯­éŸ³ï¼‰
        const silenceDuration = now - lastSoundTimeRef.current;
        continuousSilenceDurationRef.current = silenceDuration;
        
        // çŠ¶æ€è½¬æ¢ï¼šspeech -> silence
        if (vadStateRef.current === 'speech') {
          vadStateRef.current = 'silence';
        }
        
        // å½•éŸ³æ—¶é—´æ£€æŸ¥
        if (hasAudioInput && isRecording) {
          const recordingDuration = now - recordingStartTimeRef.current;
          
          // æ»¡è¶³æœ€çŸ­è¯­éŸ³æ—¶é•¿è¦æ±‚
          if (recordingDuration > VAD_CONFIG.MIN_SPEECH_DURATION) {
            // é™éŸ³æŒç»­è¶³å¤Ÿé•¿æ—¶é—´
            if (silenceDuration > VAD_CONFIG.SILENCE_DURATION && !silenceTimeoutRef.current) {
              
              // ç¡®è®¤å»¶è¿Ÿï¼Œé¿å…è¯¯è§¦å‘
              silenceTimeoutRef.current = setTimeout(() => {
                const currentSilence = Date.now() - lastSoundTimeRef.current;
                if (isRecording && currentSilence > VAD_CONFIG.SILENCE_DURATION) {
                  stopListening();
                }
              }, VAD_CONFIG.CONFIRMATION_DELAY);
            }
          }
        }
        
      } else {
        // ğŸ“Š ä¸­é—´çŠ¶æ€ï¼ˆä»‹äºå£°éŸ³å’Œé™éŸ³ä¹‹é—´ï¼‰
        // åœ¨ä¸­é—´çŠ¶æ€æ—¶ï¼Œå¦‚æœæ­£åœ¨è¯´è¯ä¸­ï¼Œåº”è¯¥é‡ç½®é™éŸ³è®¡æ—¶
        if (vadStateRef.current === 'speech') {
          // è¿˜åœ¨è¯´è¯èŒƒå›´å†…ï¼Œé‡ç½®é™éŸ³è®¡æ—¶
          lastSoundTimeRef.current = now;
          continuousSilenceDurationRef.current = 0;
          
          // æ¸…é™¤é™éŸ³æ£€æµ‹å®šæ—¶å™¨
          if (silenceTimeoutRef.current) {
            clearTimeout(silenceTimeoutRef.current);
            silenceTimeoutRef.current = null;
          }
        } else {
          // çœŸæ­£çš„é™éŸ³çŠ¶æ€
          const silenceDuration = now - lastSoundTimeRef.current;
          continuousSilenceDurationRef.current = silenceDuration;
        }
      }
      
    });

    // ç›‘å¬ ESC é”®å…³é—­çª—å£
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.key === 'Escape') {
        handleCancel();
      }
      // ç§»é™¤ Enter é”®è§¦å‘ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯å…¨è‡ªåŠ¨çš„
    };
    document.addEventListener('keydown', handleKeyDown);

    return () => {
      unlistenTrigger.then(fn => fn());
      unlistenHoldStart.then(fn => fn());
      unlistenHoldEnd.then(fn => fn());
      unlistenStreaming.then(fn => fn());
      unlistenStreamingComplete.then(fn => fn());
      unlistenAudioLevel.then(fn => fn());
      document.removeEventListener('keydown', handleKeyDown);
      clearAllTimeouts();
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
      stopPerformanceMonitoring();
    };
  }, [hasAudioInput, isRecording]);

  // æ¸…ç†æ‰€æœ‰è¶…æ—¶
  const clearAllTimeouts = () => {
    if (noSoundTimeoutRef.current) {
      clearTimeout(noSoundTimeoutRef.current);
      noSoundTimeoutRef.current = null;
    }
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
    if (autoCloseTimeoutRef.current) {
      clearTimeout(autoCloseTimeoutRef.current);
      autoCloseTimeoutRef.current = null;
    }
    if (processingTimeoutRef.current) {
      clearTimeout(processingTimeoutRef.current);
      processingTimeoutRef.current = null;
    }
  };

  // é‡ç½®é™éŸ³è¶…æ—¶ï¼ˆä¿ç•™ä½†ç®€åŒ–ï¼Œä¸»è¦é€»è¾‘åœ¨éŸ³é¢‘ç”µå¹³ç›‘å¬ä¸­ï¼‰
  const resetSilenceTimeout = () => {
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
  };

  // å¼€å§‹ç›‘å¬è¯­éŸ³
  const startListening = async () => {
    const startTime = performance.now();
    
    try {
      clearAllTimeouts();
      setState('listening');
      setIsRecording(true);
      setHasAudioInput(false);
      
      // å¯åŠ¨æ€§èƒ½ç›‘æ§
      startPerformanceMonitoring();
      
      // ğŸ”„ é‡ç½®VADçŠ¶æ€å’Œé”™è¯¯å¤„ç†çŠ¶æ€
      recordingStartTimeRef.current = Date.now();
      lastSoundTimeRef.current = Date.now();
      continuousSilenceDurationRef.current = 0;
      speechDetectedRef.current = false;
      vadStateRef.current = 'waiting';
      smoothedLevelRef.current = 0;
      audioLevelHistoryRef.current = [];
      noiseFloorRef.current = 0.03;  // é‡ç½®ä¸ºåˆç†çš„åˆå§‹å™ªéŸ³åŸºçº¿
      retryCountRef.current = 0;  // é‡ç½®é‡è¯•è®¡æ•°
      
      
      // è°ƒç”¨åç«¯å¼€å§‹å½•éŸ³ï¼ˆå¯ç”¨å®æ—¶æ¨¡å¼ï¼‰
      await invoke('start_voice_recording', {
        deviceId: 'default',  // ä¿®å¤ï¼šä½¿ç”¨é©¼å³°å‘½å deviceId è€Œä¸æ˜¯ device_id
        realtime: true
      });
      
      // è®¾ç½®æ— å£°éŸ³æ£€æµ‹è¶…æ—¶ï¼ˆ5ç§’å†…æ²¡æœ‰æ£€æµ‹åˆ°å£°éŸ³åˆ™è‡ªåŠ¨å…³é—­ï¼‰
      noSoundTimeoutRef.current = setTimeout(() => {
        if (!hasAudioInput) {
          handleCancel();
        }
      }, 5000);
      
      // å¼€å§‹éŸ³é¢‘ååº”åŠ¨ç”» - ç°åœ¨é€šè¿‡ Motion ç»„ä»¶å¤„ç†
      // animateWaveform(); // ç§»é™¤æ—§åŠ¨ç”»ï¼Œä½¿ç”¨æ–°çš„ Motion ç³»ç»Ÿ
      
      // æµ‹é‡è¯­éŸ³è¾“å…¥å¯åŠ¨å»¶è¿Ÿ
      measureVoiceInputLatency(startTime);
    } catch (error) {
      setState('idle');
      setIsRecording(false);
    }
  };

  // åœæ­¢ç›‘å¬å¹¶å¤„ç†
  const stopListening = async () => {
    // é˜²æ­¢é‡å¤è°ƒç”¨
    if (isProcessing) {
      return;
    }
    
    setIsProcessing(true);
    
    try {
      clearAllTimeouts();
      setIsRecording(false);
      
      // å¦‚æœæ²¡æœ‰éŸ³é¢‘è¾“å…¥ï¼Œç›´æ¥å…³é—­
      if (!hasAudioInput) {
        await handleCancel();
        return;
      }
      
      setState('processing');
      
      // è®¾ç½®å¤„ç†è¶…æ—¶ - 8ç§’åè‡ªåŠ¨é‡è¯•æˆ–å¤±è´¥
      processingTimeoutRef.current = setTimeout(async () => {
        retryCountRef.current++;
        
        if (retryCountRef.current <= 2) {
          // æœ€å¤šé‡è¯•2æ¬¡
          setTranscribedText(`é‡è¯•ä¸­... (${retryCountRef.current}/2)`);
          
          try {
            // å†æ¬¡å°è¯•åœæ­¢å½•éŸ³
            const retryText = await invoke<string>('stop_voice_recording');
            
            // æ¸…é™¤è¶…æ—¶
            if (processingTimeoutRef.current) {
              clearTimeout(processingTimeoutRef.current);
              processingTimeoutRef.current = null;
            }
            
            if (retryText && retryText.trim()) {
              setState('injecting');
              setTranscribedText(retryText);
              
              // å…ˆéšè—çª—å£ï¼Œæ¢å¤åŸå§‹åº”ç”¨ç„¦ç‚¹ï¼Œç„¶åæ³¨å…¥æ–‡æœ¬
              await appWindow.hide();
              await new Promise(resolve => setTimeout(resolve, 300));
              
              // å¦‚æœæœ‰åŸå§‹åº”ç”¨ä¿¡æ¯ï¼Œæ¿€æ´»å®ƒ
              if (activeApp && activeApp.bundleId) {
                await invoke('activate_app_by_bundle_id', { bundleId: activeApp.bundleId });
                await new Promise(resolve => setTimeout(resolve, 500));
              }
              
              await invoke('inject_text_to_active_app', { 
                text: retryText, 
                targetBundleId: activeApp.bundleId 
              });
              
              // çª—å£å·²éšè—ï¼Œç›´æ¥æ¸…ç†çŠ¶æ€
              setTimeout(() => {
                setTranscribedText('');
                setHasAudioInput(false);
                setState('idle');
                setIsProcessing(false);
                setIsProcessingTrigger(false);
              }, 100);
            } else {
              closeWindow();
            }
          } catch (retryError) {
            // ç»§ç»­ç­‰å¾…ä¸‹ä¸€æ¬¡è¶…æ—¶é‡è¯•
          }
        } else {
          // é‡è¯•æ¬¡æ•°ç”¨å®Œï¼Œä¼˜é›…å¤±è´¥
          setState('idle');
          setTranscribedText('å¤„ç†è¶…æ—¶ï¼Œæ“ä½œå·²å–æ¶ˆ');
          setTimeout(() => {
            closeWindow();
          }, 2000);
        }
      }, 8000); // 8ç§’è¶…æ—¶
      
      // å°è¯•åœæ­¢å½•éŸ³å¹¶è·å–è½¬å½•ç»“æœ
      const finalText = await invoke<string>('stop_voice_recording');
      
      // å¦‚æœæˆåŠŸå®Œæˆï¼Œæ¸…é™¤è¶…æ—¶
      if (processingTimeoutRef.current) {
        clearTimeout(processingTimeoutRef.current);
        processingTimeoutRef.current = null;
      }
      
      
      if (finalText && finalText.trim()) {
        setState('injecting');
        setTranscribedText(finalText);
        
        // å…ˆéšè—çª—å£
        await appWindow.hide();
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿çª—å£å®Œå…¨éšè—
        await new Promise(resolve => setTimeout(resolve, 300));
        
        // å¦‚æœæœ‰åŸå§‹åº”ç”¨ä¿¡æ¯ï¼Œæ¿€æ´»å®ƒ
        if (activeApp && activeApp.bundleId) {
          try {
            await invoke('activate_app_by_bundle_id', { bundleId: activeApp.bundleId });
            // å¢åŠ ç­‰å¾…æ—¶é—´ç¡®ä¿åº”ç”¨å®Œå…¨æ¿€æ´»
            await new Promise(resolve => setTimeout(resolve, 800));
          } catch (error) {
            // æ¿€æ´»å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ
          }
        }
        
        // æ³¨å…¥æ–‡æœ¬åˆ°å½“å‰æ´»åŠ¨åº”ç”¨
        try {
          await invoke('inject_text_to_active_app', { 
            text: finalText, 
            targetBundleId: activeApp.bundleId 
          });
          
          // é¢å¤–éªŒè¯ï¼šç­‰å¾…ä¸€ä¸‹çœ‹æ˜¯å¦çœŸçš„æˆåŠŸ
          await new Promise(resolve => setTimeout(resolve, 300));
        } catch (error) {
          throw error; // é‡æ–°æŠ›å‡ºé”™è¯¯ä»¥ä¾¿ä¸Šå±‚å¤„ç†
        }
        
        // çª—å£å·²éšè—ï¼Œç›´æ¥æ¸…ç†çŠ¶æ€
        setTimeout(() => {
          setTranscribedText('');
          setHasAudioInput(false);
          setState('idle');
          setIsProcessing(false);
          setIsProcessingTrigger(false);
        }, 100);
      } else {
        // æ²¡æœ‰è¯†åˆ«åˆ°å†…å®¹ï¼Œæ˜¾ç¤ºå¤±è´¥
        setState('idle');
        setTranscribedText('æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹');
        
        // ä¸å†é‡è¯•stop_voice_recordingï¼Œå› ä¸ºå½•éŸ³å·²åœæ­¢
        setTimeout(() => {
          closeWindow();
        }, 2000);
            
        // åˆ é™¤é‡è¯•é€»è¾‘ï¼Œé¿å…é‡å¤è°ƒç”¨
      }
    } catch (error) {
      setIsProcessing(false);
      // æ¸…é™¤å¤„ç†è¶…æ—¶
      if (processingTimeoutRef.current) {
        clearTimeout(processingTimeoutRef.current);
        processingTimeoutRef.current = null;
      }
      
      
      // å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œä¸ç›´æ¥å¤±è´¥
      retryCountRef.current++;
      if (retryCountRef.current <= 2) {
        setState('processing');
        setTranscribedText(`é”™è¯¯æ¢å¤ä¸­... (${retryCountRef.current}/2)`);
        
        // å»¶è¿Ÿé‡è¯•
        setTimeout(() => {
          stopListening();
        }, 1000);
      } else {
        setState('idle');
        setTranscribedText('è½¬å½•å¤±è´¥ï¼Œè¯·é‡è¯•');
        setTimeout(() => {
          closeWindow();
        }, 2000);
      }
    }
  };

  // å–æ¶ˆæ“ä½œ
  const handleCancel = async () => {
    clearAllTimeouts();
    stopPerformanceMonitoring();
    
    if (isRecording) {
      try {
        await invoke('stop_voice_recording');
      } catch (error) {
      }
    }
    
    setIsRecording(false);
    setState('idle');
    closeWindow();
  };

  // å…³é—­çª—å£
  const closeWindow = async () => {
    clearAllTimeouts();
    setTranscribedText('');
    setHasAudioInput(false);
    setState('idle');
    setIsRecording(false);
    setIsProcessing(false);
    setIsProcessingTrigger(false); // é‡ç½®è§¦å‘æ ‡å¿—
    await appWindow.hide();
  };

  // è·å–åº”ç”¨å›¾æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
  const getAppIcon = () => {
    if (activeApp.icon) {
      return <img src={activeApp.icon} alt={activeApp.name} className="app-icon" />;
    }
    // é»˜è®¤å›¾æ ‡
    return <div className="app-icon-placeholder">ğŸ“</div>;
  };

  // è·å–çŠ¶æ€æ–‡æœ¬
  const getStatusText = () => {
    // åªæ˜¾ç¤ºçœŸå®çš„è½¬å½•æ–‡æœ¬ï¼Œä¸æ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®
    if (transcribedText && transcribedText !== 'ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„') {
      return transcribedText;
    }
    
    switch (state) {
      case 'listening':
        return hasAudioInput ? 'æ­£åœ¨è†å¬...' : 'è¯·å¼€å§‹è¯´è¯...';
      case 'processing':
        return 'æ­£åœ¨è½¬å½•...';
      case 'injecting':
        return 'æ­£åœ¨è¾“å…¥åˆ°ç›®æ ‡åº”ç”¨...';
      default:
        return '';
    }
  };

  return (
    <div className="macos-voice-input" ref={containerRef}>
      <div 
        className={`voice-input-container ${state === 'listening' ? 'listening' : ''} ${state === 'processing' ? 'processing' : ''} ${state === 'injecting' ? 'success' : ''}`}
      >
        {/* Audio level indicator for reactive effects */}
        <div 
          className="audio-level-indicator" 
          style={{
            opacity: audioLevel > 0.1 ? audioLevel : 0,
            transform: `scale(${1 + audioLevel * 0.2})`
          }}
        />
        
        {/* å·¦ä¾§ - åº”ç”¨å›¾æ ‡å’Œä¿¡æ¯ */}
        <div className="app-info-section">
          <div className="app-icon-wrapper">
            {getAppIcon()}
          </div>
          <div className="app-name">{activeApp.name}</div>
        </div>

        {/* ä¸­é—´ - æ³¢å½¢å’Œæ–‡å­—æ˜¾ç¤º */}
        <div className="voice-content-section">
          {state === 'listening' && (
            <div className="waveform-container">
              <div className="waveform-bars">
                {Array.from({ length: 8 }, (_, i) => (
                  <div 
                    key={i}
                    className="waveform-bar"
                    style={{
                      height: isRecording ? `${8 + audioLevel * 12 + Math.random() * 4}px` : '4px',
                      animationDelay: `${i * 0.1}s`
                    }}
                  />
                ))}
              </div>
              <div className={transcribedText ? 'realtime-text' : 'listening-hint'}>
                {getStatusText()}
              </div>
            </div>
          )}

          {state === 'processing' && (
            <div className="processing-container">
              <div className="processing-spinner" />
              <div className="processing-text">
                <span>å¤„ç†ä¸­</span>
                <span className="processing-dots"></span>
              </div>
            </div>
          )}

          {state === 'injecting' && (
            <div className="success-container">
              <div className="success-icon">âœ“</div>
              <div className="final-text">{transcribedText}</div>
            </div>
          )}
        </div>

        {/* å³ä¾§ - æ§åˆ¶æŒ‰é’® */}
        <div className="control-section">
          <button 
            className="close-button"
            onClick={handleCancel}
            title="å–æ¶ˆ (ESC)"
            disabled={isProcessing}
          >
            Ã—
          </button>
        </div>
      </div>

      {/* åº•éƒ¨æç¤º */}
      <div className="bottom-hint">
        <span className="hint-text">
          {hasAudioInput 
            ? 'æ­£åœ¨è†å¬ï¼Œè¯´å®Œè¯·ç¨å€™...' 
            : 'è¯·å¼€å§‹è¯´è¯'}
        </span>
      </div>
    </div>
  );
};

export default MacOSVoiceInput;
