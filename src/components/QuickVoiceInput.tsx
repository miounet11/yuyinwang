import React, { useState, useEffect, useRef } from 'react';
import { invoke } from '@tauri-apps/api/tauri';
import { appWindow, LogicalSize, LogicalPosition } from '@tauri-apps/api/window';
import { listen } from '@tauri-apps/api/event';
import './QuickVoiceInput.css';

interface QuickVoiceInputProps {
  onClose?: () => void;
  onTextReady?: (text: string) => void;
}

const QuickVoiceInput: React.FC<QuickVoiceInputProps> = ({ onClose, onTextReady }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [transcriptionText, setTranscriptionText] = useState('');
  const [audioLevel, setAudioLevel] = useState(0);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [error, setError] = useState('');
  
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const startTimeRef = useRef<number>(0);
  const containerRef = useRef<HTMLDivElement>(null);
  const silenceStartRef = useRef<number>(0);
  const lastAudioLevelRef = useRef<number>(0);

  useEffect(() => {
    // è®¾ç½®çª—å£å±æ€§
    const setupWindow = async () => {
      try {
        // è®¾ç½®çª—å£å§‹ç»ˆåœ¨æœ€å‰
        await appWindow.setAlwaysOnTop(true);
        // è®¾ç½®çª—å£è£…é¥°ï¼ˆæ— æ ‡é¢˜æ ï¼‰
        await appWindow.setDecorations(false);
        // è®¾ç½®çª—å£å¤§å°
        await appWindow.setSize(new LogicalSize(400, 150));
        
        // è·å–å±å¹•å°ºå¯¸å¹¶å±…ä¸­æ˜¾ç¤º
        const screenSize = await appWindow.currentMonitor();
        if (screenSize) {
          const screenWidth = screenSize.size.width;
          const screenHeight = screenSize.size.height;
          // å›ºå®šåœ¨å±å¹•ä¸­é—´ä½ç½®
          const x = Math.floor(screenWidth / 2 - 200);
          const y = Math.floor(screenHeight / 2 - 75);
          await appWindow.setPosition(new LogicalPosition(x, y));
        } else {
          // å¦‚æœæ— æ³•è·å–å±å¹•å°ºå¯¸ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®
          await appWindow.setPosition(new LogicalPosition(window.screen.width / 2 - 200, window.screen.height / 2 - 75));
        }
      } catch (error) {
        console.error('è®¾ç½®çª—å£å±æ€§å¤±è´¥:', error);
      }
    };

    setupWindow();
    
    // è‡ªåŠ¨å¼€å§‹å½•éŸ³
    startRecording();

    // ç›‘å¬å¿«æ·é”®é‡Šæ”¾äº‹ä»¶ï¼ˆåœæ­¢å½•éŸ³ï¼‰
    const unlistenKeyRelease = listen('quick_voice_key_released', () => {
      if (isRecording) {
        stopRecording();
      }
    });

    // ç›‘å¬ESCé”®å…³é—­çª—å£
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.key === 'Escape') {
        handleClose();
      }
    };
    document.addEventListener('keydown', handleKeyDown);

    return () => {
      unlistenKeyRelease.then(fn => fn());
      document.removeEventListener('keydown', handleKeyDown);
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      // ç¡®ä¿åœ¨ç»„ä»¶å¸è½½æ—¶åœæ­¢å½•éŸ³
      if (isRecording) {
        invoke('stop_recording').catch(console.error);
      }
    };
  }, [isRecording]); // Add isRecording to dependencies

  const startRecording = async () => {
    try {
      // å…ˆå°è¯•åœæ­¢ä»»ä½•ç°æœ‰çš„å½•éŸ³
      try {
        await invoke('stop_recording');
      } catch (e) {
        // å¿½ç•¥é”™è¯¯ï¼Œå¯èƒ½æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„å½•éŸ³
      }
      
      setError('');
      setIsRecording(true);
      setTranscriptionText('');
      startTimeRef.current = Date.now();
      
      // å¯åŠ¨å½•éŸ³ï¼Œä½¿ç”¨é»˜è®¤è®¾å¤‡
      await invoke('start_recording', {
        deviceId: "default"  // ä½¿ç”¨é»˜è®¤è®¾å¤‡è€Œä¸æ˜¯null
      });

      // å¯åŠ¨è®¡æ—¶å™¨å’ŒéŸ³é¢‘ç”µå¹³ç›‘æ§
      timerRef.current = setInterval(async () => {
        const duration = (Date.now() - startTimeRef.current) / 1000;
        setRecordingDuration(duration);
        
        // è·å–å®é™…éŸ³é¢‘ç”µå¹³
        let currentLevel = 0;
        try {
          currentLevel = await invoke<number>('get_audio_level');
          setAudioLevel(Math.min(1.0, currentLevel));
        } catch {
          // å¦‚æœæ— æ³•è·å–éŸ³é¢‘ç”µå¹³ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå€¼
          currentLevel = Math.random() * 0.5 + 0.3;
          setAudioLevel(currentLevel);
        }
        
        // é™éŸ³æ£€æµ‹ï¼ˆVAD - Voice Activity Detectionï¼‰
        const SILENCE_THRESHOLD = 0.02; // é™éŸ³é˜ˆå€¼
        const SILENCE_DURATION = 2000; // 2ç§’é™éŸ³åè‡ªåŠ¨åœæ­¢
        
        if (currentLevel < SILENCE_THRESHOLD) {
          if (silenceStartRef.current === 0) {
            silenceStartRef.current = Date.now();
          } else if (Date.now() - silenceStartRef.current > SILENCE_DURATION) {
            // æ£€æµ‹åˆ°æŒç»­é™éŸ³ï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³
            console.log('æ£€æµ‹åˆ°é™éŸ³ï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³');
            stopRecording();
          }
        } else {
          // æ£€æµ‹åˆ°å£°éŸ³ï¼Œé‡ç½®é™éŸ³è®¡æ—¶å™¨
          silenceStartRef.current = 0;
        }
        
        lastAudioLevelRef.current = currentLevel;
      }, 100);
    } catch (error) {
      console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error);
      setError(`å½•éŸ³å¤±è´¥: ${error}`);
      setIsRecording(false);
    }
  };

  const stopRecording = async () => {
    try {
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }

      setIsRecording(false);
      setIsTranscribing(true);
      setAudioLevel(0);

      // åœæ­¢å½•éŸ³å¹¶è·å–è½¬å½•
      const result = await invoke<string>('stop_recording_and_transcribe', {
        model: 'luyingwang-online'
      });

      setIsTranscribing(false);
      setTranscriptionText(result);

      // è‡ªåŠ¨æ’å…¥æ–‡æœ¬åˆ°å½“å‰åº”ç”¨
      if (result) {
        // è°ƒç”¨åç«¯æ’å…¥æ–‡æœ¬åˆ°å½“å‰åº”ç”¨
        try {
          await invoke('insert_text_to_app', { text: result });
          console.log('æ–‡æœ¬å·²æ’å…¥åˆ°å½“å‰åº”ç”¨');
        } catch (error) {
          console.error('æ’å…¥æ–‡æœ¬å¤±è´¥:', error);
        }
        
        // å¦‚æœæœ‰å›è°ƒï¼Œä¹Ÿè°ƒç”¨å›è°ƒ
        if (onTextReady) {
          onTextReady(result);
        }
        
        // æ’å…¥æ–‡æœ¬åè‡ªåŠ¨å…³é—­
        setTimeout(() => {
          handleClose();
        }, 500);
      }
    } catch (error) {
      console.error('åœæ­¢å½•éŸ³å¤±è´¥:', error);
      setError(`è½¬å½•å¤±è´¥: ${error}`);
      setIsTranscribing(false);
    }
  };

  const handleClose = () => {
    if (isRecording) {
      invoke('stop_recording').catch(console.error);
    }
    if (onClose) {
      onClose();
    } else {
      appWindow.close();
    }
  };

  const formatDuration = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="quick-voice-input" ref={containerRef}>
      <div className="voice-input-container">
        {/* çŠ¶æ€æŒ‡ç¤ºå™¨ */}
        <div className={`status-indicator ${isRecording ? 'recording' : isTranscribing ? 'transcribing' : ''}`}>
          <div className="status-icon">
            {isRecording ? 'ğŸ¤' : isTranscribing ? 'â³' : 'âœ…'}
          </div>
          {isRecording && (
            <div className="recording-pulse">
              <div className="pulse-ring"></div>
            </div>
          )}
        </div>

        {/* ä¸»è¦å†…å®¹åŒº */}
        <div className="voice-input-content">
          {isRecording ? (
            <>
              <div className="recording-info">
                <span className="status-text">æ­£åœ¨å½•éŸ³...</span>
                <span className="duration">{formatDuration(recordingDuration)}</span>
              </div>
              <div className="audio-level-bar">
                <div 
                  className="audio-level-fill" 
                  style={{ width: `${audioLevel * 100}%` }}
                />
              </div>
              <div className="hint-text">æ¾å¼€å¿«æ·é”®åœæ­¢å½•éŸ³</div>
            </>
          ) : isTranscribing ? (
            <div className="transcribing-info">
              <span className="status-text">æ­£åœ¨è½¬å½•...</span>
              <div className="loading-spinner"></div>
            </div>
          ) : transcriptionText ? (
            <div className="transcription-result">
              <span className="result-text">{transcriptionText}</span>
            </div>
          ) : error ? (
            <div className="error-info">
              <span className="error-text">{error}</span>
            </div>
          ) : null}
        </div>

        {/* å…³é—­æŒ‰é’® */}
        <button className="close-btn" onClick={handleClose} title="å…³é—­ (ESC)">
          Ã—
        </button>
      </div>

      {/* å¿«æ·é”®æç¤º */}
      <div className="shortcut-hint">
        <kbd>ESC</kbd> å–æ¶ˆ Â· <kbd>æŒ‰ä½å¿«æ·é”®</kbd> å½•éŸ³
      </div>
    </div>
  );
};

export default QuickVoiceInput;