import React, { useState, useEffect, useRef } from 'react';
import { invoke } from '@tauri-apps/api/tauri';
import { appWindow, LogicalSize, LogicalPosition } from '@tauri-apps/api/window';
import { listen } from '@tauri-apps/api/event';
import './QuickVoiceInput.css';

interface QuickVoiceInputProps {
  onClose?: () => void;
  onTextReady?: (text: string) => void;
}

interface ActiveAppInfo {
  name: string;
  bundle_id?: string;
  icon?: string;
}

const QuickVoiceInput: React.FC<QuickVoiceInputProps> = ({ onClose, onTextReady }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [transcriptionText, setTranscriptionText] = useState('');
  const [audioLevel, setAudioLevel] = useState(0);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [error, setError] = useState('');
  const [originalApp, setOriginalApp] = useState<ActiveAppInfo | null>(null);
  const [isPartial, setIsPartial] = useState(false);
  const [usingStreaming, setUsingStreaming] = useState(true);
  
  const timerRef = useRef<number | null>(null);
  const startTimeRef = useRef<number>(0);
  const containerRef = useRef<HTMLDivElement>(null);
  const silenceStartRef = useRef<number>(0);
  const lastAudioLevelRef = useRef<number>(0);

  useEffect(() => {
    const setupWindow = async () => {
      try {
        try {
          const activeApp = await invoke<ActiveAppInfo>('get_active_app_info_for_voice');
          setOriginalApp(activeApp);
        } catch (e) {}
        await appWindow.setAlwaysOnTop(true);
        await appWindow.setDecorations(false);
        await appWindow.setSize(new LogicalSize(400, 150));
        const screenWidth = window.screen.width;
        const screenHeight = window.screen.height;
        const x = Math.floor(screenWidth / 2 - 200);
        const y = Math.floor(screenHeight / 2 - 75);
        await appWindow.setPosition(new LogicalPosition(x, y));
      } catch {}
    };

    const unlistenAppInfo = listen<ActiveAppInfo>('voice_input_triggered', (event) => {
      setOriginalApp(event.payload);
    });

    setupWindow();
    
    // è‡ªåŠ¨å¼€å§‹å½•éŸ³ï¼ˆä½¿ç”¨æ¸è¿›å¼æµï¼‰
    startRecording();

    // åœæ­¢å½•éŸ³ï¼šå¿«æ·é”®æ¾å¼€
    const unlistenKeyRelease = listen('quick_voice_key_released', () => {
      if (isRecording) {
        stopRecording();
      }
    });

    // ç›‘å¬æµå¼äº‹ä»¶
    const unlistenStreaming = listen<any>('streaming_transcription', (event) => {
      const payload: any = event.payload || {};
      const text: string = payload.text || '';
      const partial: boolean = !!payload.is_partial;
      setTranscriptionText(text);
      setIsPartial(partial);
      if (text) setIsTranscribing(false);
    });
    const unlistenFinal = listen<string>('final_transcription', (event) => {
      const finalText = (event.payload || '').toString();
      if (finalText) {
        setTranscriptionText(finalText);
        setIsPartial(false);
      }
    });
    const unlistenComplete = listen<any>('progressive_voice_input_complete', async () => {
      // æ¸è¿›å¼æ³¨å…¥å·²å®Œæˆï¼Œå…³é—­çª—å£
      try {
        await appWindow.hide();
      } catch {}
      if (onClose) onClose(); else appWindow.close();
    });

    // ESC å…³é—­
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.key === 'Escape') {
        handleClose();
      }
    };
    document.addEventListener('keydown', handleKeyDown);

    return () => {
      unlistenAppInfo.then(fn => fn());
      unlistenKeyRelease.then(fn => fn());
      unlistenStreaming.then(fn => fn());
      unlistenFinal.then(fn => fn());
      unlistenComplete.then(fn => fn());
      document.removeEventListener('keydown', handleKeyDown);
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (isRecording) {
        invoke('stop_voice_recording').catch(() => {});
      }
    };
  }, [isRecording]);

  const startRecording = async () => {
    try {
      // åœæ­¢ç°æœ‰å½•éŸ³
      try { await invoke('stop_voice_recording'); } catch {}
      setError('');
      setIsRecording(true);
      setTranscriptionText('');
      setIsPartial(false);
      setUsingStreaming(true);
      startTimeRef.current = Date.now();

      // å¯åŠ¨æ¸è¿›å¼è¯­éŸ³è¾“å…¥ï¼ˆä»…æœ€ç»ˆæ³¨å…¥ï¼Œé¿å…é‡å¤æ³¨å…¥ï¼‰
      await invoke('start_progressive_voice_input', { targetBundleId: null, enableRealTimeInjection: false });

      // è®¡æ—¶å™¨ä¸ç”µå¹³ï¼ˆå°½é‡ä½¿ç”¨çœŸå®APIï¼Œå¤±è´¥å›é€€0ï¼‰
      timerRef.current = window.setInterval(async () => {
        const duration = (Date.now() - startTimeRef.current) / 1000;
        setRecordingDuration(duration);
        let currentLevel = 0;
        try {
          currentLevel = await invoke<number>('get_audio_level');
          setAudioLevel(Math.min(1.0, currentLevel));
        } catch { setAudioLevel(0); }
        lastAudioLevelRef.current = currentLevel;
      }, 100);
    } catch (error) {
      setError(`å½•éŸ³å¤±è´¥: ${error}`);
      setIsRecording(false);
    }
  };

  const stopRecording = async () => {
    try {
      if (timerRef.current) { clearInterval(timerRef.current); timerRef.current = null; }
      setIsRecording(false);
      setIsTranscribing(true);
      setAudioLevel(0);
      // ä½¿ç”¨æ¸è¿›å¼åœæ­¢ï¼Œä¸åšæœ¬åœ°æ³¨å…¥ï¼Œé¿å…é‡å¤
      await invoke('stop_voice_recording');
    } catch (error) {
      setError(`åœæ­¢å½•éŸ³å¤±è´¥: ${error}`);
      setIsTranscribing(false);
    }
  };

  const handleClose = () => {
    if (isRecording) {
      invoke('stop_voice_recording').catch(() => {});
    }
    if (onClose) onClose(); else appWindow.close();
  };

  const formatDuration = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="quick-voice-input" ref={containerRef}>
      <div className="voice-input-container">
        <div className={`status-indicator ${isRecording ? 'recording' : isTranscribing ? 'transcribing' : ''}`}>
          <div className="status-icon">
            {isRecording ? 'ğŸ¤' : isTranscribing ? 'â³' : 'âœ…'}
          </div>
          {isRecording && (
            <div className="recording-pulse">
              <div className="pulse-ring"></div>
            </div>
          )}
        </div>

        <div className="voice-input-content">
          {isRecording ? (
            <>
              <div className="recording-info">
                <span className="status-text">æ­£åœ¨å½•éŸ³...</span>
                <span className="duration">{formatDuration(recordingDuration)}</span>
              </div>
              <div className="audio-level-bar">
                <div 
                  className="audio-level-fill" 
                  style={{ width: `${audioLevel * 100}%` }}
                />
              </div>
              <div className="hint-text">æ¾å¼€å¿«æ·é”®åœæ­¢å½•éŸ³</div>
            </>
          ) : isTranscribing ? (
            <div className="transcribing-info">
              <span className="status-text">æ­£åœ¨è½¬å½•...</span>
              <div className="loading-spinner"></div>
            </div>
          ) : transcriptionText ? (
            <div className="transcription-result">
              <span className={`result-text ${isPartial ? 'partial' : 'final'}`}>{transcriptionText}</span>
              {error && <div className="error-text">{error}</div>}
            </div>
          ) : error ? (
            <div className="error-info">
              <span className="error-text">{error}</span>
            </div>
          ) : null}
        </div>

        <button className="close-btn" onClick={handleClose} title="å…³é—­ (ESC)">Ã—</button>
      </div>

      <div className="shortcut-hint">
        <kbd>ESC</kbd> å–æ¶ˆ Â· <kbd>æŒ‰ä½å¿«æ·é”®</kbd> å½•éŸ³
        {originalApp && <span className="app-info"> Â· ç›®æ ‡: {originalApp.name}</span>}
      </div>
    </div>
  );
};

export default QuickVoiceInput;
