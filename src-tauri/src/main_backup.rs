// Spokenly Clone - ç®€åŒ–ç‰ˆæœ¬ä¸“æ³¨æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½å’ŒAI Agentå¤„ç†
use tauri::{Manager, AppHandle, CustomMenuItem, SystemTray, SystemTrayMenu, SystemTrayEvent, WindowEvent, GlobalShortcutManager};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use parking_lot::Mutex;
use std::time::{SystemTime, UNIX_EPOCH};
use std::path::PathBuf;
use uuid::Uuid;
use tokio::fs;
use reqwest::Client;
use reqwest::multipart::{Form, Part};
use tokio::fs::File;
use tokio::io::AsyncReadExt;
use std::collections::HashMap;
use std::process::Command;

// å®‰å…¨æ¨¡å—å¯¼å…¥
mod security {
    pub mod path_validator;
    pub mod secure_client; 
    pub mod command_executor;
}
use security::command_executor::SecureCommandExecutor;
use chrono::{DateTime, Local};
use whisper_rs::{WhisperContext, WhisperContextParameters, FullParams, SamplingStrategy};
// Removed rdev dependency - global keyboard listener was causing crashes

mod audio_recorder;
mod ai_agent;
mod database;
mod folder_watcher;
mod performance_optimizer;

#[cfg(target_os = "macos")]
use cocoa::base::nil;

#[cfg(target_os = "macos")]
use cocoa::foundation::NSString;

#[cfg(target_os = "macos")]
use objc::runtime::Class;

#[cfg(target_os = "macos")]
use objc::{msg_send, sel, sel_impl};

#[cfg(target_os = "macos")]
extern "C" {
    fn IOHIDCheckAccess(requestType: i32) -> i32;
}

#[cfg(target_os = "macos")]
const kIOHIDRequestTypeListenEvent: i32 = 1;

#[cfg(target_os = "macos")]
fn check_accessibility_permission() -> bool {
    // æ£€æŸ¥è¾…åŠ©åŠŸèƒ½æƒé™
    let status = std::process::Command::new("osascript")
        .args(&["-e", "tell application \"System Events\" to get name of first process"])
        .output()
        .map(|output| output.status.success())
        .unwrap_or(false);
    
    if !status {
        println!("ğŸ” è¯·åœ¨ ç³»ç»Ÿåå¥½è®¾ç½® > å®‰å…¨æ€§ä¸éšç§ > éšç§ > è¾…åŠ©åŠŸèƒ½ ä¸­å¯ç”¨æ­¤åº”ç”¨");
    }
    status
}


#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TranscriptionEntry {
    pub id: String,
    pub text: String,
    pub timestamp: i64,
    pub duration: f64,
    pub model: String,
    pub confidence: f64,
    pub audio_file_path: Option<String>,
    pub created_at: Option<String>,
    pub updated_at: Option<String>,
    pub tags: Option<String>,
    pub metadata: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AudioDevice {
    pub name: String,
    pub id: String,
    pub is_default: bool,
    pub is_available: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AIPrompt {
    pub id: String,
    pub name: String,
    pub description: String,
    pub agent_type: String,
    pub prompt_text: String,
    pub is_active: bool,
    pub created_at: u64,
    pub updated_at: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentRequest {
    pub agent_type: String,
    pub input_text: String,
    pub prompt_id: Option<String>,
    pub additional_context: Option<HashMap<String, String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentResponse {
    pub success: bool,
    pub output_text: String,
    pub agent_type: String,
    pub processing_time_ms: u64,
    pub error: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OpenAIRequest {
    pub model: String,
    pub messages: Vec<OpenAIMessage>,
    pub temperature: f32,
    pub max_tokens: Option<u32>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OpenAIMessage {
    pub role: String,
    pub content: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OpenAIResponse {
    pub choices: Vec<OpenAIChoice>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OpenAIChoice {
    pub message: OpenAIMessage,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TranscriptionResult {
    text: String,
}

#[derive(Debug)]
pub struct AppState {
    pub is_recording: bool,
    pub transcription_history: Vec<TranscriptionEntry>,
    pub temp_dir: PathBuf,
    pub ai_prompts: Vec<AIPrompt>,
    pub http_client: Client,
    pub openai_api_key: Option<String>,
    pub audio_recorder: Arc<Mutex<audio_recorder::AudioRecorder>>,
    pub database: Arc<database::DatabaseManager>,
    pub folder_watcher: Arc<folder_watcher::FolderWatcher>,
    pub performance_optimizer: Arc<Mutex<performance_optimizer::PerformanceOptimizer>>,
}

impl AppState {
    pub fn new() -> Self {
        let temp_dir = std::env::temp_dir().join("spokenly-clone");
        std::fs::create_dir_all(&temp_dir).ok();
        
        // åˆå§‹åŒ–æ•°æ®åº“
        let db_dir = directories::UserDirs::new()
            .map(|dirs| dirs.home_dir().join("Library/Application Support/spokenly-clone"))
            .unwrap_or_else(|| temp_dir.clone());
        std::fs::create_dir_all(&db_dir).ok();
        
        let db_path = db_dir.join("spokenly.db");
        let database = database::DatabaseManager::new(&db_path)
            .expect("æ— æ³•åˆå§‹åŒ–æ•°æ®åº“");
        
        // åˆ›å»ºHTTPå®¢æˆ·ç«¯
        let http_client = Client::builder()
            .timeout(std::time::Duration::from_secs(30))
            .build()
            .unwrap();
        
        // ä»ç¯å¢ƒå˜é‡è¯»å–OpenAI APIå¯†é’¥ - å®‰å…¨å®ç°
        let openai_api_key = std::env::var("OPENAI_API_KEY").ok();
        
        // åˆå§‹åŒ–é»˜è®¤AIæç¤º
        let mut ai_prompts = Vec::new();
        ai_prompts.push(create_default_prompt("speech-to-text", "è¯­éŸ³è½¬æ–‡å­—", "å°†è¯­éŸ³è½¬æ¢ä¸ºå‡†ç¡®çš„æ–‡æœ¬"));
        ai_prompts.push(create_default_prompt("text-enhancer", "æ–‡æœ¬å¢å¼º", "ä¼˜åŒ–å’Œå¢å¼ºæ–‡æœ¬å†…å®¹ï¼Œä½¿å…¶æ›´æ¸…æ™°å‡†ç¡®"));
        ai_prompts.push(create_default_prompt("translator", "ç¿»è¯‘", "å°†æ–‡æœ¬ç¿»è¯‘ä¸ºç›®æ ‡è¯­è¨€"));
        ai_prompts.push(create_default_prompt("summarizer", "æ‘˜è¦", "ç”Ÿæˆå†…å®¹çš„ç®€æ´æ‘˜è¦"));
        ai_prompts.push(create_default_prompt("formatter", "æ ¼å¼åŒ–", "æ ¼å¼åŒ–æ–‡æœ¬å†…å®¹ï¼Œä½¿å…¶ç»“æ„æ¸…æ™°"));
        ai_prompts.push(create_default_prompt("grammar-check", "è¯­æ³•æ£€æŸ¥", "æ£€æŸ¥å¹¶ä¿®æ­£è¯­æ³•é”™è¯¯"));
        ai_prompts.push(create_default_prompt("tone-adjuster", "è¯­è°ƒè°ƒæ•´", "è°ƒæ•´æ–‡æœ¬çš„è¯­è°ƒå’Œé£æ ¼"));
        ai_prompts.push(create_default_prompt("auto-input", "è‡ªåŠ¨è¾“å…¥", "ç”Ÿæˆé€‚åˆçš„æ–‡æœ¬è¾“å…¥å†…å®¹"));
        
        // ä»æ•°æ®åº“åŠ è½½å†å²è®°å½•
        let transcription_history = database.get_all_transcriptions()
            .unwrap_or_else(|e| {
                eprintln!("åŠ è½½å†å²è®°å½•å¤±è´¥: {}", e);
                Vec::new()
            });
        
        Self {
            is_recording: false,
            transcription_history,
            temp_dir,
            ai_prompts,
            http_client,
            openai_api_key,
            audio_recorder: Arc::new(Mutex::new(audio_recorder::AudioRecorder::new())),
            database: Arc::new(database),
            folder_watcher: Arc::new(folder_watcher::FolderWatcher::new()),
            performance_optimizer: Arc::new(Mutex::new(performance_optimizer::PerformanceOptimizer::new())),
        }
    }
}

fn create_default_prompt(agent_type: &str, name: &str, description: &str) -> AIPrompt {
    let timestamp = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
    
    let prompt_text = match agent_type {
        "speech-to-text" => "è¯·å°†ä»¥ä¸‹è¯­éŸ³å†…å®¹è½¬æ¢ä¸ºå‡†ç¡®çš„æ–‡æœ¬ï¼Œä¿æŒåŸæ„ä¸å˜ï¼š",
        "text-enhancer" => "è¯·ä¼˜åŒ–ä»¥ä¸‹æ–‡æœ¬ï¼Œä½¿å…¶æ›´æ¸…æ™°ã€å‡†ç¡®å’Œä¸“ä¸šï¼š",
        "translator" => "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘ä¸ºæŒ‡å®šçš„ç›®æ ‡è¯­è¨€ï¼Œä¿æŒåŸæ„å’Œè¯­è°ƒï¼š",
        "summarizer" => "è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆç®€æ´æ˜äº†çš„æ‘˜è¦ï¼Œçªå‡ºè¦ç‚¹ï¼š",
        "formatter" => "è¯·å°†ä»¥ä¸‹å†…å®¹æ ¼å¼åŒ–ï¼Œä½¿ç»“æ„æ¸…æ™°ï¼Œæ˜“äºé˜…è¯»ï¼š",
        "grammar-check" => "è¯·æ£€æŸ¥ä»¥ä¸‹æ–‡æœ¬çš„è¯­æ³•é”™è¯¯å¹¶æä¾›ä¿®æ­£å»ºè®®ï¼š",
        "tone-adjuster" => "è¯·è°ƒæ•´ä»¥ä¸‹æ–‡æœ¬çš„è¯­è°ƒå’Œé£æ ¼ï¼Œä½¿å…¶ç¬¦åˆæŒ‡å®šè¦æ±‚ï¼š",
        "auto-input" => "è¯·åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆåˆé€‚çš„æ–‡æœ¬è¾“å…¥å†…å®¹ï¼š",
        _ => "è¯·å¤„ç†ä»¥ä¸‹å†…å®¹ï¼š"
    }.to_string();
    
    AIPrompt {
        id: Uuid::new_v4().to_string(),
        name: name.to_string(),
        description: description.to_string(),
        agent_type: agent_type.to_string(),
        prompt_text,
        is_active: true,
        created_at: timestamp,
        updated_at: timestamp,
    }
}

#[tauri::command]
async fn upload_file(
    file_path: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>,
    app_handle: AppHandle
) -> Result<String, String> {
    let file_path = PathBuf::from(&file_path);
    
    if !file_path.exists() {
        return Err("æ–‡ä»¶ä¸å­˜åœ¨".to_string());
    }

    // æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    let extension = file_path.extension()
        .and_then(|ext| ext.to_str())
        .map(|ext| ext.to_lowercase())
        .unwrap_or_default();
    
    let supported_formats = ["mp3", "wav", "m4a", "flac", "mp4", "mov", "m4v"];
    if !supported_formats.contains(&extension.as_str()) {
        return Err(format!("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .{}", extension));
    }

    println!("ğŸ“ å¼€å§‹å¤„ç†æ–‡ä»¶: {:?}", file_path);
    
    let entry_id = Uuid::new_v4().to_string();
    let timestamp = SystemTime::now().duration_since(UNIX_EPOCH)
        .unwrap().as_secs();

    // å¤åˆ¶æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
    let temp_path = {
        let app_state = state.lock();
        app_state.temp_dir.join(format!("{}_{}.{}", entry_id, timestamp, extension))
    };

    match fs::copy(&file_path, &temp_path).await {
        Ok(_) => {
            println!("âœ… æ–‡ä»¶å·²å¤åˆ¶åˆ°: {:?}", temp_path);
            
            // å¯åŠ¨è½¬å½•å¤„ç†
            let app_handle_clone = app_handle.clone();
            let state_clone = Arc::clone(&state);
            let temp_path_clone = temp_path.clone();
            
            tokio::spawn(async move {
                match process_file_transcription(&temp_path_clone, entry_id, state_clone).await {
                    Ok(entry) => {
                        let _ = app_handle_clone.emit_all("file_transcription_result", &entry);
                    },
                    Err(e) => {
                        eprintln!("æ–‡ä»¶è½¬å½•å¤±è´¥: {}", e);
                        let _ = app_handle_clone.emit_all("file_transcription_error", &e.to_string());
                    }
                }
            });
            
            Ok(format!("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå¼€å§‹è½¬å½•: {}", file_path.display()))
        },
        Err(e) => {
            Err(format!("æ–‡ä»¶å¤åˆ¶å¤±è´¥: {}", e))
        }
    }
}

async fn process_file_transcription(
    file_path: &PathBuf,
    entry_id: String,
    state: Arc<Mutex<AppState>>
) -> Result<TranscriptionEntry, Box<dyn std::error::Error + Send + Sync>> {
    
    println!("ğŸ”„ å¼€å§‹è½¬å½•æ–‡ä»¶: {:?}", file_path);
    
    let client = {
        let app_state = state.lock();
        app_state.http_client.clone()
    };
    
    // ä½¿ç”¨å½•éŸ³æ¥å£æœåŠ¡è¿›è¡ŒçœŸå®è½¬å†™
    let transcription_result = transcribe_via_luyin_api(&client, file_path).await?;
    let text = transcription_result.text;
    
    let timestamp = SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs();
    
    let entry = TranscriptionEntry {
        id: entry_id,
        text,
        timestamp: timestamp as i64,
        duration: 120.0, // å‡è®¾2åˆ†é’Ÿ
        model: "gpt-4o-mini".to_string(),
        confidence: 0.95,
        audio_file_path: Some(file_path.to_string_lossy().to_string()),
        created_at: None,
        updated_at: None,
        tags: None,
        metadata: None,
    };
    
    // ä¿å­˜åˆ°æ•°æ®åº“å¹¶æ·»åŠ åˆ°å†…å­˜å†å²è®°å½•
    {
        let mut state_guard = state.lock();
        
        // ä¿å­˜åˆ°æ•°æ®åº“
        if let Err(e) = state_guard.database.insert_transcription(&entry) {
            eprintln!("ä¿å­˜è½¬å½•è®°å½•åˆ°æ•°æ®åº“å¤±è´¥: {}", e);
        }
        
        state_guard.transcription_history.insert(0, entry.clone());
        
        // é™åˆ¶å†…å­˜å†å²è®°å½•æ•°é‡
        if state_guard.transcription_history.len() > 100 {
            state_guard.transcription_history.truncate(100);
        }
    }
    
    println!("âœ… æ–‡ä»¶è½¬å½•å®Œæˆ: {}", entry.text);
    Ok(entry)
}

#[tauri::command]
async fn process_batch(
    request: BatchProcessRequest,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<BatchProcessResponse, String> {
    let start_time = SystemTime::now();
    
    println!("ğŸ“¦ å¼€å§‹æ‰¹é‡å¤„ç†: {} ({} é¡¹)", request.agent_type, request.input_texts.len());
    
    let mut results = Vec::new();
    let mut success_count = 0;
    let mut error_count = 0;
    
    for (index, input_text) in request.input_texts.iter().enumerate() {
        println!("ğŸ”„ å¤„ç†é¡¹ç›® {}/{}", index + 1, request.input_texts.len());
        
        let agent_request = AgentRequest {
            agent_type: request.agent_type.clone(),
            input_text: input_text.clone(),
            prompt_id: request.prompt_id.clone(),
            additional_context: request.additional_context.clone(),
        };
        
        match process_with_agent(agent_request, state.clone()).await {
            Ok(result) => {
                if result.success {
                    success_count += 1;
                } else {
                    error_count += 1;
                }
                results.push(result);
            },
            Err(e) => {
                error_count += 1;
                results.push(AgentResponse {
                    success: false,
                    output_text: String::new(),
                    agent_type: request.agent_type.clone(),
                    processing_time_ms: 0,
                    error: Some(e),
                });
            }
        }
    }
    
    let total_time = start_time.elapsed().unwrap().as_millis() as u64;
    
    println!("âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {} ({}ms, æˆåŠŸ: {}, å¤±è´¥: {})", 
             request.agent_type, total_time, success_count, error_count);
    
    Ok(BatchProcessResponse {
        success: error_count == 0,
        results,
        total_processing_time_ms: total_time,
        success_count,
        error_count,
    })
}

// Removed key_to_string function - no longer needed without global keyboard listener

#[tauri::command]
async fn start_recording(
    state: tauri::State<'_, Arc<Mutex<AppState>>>,
) -> Result<String, String> {
    let mut app_state = state.lock();
    if !app_state.is_recording {
        app_state.is_recording = true;
        let mut recorder = app_state.audio_recorder.lock();
        recorder.start_recording().map_err(|e| e.to_string())?;
        Ok("Recording started".to_string())
    } else {
        Err("Already recording".to_string())
    }
}
#[tauri::command]
async fn stop_recording(
    state: tauri::State<'_, Arc<Mutex<AppState>>>,
    app_handle: AppHandle,
    model: String,
    model_type: String
) -> Result<String, String> {
    let (client, api_key, temp_dir, recorder_arc, audio_data);
    {
        let mut app_state = state.lock();
        
        println!("ğŸ” è°ƒè¯•ä¿¡æ¯: å½“å‰å½•éŸ³çŠ¶æ€ is_recording = {}", app_state.is_recording);
        println!("ğŸ” è°ƒè¯•ä¿¡æ¯: æ”¶åˆ°çš„æ¨¡å‹å‚æ•° model = '{}', modelType = '{}'", model, model_type);
        
        if !app_state.is_recording {
            println!("âš ï¸ é”™è¯¯: å°è¯•åœæ­¢å½•éŸ³ä½†å½“å‰çŠ¶æ€ä¸ºæœªå½•éŸ³");
            return Err("Not recording".to_string());
        }
        
        println!("âœ… å½•éŸ³çŠ¶æ€æ­£å¸¸ï¼Œå‡†å¤‡åœæ­¢å½•éŸ³...");
        app_state.is_recording = false;
        client = app_state.http_client.clone();
        api_key = app_state.openai_api_key.clone().unwrap();
        temp_dir = app_state.temp_dir.clone();
        recorder_arc = app_state.audio_recorder.clone();
    }
    
    // åœæ­¢å½•éŸ³å¹¶è·å–éŸ³é¢‘æ•°æ®
    {
        let mut recorder = recorder_arc.lock();
        match recorder.stop_recording() {
            Ok(data) => {
                audio_data = data;
                println!("â¹ï¸ åœæ­¢å½•éŸ³ï¼Œè·å¾— {} ä¸ªæ ·æœ¬", audio_data.len());
            },
            Err(e) => {
                eprintln!("åœæ­¢å½•éŸ³å¤±è´¥: {}", e);
                return Err(format!("Failed to stop recording: {}", e));
            }
        }
    }
    
    // å¦‚æœæ²¡æœ‰éŸ³é¢‘æ•°æ®ï¼Œè¿”å›é”™è¯¯
    if audio_data.is_empty() {
        return Err("No audio data captured".to_string());
    }
    
    // ç”Ÿæˆæ–‡ä»¶åå¹¶ä¿å­˜éŸ³é¢‘
    let entry_id = Uuid::new_v4().to_string();
    let timestamp = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
    let audio_file_path = temp_dir.join(format!("recording_{}_{}.wav", entry_id, timestamp));
    
    // ä¿å­˜éŸ³é¢‘åˆ° WAV æ–‡ä»¶
    {
        let recorder = recorder_arc.lock();
        match recorder.save_to_wav(&audio_data, &audio_file_path) {
            Ok(_) => {
                println!("ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜åˆ°: {:?}", audio_file_path);
            },
            Err(e) => {
                eprintln!("ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {}", e);
                return Err(format!("Failed to save audio: {}", e));
            }
        }
    }
    
    // è®¡ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆå‡è®¾ 44100 Hz é‡‡æ ·ç‡ï¼‰
    let duration = (audio_data.len() as f32 / 44100.0) as u64;
    
    // æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©è½¬å½•æ–¹å¼
    println!("ğŸ” è°ƒè¯•ä¿¡æ¯: æ¥æ”¶åˆ°çš„å‚æ•° - model: '{}', model_type: '{}'", model, model_type);
    let transcription_result = if model_type == "local" {
        // æœ¬åœ° Whisper æ¨¡å‹è½¬å½•
        println!("ğŸ” ä½¿ç”¨æœ¬åœ° {} æ¨¡å‹è¿›è¡Œè½¬å½•...", model);
        match transcribe_with_local_whisper(&audio_file_path, &model).await {
            Ok(result) => {
                println!("âœ… æœ¬åœ°è½¬å½•æˆåŠŸ: {}", result.text);
                result
            },
            Err(e) => {
                println!("âŒ æœ¬åœ°è½¬å½•å¤±è´¥: {}", e);
                return Err(e.to_string());
            }
        }
    } else if model == "luyingwang-online" {
        // ä½¿ç”¨å½•éŸ³æ¥å£æœåŠ¡è¿›è¡ŒçœŸå®åœ¨çº¿è½¬å†™
        println!("ğŸŒ ä½¿ç”¨é²éŸ³ç½‘æœåŠ¡è¿›è¡Œè½¬å†™...");
        match transcribe_via_luyin_api(&client, &audio_file_path).await {
            Ok(result) => {
                println!("âœ… é²éŸ³ç½‘åœ¨çº¿è½¬å†™æˆåŠŸ: {}", result.text);
                result
            },
            Err(e) => {
                println!("âŒ é²éŸ³ç½‘åœ¨çº¿è½¬å†™å¤±è´¥: {}", e);
                return Err(e);
            }
        }
    } else {
        // åœ¨çº¿ API è½¬å½•
        println!("ğŸ“¤ æ­£åœ¨å‘é€éŸ³é¢‘åˆ° {} API...", model);
        match transcribe_audio_file(&client, &api_key, &audio_file_path, &model).await {
            Ok(result) => {
                println!("âœ… åœ¨çº¿è½¬å½•æˆåŠŸ: {}", result.text);
                result
            },
            Err(e) => {
                println!("âŒ åœ¨çº¿è½¬å½•å¤±è´¥: {}", e);
                return Err(e.to_string());
            }
        }
    };
    
    let entry = TranscriptionEntry {
        id: entry_id,
        text: transcription_result.text,
        timestamp: timestamp as i64,
        duration: duration as f64,
        model: "gpt-4o-mini".to_string(),
        confidence: 0.95,
        audio_file_path: Some(audio_file_path.to_string_lossy().to_string()),
        created_at: None,
        updated_at: None,
        tags: None,
        metadata: None,
    };
    
    {
        let mut app_state = state.lock();
        
        // ä¿å­˜åˆ°æ•°æ®åº“
        if let Err(e) = app_state.database.insert_transcription(&entry) {
            eprintln!("ä¿å­˜è½¬å½•è®°å½•åˆ°æ•°æ®åº“å¤±è´¥: {}", e);
        }
        
        app_state.transcription_history.insert(0, entry.clone());
        
        if app_state.transcription_history.len() > 100 {
            app_state.transcription_history.truncate(100);
        }
    }
    
    let _ = app_handle.emit_all("transcription_result", &entry);
    Ok("Recording stopped".to_string())
}

#[tauri::command]
async fn delete_file(
    entry_id: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let mut app_state = state.lock();
    
    // ä»å†å²è®°å½•ä¸­æ‰¾åˆ°å¹¶åˆ é™¤æ¡ç›®
    if let Some(pos) = app_state.transcription_history.iter().position(|entry| entry.id == entry_id) {
        let entry = app_state.transcription_history.remove(pos);
        
        // ä»æ•°æ®åº“åˆ é™¤
        if let Err(e) = app_state.database.delete_transcription(&entry_id) {
            eprintln!("ä»æ•°æ®åº“åˆ é™¤è½¬å½•è®°å½•å¤±è´¥: {}", e);
        }
        
        // åˆ é™¤å…³è”çš„éŸ³é¢‘æ–‡ä»¶
        if let Some(file_path_str) = &entry.audio_file_path {
            let file_path = PathBuf::from(file_path_str);
            if file_path.exists() {
                match std::fs::remove_file(&file_path) {
                    Ok(_) => println!("ğŸ—‘ï¸ å·²åˆ é™¤éŸ³é¢‘æ–‡ä»¶: {:?}", file_path),
                    Err(e) => eprintln!("åˆ é™¤éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {:?}: {}", file_path, e),
                }
            }
        }
        
        println!("âœ… å·²åˆ é™¤è½¬å½•è®°å½•: {}", entry.text);
        Ok(())
    } else {
        Err("æœªæ‰¾åˆ°æŒ‡å®šçš„è½¬å½•è®°å½•".to_string())
    }
}

#[tauri::command]
async fn export_transcription(
    entry_id: String,
    export_format: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<String, String> {
    let app_state = state.lock();
    
    // æ‰¾åˆ°æŒ‡å®šçš„è½¬å½•è®°å½•
    let entry = app_state.transcription_history.iter()
        .find(|e| e.id == entry_id)
        .ok_or("æœªæ‰¾åˆ°æŒ‡å®šçš„è½¬å½•è®°å½•")?;
    
    // è·å–æ¡Œé¢è·¯å¾„
    let desktop_path = directories::UserDirs::new()
        .and_then(|dirs| dirs.desktop_dir().map(|p| p.to_path_buf()))
        .unwrap_or_else(|| std::env::home_dir().unwrap_or_else(|| PathBuf::from(".")));
    
    // ç”Ÿæˆæ–‡ä»¶å
    let timestamp_str = Local::now().format("%Y%m%d_%H%M%S");
    let file_name = format!("transcription_{}_{}.{}", 
        entry_id.chars().take(8).collect::<String>(), 
        timestamp_str, 
        export_format
    );
    let export_path = desktop_path.join(&file_name);
    
    // æ ¹æ®æ ¼å¼å¯¼å‡º
    match export_format.as_str() {
        "txt" => {
            // å¯¼å‡ºä¸ºçº¯æ–‡æœ¬
            let content = format!(
                "è½¬å½•æ–‡æœ¬\n{}\n\næ—¶é—´: {}\næ—¶é•¿: {}ç§’\næ¨¡å‹: {}\nç½®ä¿¡åº¦: {:.1}%\n",
                entry.text,
                DateTime::<Local>::from(
                    std::time::UNIX_EPOCH + std::time::Duration::from_secs(entry.timestamp as u64)
                ).format("%Y-%m-%d %H:%M:%S"),
                entry.duration,
                entry.model,
                entry.confidence * 100.0
            );
            std::fs::write(&export_path, content)
                .map_err(|e| format!("å†™å…¥æ–‡ä»¶å¤±è´¥: {}", e))?;
        },
        "json" => {
            // å¯¼å‡ºä¸ºJSON
            let json_content = serde_json::to_string_pretty(&entry)
                .map_err(|e| format!("åºåˆ—åŒ–å¤±è´¥: {}", e))?;
            std::fs::write(&export_path, json_content)
                .map_err(|e| format!("å†™å…¥æ–‡ä»¶å¤±è´¥: {}", e))?;
        },
        _ => {
            return Err(format!("ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {}", export_format));
        }
    }
    
    println!("ğŸ“¤ å·²å¯¼å‡ºè½¬å½•è®°å½•åˆ°: {:?}", export_path);
    Ok(export_path.to_string_lossy().to_string())
}

#[tauri::command]
async fn get_supported_formats() -> Result<Vec<String>, String> {
    Ok(vec![
        "mp3".to_string(),
        "wav".to_string(),
        "m4a".to_string(),
        "flac".to_string(),
        "mp4".to_string(),
        "mov".to_string(),
        "m4v".to_string(),
    ])
}

// æ–‡ä»¶å¤¹ç›‘æ§ç›¸å…³å‘½ä»¤
#[tauri::command]
async fn add_watched_folder(
    folder_path: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let app_state = state.lock();
    let path = PathBuf::from(folder_path);
    app_state.folder_watcher.add_folder(path)
}

#[tauri::command]
async fn remove_watched_folder(
    folder_path: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let app_state = state.lock();
    let path = PathBuf::from(folder_path);
    app_state.folder_watcher.remove_folder(&path)
}

#[tauri::command]
async fn get_watched_folders(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<Vec<String>, String> {
    let app_state = state.lock();
    let folders = app_state.folder_watcher.get_watched_folders();
    Ok(folders.into_iter().map(|p| p.to_string_lossy().to_string()).collect())
}

#[tauri::command]
async fn get_folder_watcher_stats(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(usize, Vec<String>), String> {
    let app_state = state.lock();
    Ok(app_state.folder_watcher.get_folder_stats())
}

#[tauri::command]
async fn clear_all_watched_folders(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let app_state = state.lock();
    app_state.folder_watcher.clear_all();
    Ok(())
}

// æ•°æ®åº“ç›¸å…³å‘½ä»¤
#[tauri::command]
async fn get_transcription_history(state: tauri::State<'_, Arc<Mutex<AppState>>>) -> Result<Vec<TranscriptionEntry>, String> {
    let app_state = state.lock();
    Ok(app_state.transcription_history.clone())
}

#[tauri::command]
async fn update_transcription_text(
    entry_id: String,
    new_text: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let mut app_state = state.lock();
    
    // æ›´æ–°æ•°æ®åº“
    if let Err(e) = app_state.database.update_transcription(&entry_id, &new_text) {
        return Err(format!("æ›´æ–°æ•°æ®åº“å¤±è´¥: {}", e));
    }
    
    // æ›´æ–°å†…å­˜ä¸­çš„å†å²è®°å½•
    if let Some(entry) = app_state.transcription_history.iter_mut().find(|e| e.id == entry_id) {
        entry.text = new_text;
        println!("âœ… è½¬å½•æ–‡æœ¬å·²æ›´æ–°: {}", entry_id);
    }
    
    Ok(())
}

#[tauri::command]
async fn search_transcriptions(
    query: String,
    limit: Option<usize>,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<Vec<TranscriptionEntry>, String> {
    let app_state = state.lock();
    
    match app_state.database.search_transcriptions(&query, limit) {
        Ok(results) => Ok(results),
        Err(e) => Err(format!("æœç´¢å¤±è´¥: {}", e))
    }
}

#[tauri::command]
async fn get_database_stats(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(usize, f64, usize), String> {
    let app_state = state.lock();
    
    match app_state.database.get_database_stats() {
        Ok(stats) => Ok(stats),
        Err(e) => Err(format!("è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {}", e))
    }
}

#[tauri::command]
async fn get_model_stats(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<Vec<(String, i32, f64, f64)>, String> {
    let app_state = state.lock();
    
    match app_state.database.get_model_stats() {
        Ok(stats) => Ok(stats),
        Err(e) => Err(format!("è·å–æ¨¡å‹ç»Ÿè®¡å¤±è´¥: {}", e))
    }
}

#[tauri::command]
async fn export_database_json(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<String, String> {
    let app_state = state.lock();
    
    match app_state.database.export_to_json() {
        Ok(json) => Ok(json),
        Err(e) => Err(format!("å¯¼å‡ºæ•°æ®å¤±è´¥: {}", e))
    }
}

// ç³»ç»Ÿæ‰˜ç›˜ç›¸å…³å‘½ä»¤
#[tauri::command]
async fn set_tray_icon_recording(is_recording: bool, app_handle: AppHandle) -> Result<(), String> {
    let tray = app_handle.tray_handle();
    
    // æ›´æ–°æ‰˜ç›˜èœå•ä¸­çš„å½•éŸ³é€‰é¡¹æ–‡å­—
    let item_handle = tray.get_item("toggle_recording");
    let new_title = if is_recording { "â¹ï¸ åœæ­¢å½•éŸ³" } else { "ğŸ¤ å¼€å§‹å½•éŸ³" };
    match item_handle.set_title(new_title) {
        Ok(_) => {
            println!("ğŸ¯ æ‰˜ç›˜èœå•å·²æ›´æ–° - å½•éŸ³çŠ¶æ€: {}", is_recording);
            Ok(())
        },
        Err(e) => Err(format!("è®¾ç½®æ‰˜ç›˜èœå•å¤±è´¥: {}", e))
    }
}

#[tauri::command]
async fn show_main_window(app_handle: AppHandle) -> Result<(), String> {
    let window = app_handle.get_window("main").ok_or("ä¸»çª—å£ä¸å­˜åœ¨")?;
    window.show().map_err(|e| format!("æ˜¾ç¤ºä¸»çª—å£å¤±è´¥: {}", e))?;
    window.set_focus().map_err(|e| format!("èšç„¦ä¸»çª—å£å¤±è´¥: {}", e))?;
    Ok(())
}

#[tauri::command]
async fn hide_main_window(app_handle: AppHandle) -> Result<(), String> {
    let window = app_handle.get_window("main").ok_or("ä¸»çª—å£ä¸å­˜åœ¨")?;
    window.hide().map_err(|e| format!("éšè—ä¸»çª—å£å¤±è´¥: {}", e))?;
    Ok(())
}

#[tauri::command]
async fn quit_app(app_handle: AppHandle) -> Result<(), String> {
    app_handle.exit(0);
    Ok(())
}

#[tauri::command]
async fn get_current_app_info() -> Result<HashMap<String, String>, String> {
    let mut info = HashMap::new();
    
    // æ ¹æ®å¹³å°è·å–å½“å‰æ¿€æ´»åº”ç”¨çš„ä¿¡æ¯
    #[cfg(target_os = "macos")]
    {
        // ä½¿ç”¨ AppleScript è·å–çœŸå®çš„å½“å‰åº”ç”¨ä¿¡æ¯
        let output = Command::new("osascript")
            .arg("-e")
            .arg("tell application \"System Events\" to get name of first application process whose frontmost is true")
            .output()
            .map_err(|e| format!("Failed to execute osascript: {}", e))?;
        
        let app_name = String::from_utf8_lossy(&output.stdout).trim().to_string();
        
        // è·å–åº”ç”¨çš„ bundle ID
        let bundle_output = Command::new("osascript")
            .arg("-e")
            .arg(format!("id of app \"{}\"", app_name))
            .output()
            .ok();
        
        let bundle_id = bundle_output
            .and_then(|o| String::from_utf8(o.stdout).ok())
            .map(|s| s.trim().to_string())
            .unwrap_or_else(|| "unknown".to_string());
        
        // åº”ç”¨å›¾æ ‡æ˜ å°„
        let icon = match app_name.as_str() {
            "Finder" | "è®¿è¾¾" => "ğŸ“",
            "Safari" => "ğŸŒ",
            "Google Chrome" | "Chrome" => "ğŸ”µ",
            "Firefox" => "ğŸ¦Š",
            "Xcode" => "ğŸ”¨",
            "Terminal" | "ç»ˆç«¯" => "â¬›",
            "å¾®ä¿¡" | "WeChat" => "ğŸ’¬",
            "é’‰é’‰" | "DingTalk" => "ğŸ“",
            "Visual Studio Code" | "Code" => "ğŸ“",
            "Slack" => "ğŸ’¼",
            "Telegram" => "âœˆï¸",
            "Mail" | "é‚®ä»¶" => "ğŸ“§",
            "Calendar" | "æ—¥å†" => "ğŸ“…",
            "Notes" | "å¤‡å¿˜å½•" => "ğŸ““",
            "Messages" | "ä¿¡æ¯" => "ğŸ’¬",
            "Music" | "éŸ³ä¹" => "ğŸµ",
            "Spotify" => "ğŸ§",
            "System Preferences" | "ç³»ç»Ÿåå¥½è®¾ç½®" => "âš™ï¸",
            "Activity Monitor" | "æ´»åŠ¨ç›‘è§†å™¨" => "ğŸ“Š",
            "Preview" | "é¢„è§ˆ" => "ğŸ–¼ï¸",
            "TextEdit" | "æ–‡æœ¬ç¼–è¾‘" => "ğŸ“„",
            _ => "ğŸ“±"
        };
        
        info.insert("name".to_string(), app_name);
        info.insert("bundle_id".to_string(), bundle_id);
        info.insert("icon".to_string(), icon.to_string());
    }
    
    #[cfg(not(target_os = "macos"))]
    {
        info.insert("name".to_string(), "æœªçŸ¥åº”ç”¨".to_string());
        info.insert("bundle_id".to_string(), "unknown".to_string());
        info.insert("icon".to_string(), "ğŸ“±".to_string());
    }
    
    Ok(info)
}

// æƒé™æ£€æŸ¥å‘½ä»¤
#[cfg(target_os = "macos")]
#[tauri::command]
async fn check_permission(permission: String) -> Result<String, String> {
    use std::process::Command;
    
    match permission.as_str() {
        "accessibility" => {
            // æ£€æŸ¥è¾…åŠ©åŠŸèƒ½æƒé™
            let output = Command::new("osascript")
                .arg("-e")
                .arg("tell application \"System Events\" to get UI elements enabled")
                .output()
                .map_err(|e| e.to_string())?;
            
            let result = String::from_utf8_lossy(&output.stdout);
            if result.trim() == "true" {
                Ok("granted".to_string())
            } else {
                Ok("denied".to_string())
            }
        },
        "microphone" => {
            unsafe {
                let cls = Class::get("AVCaptureDevice").unwrap();
                let media_type = NSString::alloc(nil).init_str("soun");
                let status: i32 = msg_send![cls, authorizationStatusForMediaType: media_type];
                let status_str = match status {
                    3 => "granted".to_string(),
                    2 => "denied".to_string(),
                    1 => "restricted".to_string(),
                    0 => "not-determined".to_string(),
                    _ => "unknown".to_string(),
                };
                println!("ğŸ¤ éº¦å…‹é£æƒé™çŠ¶æ€: {} (raw: {})", status_str, status);
                Ok(status_str)
            }
        },
        "file-system" => {
            // æ–‡ä»¶ç³»ç»Ÿæƒé™é€šå¸¸æ˜¯è‡ªåŠ¨æˆäºˆçš„
            Ok("granted".to_string())
        },
        "notifications" => {
            // å®ç°é€šçŸ¥æƒé™æ£€æŸ¥
            unsafe {
                // ç®€åŒ–çš„é€šçŸ¥æƒé™æ£€æŸ¥ - å¤§å¤šæ•°æƒ…å†µä¸‹æ˜¯è¢«æˆæƒçš„
                let status = std::process::Command::new("osascript")
                    .args(&["-e", "display notification \"test\" with title \"test\""])
                    .output()
                    .map(|output| output.status.success())
                    .unwrap_or(false);
                
                let status_str = if status {
                    "granted".to_string()
                } else {
                    "not-determined".to_string()
                };
                println!("ğŸ”” é€šçŸ¥æƒé™çŠ¶æ€: {}", status_str);
                Ok(status_str)
            }
        },
        "screen-recording" => {
            // å®ç°å±å¹•å½•åˆ¶æƒé™æ£€æŸ¥
            unsafe {
                // ä½¿ç”¨ CGDisplayStreamCreate æ¥æ£€æµ‹å±å¹•å½•åˆ¶æƒé™
                let available = std::process::Command::new("osascript")
                    .args(&["-e", "tell application \"System Events\" to get name of first process"])
                    .output()
                    .map(|output| output.status.success())
                    .unwrap_or(false);
                
                let status_str = if available {
                    "granted".to_string()
                } else {
                    "denied".to_string()
                };
                println!("ğŸ–¥ï¸ å±å¹•å½•åˆ¶æƒé™çŠ¶æ€: {}", status_str);
                Ok(status_str)
            }
        },
        "automation" => {
            // æ£€æŸ¥è‡ªåŠ¨åŒ–æƒé™ï¼ˆè¾…åŠ©åŠŸèƒ½è®¿é—®ï¼‰
            unsafe {
                let available = std::process::Command::new("osascript")
                    .args(&["-e", "tell application \"System Events\" to keystroke \"test\""])
                    .output()
                    .map(|output| output.status.success())
                    .unwrap_or(false);
                
                let status_str = if available {
                    "granted".to_string()
                } else {
                    "denied".to_string()
                };
                println!("ğŸ¤– è‡ªåŠ¨åŒ–æƒé™çŠ¶æ€: {}", status_str);
                Ok(status_str)
            }
        },
        "input-monitoring" => {
            unsafe {
                let status = IOHIDCheckAccess(kIOHIDRequestTypeListenEvent);
                let status_str = match status {
                    1 => "granted".to_string(), // kIOHIDAccessTypeGranted
                    0 => "denied".to_string(),  // kIOHIDAccessTypeDenied
                    _ => "not-determined".to_string(),
                };
                println!("âŒ¨ï¸ è¾“å…¥ç›‘æ§æƒé™çŠ¶æ€: {} (raw: {})", status_str, status);
                Ok(status_str)
            }
        },
        _ => Ok("not-determined".to_string())
    }
}

#[cfg(not(target_os = "macos"))]
#[tauri::command]
async fn check_permission(permission: String) -> Result<String, String> {
    // å…¶ä»–æ“ä½œç³»ç»Ÿçš„æƒé™æ£€æŸ¥
    Ok("granted".to_string())
}

#[tauri::command]
async fn get_audio_devices() -> Result<Vec<AudioDevice>, String> {
    use cpal::traits::{DeviceTrait, HostTrait};

    let host = cpal::default_host();
    let mut devices = Vec::new();

    match host.input_devices() {
        Ok(input_devices) => {
            for (index, device) in input_devices.enumerate() {
                match device.name() {
                    Ok(name) => {
                        devices.push(AudioDevice {
                            name,
                            id: index.to_string(),
                            is_default: index == 0,
                            is_available: true,
                        });
                    }
                    Err(e) => {
                        eprintln!("è·å–è®¾å¤‡åç§°å¤±è´¥: {}", e);
                    }
                }
            }
        }
        Err(e) => {
            return Err(format!("è·å–éŸ³é¢‘è®¾å¤‡å¤±è´¥: {}", e));
        }
    }

    Ok(devices)
}

// æƒé™è¯·æ±‚å‘½ä»¤
#[tauri::command]
async fn request_permission(permission: String, _app_handle: AppHandle) -> Result<String, String> {
    println!("ğŸ” ç”³è¯·æƒé™: {}", permission);
    
    match permission.as_str() {
        "microphone" => {
            // ç”³è¯·éº¦å…‹é£æƒé™
            #[cfg(target_os = "macos")]
            {
                unsafe {
                    let cls = Class::get("AVCaptureDevice").unwrap();
                    let media_type = NSString::alloc(nil).init_str("soun");
                    let _: () = msg_send![cls, requestAccessForMediaType: media_type completionHandler: nil];
                    
                    // æ‰“å¼€ç³»ç»Ÿè®¾ç½®åˆ°éšç§é¡µé¢
                    let _ = std::process::Command::new("open")
                        .arg("x-apple.systempreferences:com.apple.preference.security?Privacy_Microphone")
                        .spawn();
                }
            }
            Ok("pending".to_string())
        },
        "screen-recording" => {
            // æ‰“å¼€å±å¹•å½•åˆ¶æƒé™è®¾ç½®
            #[cfg(target_os = "macos")]
            {
                let _ = std::process::Command::new("open")
                    .arg("x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture")
                    .spawn();
            }
            Ok("pending".to_string())
        },
        "automation" => {
            // æ‰“å¼€è¾…åŠ©åŠŸèƒ½æƒé™è®¾ç½®
            #[cfg(target_os = "macos")]
            {
                let _ = std::process::Command::new("open")
                    .arg("x-apple.systempreferences:com.apple.preference.security?Privacy_Accessibility")
                    .spawn();
            }
            Ok("pending".to_string())
        },
        "input-monitoring" => {
            // æ‰“å¼€è¾“å…¥ç›‘æ§æƒé™è®¾ç½®
            #[cfg(target_os = "macos")]
            {
                let _ = std::process::Command::new("open")
                    .arg("x-apple.systempreferences:com.apple.preference.security?Privacy_ListenEvent")
                    .spawn();
            }
            Ok("pending".to_string())
        },
        "notifications" => {
            // æ‰“å¼€é€šçŸ¥æƒé™è®¾ç½®
            #[cfg(target_os = "macos")]
            {
                let _ = std::process::Command::new("open")
                    .arg("x-apple.systempreferences:com.apple.preference.notifications")
                    .spawn();
            }
            Ok("pending".to_string())
        },
        "file-system" => {
            // æ–‡ä»¶ç³»ç»Ÿæƒé™é€šå¸¸æ˜¯è‡ªåŠ¨çš„
            Ok("granted".to_string())
        },
        _ => {
            Err("æœªçŸ¥æƒé™ç±»å‹".to_string())
        }
    }
}

#[tauri::command] 
async fn open_system_preferences(preference_pane: String) -> Result<(), String> {
    #[cfg(target_os = "macos")]
    {
        // ç›´æ¥ä½¿ç”¨ open å‘½ä»¤æ‰“å¼€ç³»ç»Ÿè®¾ç½®
        let url = match preference_pane.as_str() {
            "accessibility" => "x-apple.systempreferences:com.apple.preference.security?Privacy_Accessibility",
            "microphone" => "x-apple.systempreferences:com.apple.preference.security?Privacy_Microphone", 
            "input-monitoring" => "x-apple.systempreferences:com.apple.preference.security?Privacy_ListenEvent",
            "screen-recording" => "x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture",
            "files-and-folders" => "x-apple.systempreferences:com.apple.preference.security?Privacy_FilesAndFolders",
            "developer-tools" => "x-apple.systempreferences:com.apple.preference.security?Privacy_DeveloperTools",
            "automation" => "x-apple.systempreferences:com.apple.preference.security?Privacy_Automation",
            _ => {
                return Err(format!("æœªçŸ¥çš„è®¾ç½®é¢æ¿: {}", preference_pane));
            }
        };
        
        let output = Command::new("open")
            .arg(url)
            .output()
            .map_err(|e| format!("æ— æ³•æ‰“å¼€ç³»ç»Ÿè®¾ç½®: {}", e))?;
            
        if !output.status.success() {
            return Err(format!("æ‰“å¼€ç³»ç»Ÿè®¾ç½®å¤±è´¥: {:?}", String::from_utf8_lossy(&output.stderr)));
        }
        
        println!("âœ… å·²æ‰“å¼€ç³»ç»Ÿè®¾ç½®: {}", preference_pane);
    }
    
    #[cfg(not(target_os = "macos"))]
    {
        return Err("æ­¤åŠŸèƒ½ä»…åœ¨ macOS ä¸Šå¯ç”¨".to_string());
    }
    
    Ok(())
}

// ======== æ€§èƒ½ä¼˜åŒ–ç›¸å…³å‘½ä»¤ ========

#[tauri::command]
async fn get_performance_metrics(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<performance_optimizer::PerformanceMetrics, String> {
    let app_state = state.lock();
    let mut optimizer = app_state.performance_optimizer.lock();
    
    // è·å–ç³»ç»ŸæŒ‡æ ‡
    let (cpu_usage, memory_usage) = optimizer.get_system_metrics()
        .map_err(|e| format!("è·å–ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {}", e))?;
    
    // åˆ›å»ºæ€§èƒ½æŒ‡æ ‡å¯¹è±¡
    let mut metrics = performance_optimizer::PerformanceMetrics::default();
    metrics.cpu_usage_percent = cpu_usage;
    metrics.gpu_memory_usage_mb = memory_usage;
    
    Ok(metrics)
}

#[tauri::command]
async fn get_cache_stats(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(usize, Vec<String>), String> {
    let app_state = state.lock();
    let optimizer = app_state.performance_optimizer.lock();
    
    Ok(optimizer.get_cache_stats())
}

#[tauri::command]
async fn clear_model_cache(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let app_state = state.lock();
    let optimizer = app_state.performance_optimizer.lock();
    
    optimizer.clear_model_cache();
    Ok(())
}

#[tauri::command]
async fn configure_performance_optimizer(
    enable_gpu: bool,
    enable_caching: bool,
    max_cache_size: usize,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let app_state = state.lock();
    let mut optimizer = app_state.performance_optimizer.lock();
    
    optimizer.configure(enable_gpu, enable_caching, max_cache_size);
    println!("ğŸ”§ æ€§èƒ½ä¼˜åŒ–å™¨é…ç½®å·²æ›´æ–°: GPU={}, ç¼“å­˜={}, æœ€å¤§ç¼“å­˜={}", 
             enable_gpu, enable_caching, max_cache_size);
    
    Ok(())
}

#[tauri::command]
async fn warmup_gpu(
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let app_state = state.lock();
    let optimizer = app_state.performance_optimizer.lock();
    
    optimizer.warmup_gpu()
}

// ======== AI Agent ç›¸å…³å‘½ä»¤ ========

#[tauri::command]
async fn get_ai_prompts(state: tauri::State<'_, Arc<Mutex<AppState>>>) -> Result<Vec<AIPrompt>, String> {
    let app_state = state.lock();
    Ok(app_state.ai_prompts.clone())
}

#[tauri::command]
async fn save_ai_prompt(
    mut prompt: AIPrompt,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<AIPrompt, String> {
    let mut app_state = state.lock();
    let timestamp = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
    
    // æŸ¥æ‰¾æ˜¯å¦å­˜åœ¨ç›¸åŒIDçš„æç¤º
    if let Some(existing_index) = app_state.ai_prompts.iter().position(|p| p.id == prompt.id) {
        // æ›´æ–°ç°æœ‰æç¤º
        prompt.updated_at = timestamp;
        app_state.ai_prompts[existing_index] = prompt.clone();
        println!("âœ… å·²æ›´æ–°AIæç¤º: {}", prompt.name);
    } else {
        // åˆ›å»ºæ–°æç¤º
        if prompt.id.is_empty() {
            prompt.id = Uuid::new_v4().to_string();
        }
        prompt.created_at = timestamp;
        prompt.updated_at = timestamp;
        app_state.ai_prompts.push(prompt.clone());
        println!("âœ… å·²åˆ›å»ºæ–°AIæç¤º: {}", prompt.name);
    }
    
    Ok(prompt)
}

#[tauri::command]
async fn delete_ai_prompt(
    prompt_id: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let mut app_state = state.lock();
    
    if let Some(index) = app_state.ai_prompts.iter().position(|p| p.id == prompt_id) {
        let removed_prompt = app_state.ai_prompts.remove(index);
        println!("ğŸ—‘ï¸ å·²åˆ é™¤AIæç¤º: {}", removed_prompt.name);
        Ok(())
    } else {
        Err("æœªæ‰¾åˆ°æŒ‡å®šçš„AIæç¤º".to_string())
    }
}

#[tauri::command]
async fn activate_ai_prompt(
    prompt_id: String,
    agent_type: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let mut app_state = state.lock();
    
    // é¦–å…ˆå°†åŒç±»å‹çš„å…¶ä»–æç¤ºè®¾ä¸ºéæ¿€æ´»çŠ¶æ€
    for prompt in app_state.ai_prompts.iter_mut() {
        if prompt.agent_type == agent_type {
            prompt.is_active = prompt.id == prompt_id;
        }
    }
    
    println!("âœ… å·²æ¿€æ´»AIæç¤º: {}", prompt_id);
    Ok(())
}

#[tauri::command]
async fn process_with_agent(
    request: AgentRequest,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<AgentResponse, String> {
    let start_time = SystemTime::now();
    
    println!("ğŸ¤– å¼€å§‹å¤„ç†Agentè¯·æ±‚: {}", request.agent_type);
    
    // è·å–API keyå’ŒHTTPå®¢æˆ·ç«¯
    let (api_key, client) = {
        let app_state = state.lock();
        let api_key = app_state.openai_api_key.clone()
            .ok_or("OpenAI API key not configured")?;
        (api_key, app_state.http_client.clone())
    };
    
    // åˆ›å»ºAI Agent
    let agent = ai_agent::AIAgent::new(api_key, client);
    
    // è½¬æ¢agentç±»å‹
    let agent_type = match request.agent_type.as_str() {
        "text_enhancement" => ai_agent::AIAgentType::TextEnhancement,
        "translation" => ai_agent::AIAgentType::Translation,
        "summarization" => ai_agent::AIAgentType::Summarization,
        "grammar_correction" => ai_agent::AIAgentType::GrammarCorrection,
        "tone_adjustment" => ai_agent::AIAgentType::ToneAdjustment,
        "keyword_extraction" => ai_agent::AIAgentType::KeywordExtraction,
        "code_explanation" => ai_agent::AIAgentType::CodeExplanation,
        _ => ai_agent::AIAgentType::Custom,
    };
    
    // å‡†å¤‡é€‰é¡¹
    let mut options = request.additional_context.unwrap_or_default();
    
    // å¦‚æœæ˜¯è‡ªå®šä¹‰ç±»å‹ï¼Œæ·»åŠ æç¤ºè¯
    if matches!(agent_type, ai_agent::AIAgentType::Custom) {
        let prompt_text = if let Some(prompt_id) = &request.prompt_id {
            let app_state = state.lock();
            app_state.ai_prompts.iter()
                .find(|p| p.id == *prompt_id && p.is_active)
                .map(|p| p.prompt_text.clone())
                .unwrap_or_else(|| get_default_prompt(&request.agent_type))
        } else {
            // è·å–è¯¥ç±»å‹çš„æ¿€æ´»æç¤ºæˆ–é»˜è®¤æç¤º
            let app_state = state.lock();
            app_state.ai_prompts.iter()
                .find(|p| p.agent_type == request.agent_type && p.is_active)
                .map(|p| p.prompt_text.clone())
                .unwrap_or_else(|| get_default_prompt(&request.agent_type))
        };
        options.insert("system_prompt".to_string(), prompt_text);
    }
    
    // åˆ›å»ºAI Agentè¯·æ±‚
    let ai_request = ai_agent::AIAgentRequest {
        text: request.input_text.clone(),
        agent_type,
        options,
    };
    
    // è°ƒç”¨AI Agentå¤„ç†
    match agent.process(ai_request).await {
        Ok(ai_response) => {
            let processing_time = start_time.elapsed().unwrap().as_millis() as u64;
            
            println!("âœ… Agentå¤„ç†å®Œæˆ: {} ({}ms)", request.agent_type, processing_time);
            
            Ok(AgentResponse {
                success: true,
                output_text: ai_response.processed_text,
                agent_type: request.agent_type,
                processing_time_ms: processing_time,
                error: None,
            })
        },
        Err(e) => {
            let processing_time = start_time.elapsed().unwrap().as_millis() as u64;
            eprintln!("âŒ Agentå¤„ç†å¤±è´¥: {}", e);
            
            Ok(AgentResponse {
                success: false,
                output_text: String::new(),
                agent_type: request.agent_type,
                processing_time_ms: processing_time,
                error: Some(e),
            })
        }
    }
}


async fn transcribe_audio_file(client: &Client, api_key: &str, audio_file_path: &PathBuf, model: &str) -> Result<TranscriptionResult, String> {
    // è¯»å–éŸ³é¢‘æ–‡ä»¶
    let mut file = File::open(audio_file_path).await
        .map_err(|e| format!("Failed to open audio file: {}", e))?;
    
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer).await
        .map_err(|e| format!("Failed to read audio file: {}", e))?;
    
    // åˆ›å»º multipart form æ•°æ®
    let part = Part::bytes(buffer)
        .file_name("audio.wav")
        .mime_str("audio/wav")
        .map_err(|e| format!("Failed to create part: {}", e))?;
    
    println!("ğŸ” è°ƒè¯•ä¿¡æ¯: å‘é€åˆ°APIçš„æ¨¡å‹å‚æ•° = '{}'", model);
    
    let form = Form::new()
        .part("file", part)
        .text("model", model.to_string())
        .text("language", "zh")
        .text("response_format", "verbose_json"); // ä¸­æ–‡è¯­è¨€æç¤ºå’Œè¯¦ç»†å“åº”æ ¼å¼
    
    // å‘é€è¯·æ±‚åˆ° NewAPI (æ”¯æŒ GPT-4o mini è½¬å½•)
    let response = client
        .post("https://ttkk.inping.com/v1/audio/transcriptions")
        .header("Authorization", format!("Bearer {}", api_key))
        .multipart(form)
        .send()
        .await
        .map_err(|e| format!("Failed to send request: {}", e))?;
    
    if !response.status().is_success() {
        let error_text = response.text().await.unwrap_or_else(|_| "Unknown error".to_string());
        return Err(format!("API request failed: {}", error_text));
    }
    
    // è§£æå“åº”
    let response_text = response.text().await
        .map_err(|e| format!("Failed to read response: {}", e))?;
    
    let json: serde_json::Value = serde_json::from_str(&response_text)
        .map_err(|e| format!("Failed to parse JSON response: {}", e))?;
    
    let text = json["text"].as_str()
        .ok_or_else(|| "No text field in response".to_string())?
        .to_string();
    
    
    Ok(TranscriptionResult { text })
}

// çœŸå®æ¥å…¥ï¼šly.gl173.com å½•éŸ³è½¬æ–‡å­—æœåŠ¡
async fn transcribe_via_luyin_api(client: &Client, audio_file_path: &PathBuf) -> Result<TranscriptionResult, String> {
    // è¯»å–éŸ³é¢‘æ–‡ä»¶
    let mut file = File::open(audio_file_path).await
        .map_err(|e| format!("æ— æ³•æ‰“å¼€éŸ³é¢‘æ–‡ä»¶: {}", e))?;
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer).await
        .map_err(|e| format!("æ— æ³•è¯»å–éŸ³é¢‘æ–‡ä»¶: {}", e))?;

    // 1) ä¸Šä¼ æ–‡ä»¶ï¼Œè·å– file_id
    let file_name = audio_file_path.file_name()
        .and_then(|n| n.to_str())
        .unwrap_or("recording.wav");
    let part = Part::bytes(buffer)
        .file_name(file_name.to_string())
        .mime_str("audio/wav")
        .map_err(|e| format!("åˆ›å»ºä¸Šä¼ éƒ¨ä»¶å¤±è´¥: {}", e))?;

    let form = Form::new().part("file[]", part);
    let upload_resp = client
        .post("https://ly.gl173.com/api/v1/upload-file")
        .multipart(form)
        .send()
        .await
        .map_err(|e| format!("ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {}", e))?;

    let status = upload_resp.status();
    let upload_text = upload_resp.text().await.unwrap_or_default();
    if !status.is_success() {
        return Err(format!("ä¸Šä¼ æ¥å£é”™è¯¯({}): {}", status, upload_text));
    }
    let upload_json: serde_json::Value = serde_json::from_str(&upload_text)
        .map_err(|e| format!("è§£æä¸Šä¼ å“åº”å¤±è´¥: {} - {}", e, upload_text))?;
    if upload_json["code"].as_i64().unwrap_or(0) != 200 {
        return Err(format!("ä¸Šä¼ è¿”å›é200: {}", upload_text));
    }
    let file_id_val = upload_json["data"][0]["file_id"].clone();
    let file_id = if let Some(id) = file_id_val.as_i64() { id.to_string() } else { file_id_val.to_string() };
    if file_id.is_empty() || file_id == "null" {
        return Err(format!("æ— æ³•è·å–file_id: {}", upload_text));
    }

    // 2) åˆ›å»ºè½¬æ¢ä»»åŠ¡ï¼Œå¾—åˆ° task_id
    let task_resp = client
        .post("https://ly.gl173.com/api/v1/task-add")
        .form(&[("file_id", file_id.clone())])
        .send()
        .await
        .map_err(|e| format!("åˆ›å»ºè½¬æ¢ä»»åŠ¡å¤±è´¥: {}", e))?;
    let task_text = task_resp.text().await.unwrap_or_default();
    let task_json: serde_json::Value = serde_json::from_str(&task_text)
        .map_err(|e| format!("è§£æä»»åŠ¡åˆ›å»ºå“åº”å¤±è´¥: {} - {}", e, task_text))?;
    if task_json["code"].as_i64().unwrap_or(0) != 200 {
        return Err(format!("ä»»åŠ¡åˆ›å»ºè¿”å›é200: {}", task_text));
    }
    let task_id = task_json["data"]["task_id"].as_str()
        .unwrap_or("")
        .to_string();
    if task_id.is_empty() {
        return Err(format!("æ— æ³•è·å–task_id: {}", task_text));
    }

    // 3) è½®è¯¢è¿›åº¦ï¼Œç›´åˆ°å®Œæˆæˆ–è¶…æ—¶
    let mut attempts = 0usize;
    let max_attempts = 60usize; // 3 åˆ†é’Ÿ
    loop {
        attempts += 1;
        let progress_resp = client
            .post("https://ly.gl173.com/api/v1/task-progress")
            .form(&[("task_id", task_id.clone())])
            .send()
            .await
            .map_err(|e| format!("æŸ¥è¯¢è¿›åº¦å¤±è´¥: {}", e))?;

        let progress_text = progress_resp.text().await.unwrap_or_default();
        let progress_json: serde_json::Value = serde_json::from_str(&progress_text)
            .map_err(|e| format!("è§£æè¿›åº¦å“åº”å¤±è´¥: {} - {}", e, progress_text))?;
        if progress_json["code"].as_i64().unwrap_or(0) != 200 {
            return Err(format!("è¿›åº¦æ¥å£è¿”å›é200: {}", progress_text));
        }

        let progress = progress_json["data"]["progress"].as_i64().unwrap_or(0);
        if progress == 1 {
            let result = progress_json["data"]["result"].as_str().unwrap_or("").to_string();
            if result.is_empty() {
                return Err("è½¬æ¢å®Œæˆä½†ç»“æœä¸ºç©º".to_string());
            }
            return Ok(TranscriptionResult { text: result });
        }

        if attempts >= max_attempts {
            return Err("è½¬æ¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•".to_string());
        }

        tokio::time::sleep(std::time::Duration::from_secs(3)).await;
    }
}

// æœ¬åœ° Whisper æ¨¡å‹è½¬å½•å‡½æ•°ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰
async fn transcribe_with_local_whisper(audio_file_path: &PathBuf, model: &str) -> Result<TranscriptionResult, String> {
    println!("ğŸ” å¼€å§‹æœ¬åœ° Whisper {} è½¬å½•ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰...", model);
    
    // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if !audio_file_path.exists() {
        return Err("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨".to_string());
    }
    
    // åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œ Whisperï¼ˆå› ä¸ºå®ƒæ˜¯è®¡ç®—å¯†é›†å‹çš„ï¼‰
    let audio_path = audio_file_path.clone();
    let model_name = model.to_string();
    
    let transcription_result = tokio::task::spawn_blocking(move || {
        run_whisper_transcription_optimized(&audio_path, &model_name)
    }).await;
    
    match transcription_result {
        Ok(Ok((text, metrics))) => {
            println!("âœ… æœ¬åœ° Whisper è½¬å½•æˆåŠŸ: {}", text);
            println!("ğŸ“Š æ€§èƒ½æŒ‡æ ‡: RTF={:.2}, æ€»è€—æ—¶={}ms", 
                    metrics.real_time_factor, metrics.total_time_ms);
            Ok(TranscriptionResult { text })
        },
        Ok(Err(e)) => {
            println!("âŒ æœ¬åœ° Whisper è½¬å½•å¤±è´¥: {}", e);
            Err(e)
        },
        Err(e) => {
            println!("âŒ Whisper ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {}", e);
            Err(format!("è½¬å½•ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {}", e))
        }
    }
}

// æ€§èƒ½ä¼˜åŒ–ç‰ˆ Whisper è½¬å½•
fn run_whisper_transcription_optimized(audio_file_path: &PathBuf, model: &str) -> Result<(String, performance_optimizer::PerformanceMetrics), String> {
    let total_start = std::time::Instant::now();
    let mut metrics = performance_optimizer::PerformanceMetrics::default();
    
    // åˆ›å»ºæ€§èƒ½ä¼˜åŒ–å™¨
    let mut optimizer = performance_optimizer::PerformanceOptimizer::new();
    
    // ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
    let model_path = download_whisper_model_if_needed(model)?;
    
    // ä¼˜åŒ–ç‰ˆæ¨¡å‹åŠ è½½ï¼ˆå¸¦ç¼“å­˜ï¼‰
    let model_start = std::time::Instant::now();
    let ctx = optimizer.get_cached_model(&model_path)?;
    metrics.model_load_time_ms = model_start.elapsed().as_millis() as u64;
    
    println!("ğŸ” è¯»å–éŸ³é¢‘æ–‡ä»¶...");
    
    // ä¼˜åŒ–ç‰ˆéŸ³é¢‘æ•°æ®åŠ è½½
    let audio_start = std::time::Instant::now();
    let audio_data = load_audio_samples_optimized(audio_file_path, &mut optimizer)?;
    metrics.audio_processing_time_ms = audio_start.elapsed().as_millis() as u64;
    
    // è®¡ç®—éŸ³é¢‘æ—¶é•¿
    metrics.audio_duration_seconds = audio_data.len() as f64 / 16000.0; // 16kHzé‡‡æ ·ç‡
    
    println!("ğŸ” å¼€å§‹è½¬å½•ï¼ŒéŸ³é¢‘æ ·æœ¬æ•°: {} (æ—¶é•¿: {:.2}s)", 
             audio_data.len(), metrics.audio_duration_seconds);
    
    // è·å–ä¼˜åŒ–çš„è½¬å½•å‚æ•°
    let params = optimizer.get_optimized_transcription_params();
    
    // è¿è¡Œè½¬å½•
    let transcription_start = std::time::Instant::now();
    let mut state = ctx.create_state()
        .map_err(|e| format!("æ— æ³•åˆ›å»º Whisper çŠ¶æ€: {}", e))?;
    
    state.full(params, &audio_data)
        .map_err(|e| format!("Whisper è½¬å½•å¤±è´¥: {}", e))?;
    
    metrics.transcription_time_ms = transcription_start.elapsed().as_millis() as u64;
    
    // è·å–è½¬å½•ç»“æœ
    let num_segments = state.full_n_segments()
        .map_err(|e| format!("æ— æ³•è·å–åˆ†æ®µæ•°é‡: {}", e))?;
    
    let mut full_text = String::new();
    for i in 0..num_segments {
        let segment = state.full_get_segment_text(i)
            .map_err(|e| format!("æ— æ³•è·å–åˆ†æ®µæ–‡æœ¬: {}", e))?;
        full_text.push_str(&segment);
        full_text.push(' ');
    }
    
    let result = full_text.trim().to_string();
    
    // è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    metrics.total_time_ms = total_start.elapsed().as_millis() as u64;
    metrics.real_time_factor = optimizer.calculate_rtf(metrics.transcription_time_ms, metrics.audio_duration_seconds);
    
    // è·å–ç³»ç»ŸæŒ‡æ ‡
    if let Ok((cpu_usage, memory_usage)) = optimizer.get_system_metrics() {
        metrics.cpu_usage_percent = cpu_usage;
        metrics.gpu_memory_usage_mb = memory_usage; // è¿™é‡Œç”¨å†…å­˜ä½¿ç”¨ä»£æ›¿GPUå†…å­˜
    }
    
    println!("âœ… è½¬å½•å®Œæˆï¼Œç»“æœé•¿åº¦: {} å­—ç¬¦", result.len());
    println!("ğŸ“Š è¯¦ç»†æ€§èƒ½æŒ‡æ ‡:");
    println!("   - æ¨¡å‹åŠ è½½: {}ms", metrics.model_load_time_ms);
    println!("   - éŸ³é¢‘å¤„ç†: {}ms", metrics.audio_processing_time_ms);
    println!("   - è½¬å½•æ—¶é—´: {}ms", metrics.transcription_time_ms);
    println!("   - æ€»è€—æ—¶: {}ms", metrics.total_time_ms);
    println!("   - RTF: {:.3} (ç›®æ ‡: <0.3)", metrics.real_time_factor);
    println!("   - CPUä½¿ç”¨: {:.1}%", metrics.cpu_usage_percent);
    
    if result.is_empty() {
        return Err("è½¬å½•ç»“æœä¸ºç©ºï¼Œå¯èƒ½éŸ³é¢‘æ–‡ä»¶æ— æ•ˆæˆ–å¤ªçŸ­".to_string());
    }
    
    Ok((result, metrics))
}

// åŒæ­¥è¿è¡Œ Whisper è½¬å½•ï¼ˆåŸç‰ˆï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
fn run_whisper_transcription(audio_file_path: &PathBuf, model: &str) -> Result<String, String> {
    // é¦–å…ˆå°è¯•ä¸‹è½½å¹¶ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
    let model_path = download_whisper_model_if_needed(model)?;
    
    println!("ğŸ” åŠ è½½ Whisper æ¨¡å‹: {}", model_path);
    
    // åˆå§‹åŒ– Whisper ä¸Šä¸‹æ–‡
    let ctx = WhisperContext::new_with_params(&model_path, WhisperContextParameters::default())
        .map_err(|e| format!("æ— æ³•åŠ è½½ Whisper æ¨¡å‹: {}", e))?;
    
    println!("ğŸ” è¯»å–éŸ³é¢‘æ–‡ä»¶...");
    
    // è¯»å–éŸ³é¢‘æ•°æ®
    let audio_data = load_audio_samples(audio_file_path)?;
    
    println!("ğŸ” å¼€å§‹è½¬å½•ï¼ŒéŸ³é¢‘æ ·æœ¬æ•°: {}", audio_data.len());
    
    // è®¾ç½®è½¬å½•å‚æ•°
    let mut params = FullParams::new(SamplingStrategy::Greedy { best_of: 1 });
    params.set_language(Some("auto"));
    params.set_translate(false);
    params.set_print_special(false);
    params.set_print_progress(false);
    params.set_print_realtime(false);
    params.set_print_timestamps(false);
    
    // è¿è¡Œè½¬å½•
    let mut state = ctx.create_state()
        .map_err(|e| format!("æ— æ³•åˆ›å»º Whisper çŠ¶æ€: {}", e))?;
    
    state.full(params, &audio_data)
        .map_err(|e| format!("Whisper è½¬å½•å¤±è´¥: {}", e))?;
    
    // è·å–è½¬å½•ç»“æœ
    let num_segments = state.full_n_segments()
        .map_err(|e| format!("æ— æ³•è·å–åˆ†æ®µæ•°é‡: {}", e))?;
    
    let mut full_text = String::new();
    for i in 0..num_segments {
        let segment = state.full_get_segment_text(i)
            .map_err(|e| format!("æ— æ³•è·å–åˆ†æ®µæ–‡æœ¬: {}", e))?;
        full_text.push_str(&segment);
        full_text.push(' ');
    }
    
    let result = full_text.trim().to_string();
    println!("âœ… è½¬å½•å®Œæˆï¼Œç»“æœé•¿åº¦: {} å­—ç¬¦", result.len());
    
    if result.is_empty() {
        return Err("è½¬å½•ç»“æœä¸ºç©ºï¼Œå¯èƒ½éŸ³é¢‘æ–‡ä»¶æ— æ•ˆæˆ–å¤ªçŸ­".to_string());
    }
    
    Ok(result)
}

// ä¸‹è½½ Whisper æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
fn download_whisper_model_if_needed(model: &str) -> Result<String, String> {
    let model_path = get_local_model_path(model);
    
    if PathBuf::from(&model_path).exists() {
        println!("âœ… æ‰¾åˆ°æœ¬åœ°æ¨¡å‹æ–‡ä»¶: {}", model_path);
        return Ok(model_path);
    }
    
    // åˆ›å»ºæ¨¡å‹ç›®å½•
    let model_path_buf = PathBuf::from(&model_path);
    let model_dir = model_path_buf.parent()
        .ok_or("æ— æ³•è·å–æ¨¡å‹ç›®å½•")?;
    
    std::fs::create_dir_all(model_dir)
        .map_err(|e| format!("æ— æ³•åˆ›å»ºæ¨¡å‹ç›®å½•: {}", e))?;
    
    // å°è¯•ä¸‹è½½æ¨¡å‹
    println!("ğŸ“¥ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä¸‹è½½: {}", model);
    download_whisper_model(model, &model_path)?;
    
    Ok(model_path)
}

// ä¸‹è½½ Whisper æ¨¡å‹æ–‡ä»¶
fn download_whisper_model(model: &str, model_path: &str) -> Result<(), String> {
    let model_url = get_whisper_model_url(model)?;
    
    println!("ğŸ“¥ å¼€å§‹ä¸‹è½½æ¨¡å‹: {} -> {}", model_url, model_path);
    
    // ä½¿ç”¨ curl ä¸‹è½½æ¨¡å‹ï¼ˆç®€å•å®ç°ï¼‰
    let output = std::process::Command::new("curl")
        .args(&["-L", "-o", model_path, &model_url])
        .output()
        .map_err(|e| format!("ä¸‹è½½å‘½ä»¤æ‰§è¡Œå¤±è´¥: {}", e))?;
    
    if !output.status.success() {
        let error = String::from_utf8_lossy(&output.stderr);
        return Err(format!("æ¨¡å‹ä¸‹è½½å¤±è´¥: {}", error));
    }
    
    println!("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {}", model_path);
    Ok(())
}

// è·å– Whisper æ¨¡å‹ä¸‹è½½ URL
fn get_whisper_model_url(model: &str) -> Result<String, String> {
    let base_url = "https://huggingface.co/ggerganov/whisper.cpp/resolve/main";
    let model_file = match model {
        "whisper-tiny" => "ggml-tiny.bin",
        "whisper-base" => "ggml-base.bin", 
        "whisper-small" => "ggml-small.bin",
        "whisper-medium" => "ggml-medium.bin",
        "whisper-large-v3" => "ggml-large-v3.bin",
        "whisper-large-v3-turbo" => "ggml-large-v3-turbo.bin",
        _ => return Err(format!("ä¸æ”¯æŒçš„æ¨¡å‹: {}", model))
    };
    
    Ok(format!("{}/{}", base_url, model_file))
}

// ä¼˜åŒ–ç‰ˆéŸ³é¢‘æ ·æœ¬åŠ è½½
fn load_audio_samples_optimized(audio_file_path: &PathBuf, optimizer: &mut performance_optimizer::PerformanceOptimizer) -> Result<Vec<f32>, String> {
    println!("ğŸ” è¯»å–éŸ³é¢‘æ–‡ä»¶ï¼ˆä¼˜åŒ–ç‰ˆï¼‰: {:?}", audio_file_path);
    
    // è¯»å– WAV æ–‡ä»¶
    let mut reader = hound::WavReader::open(audio_file_path)
        .map_err(|e| format!("æ— æ³•æ‰“å¼€éŸ³é¢‘æ–‡ä»¶: {}", e))?;
    
    let spec = reader.spec();
    println!("ğŸ” éŸ³é¢‘è§„æ ¼: {}Hz, {} å£°é“, {} ä½", spec.sample_rate, spec.channels, spec.bits_per_sample);
    
    // è¯»å–æ ·æœ¬
    let samples: Result<Vec<i16>, _> = reader.samples().collect();
    let samples = samples.map_err(|e| format!("æ— æ³•è¯»å–éŸ³é¢‘æ ·æœ¬: {}", e))?;
    
    // è½¬æ¢ä¸º f32
    let mut float_samples: Vec<f32> = samples.iter()
        .map(|&s| s as f32 / 32768.0)
        .collect();
    
    // å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬æ¢ä¸ºå•å£°é“
    if spec.channels == 2 {
        let mono_samples: Vec<f32> = float_samples.chunks(2)
            .map(|chunk| (chunk[0] + chunk.get(1).unwrap_or(&0.0)) / 2.0)
            .collect();
        float_samples = mono_samples;
    }
    
    // ä½¿ç”¨æ€§èƒ½ä¼˜åŒ–å™¨è¿›è¡Œå¿«é€Ÿé‡é‡‡æ ·
    let final_samples = optimizer.preprocess_audio_fast(&float_samples, spec.sample_rate)?;
    
    println!("âœ… éŸ³é¢‘å¤„ç†å®Œæˆï¼Œæ ·æœ¬æ•°: {}", final_samples.len());
    Ok(final_samples)
}

// åŠ è½½éŸ³é¢‘æ ·æœ¬æ•°æ®ï¼ˆåŸç‰ˆï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
fn load_audio_samples(audio_file_path: &PathBuf) -> Result<Vec<f32>, String> {
    println!("ğŸ” è¯»å–éŸ³é¢‘æ–‡ä»¶: {:?}", audio_file_path);
    
    // è¯»å– WAV æ–‡ä»¶
    let mut reader = hound::WavReader::open(audio_file_path)
        .map_err(|e| format!("æ— æ³•æ‰“å¼€éŸ³é¢‘æ–‡ä»¶: {}", e))?;
    
    let spec = reader.spec();
    println!("ğŸ” éŸ³é¢‘è§„æ ¼: {}Hz, {} å£°é“, {} ä½", spec.sample_rate, spec.channels, spec.bits_per_sample);
    
    // Whisper éœ€è¦ 16kHz å•å£°é“
    let target_sample_rate = 16000;
    
    // è¯»å–æ ·æœ¬
    let samples: Result<Vec<i16>, _> = reader.samples().collect();
    let samples = samples.map_err(|e| format!("æ— æ³•è¯»å–éŸ³é¢‘æ ·æœ¬: {}", e))?;
    
    // è½¬æ¢ä¸º f32 å¹¶é‡é‡‡æ ·åˆ° 16kHz
    let mut float_samples: Vec<f32> = samples.iter()
        .map(|&s| s as f32 / 32768.0)
        .collect();
    
    // å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬æ¢ä¸ºå•å£°é“
    if spec.channels == 2 {
        let mono_samples: Vec<f32> = float_samples.chunks(2)
            .map(|chunk| (chunk[0] + chunk.get(1).unwrap_or(&0.0)) / 2.0)
            .collect();
        float_samples = mono_samples;
    }
    
    // ç®€å•é‡é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if spec.sample_rate != target_sample_rate {
        println!("ğŸ” é‡é‡‡æ ·: {}Hz -> {}Hz", spec.sample_rate, target_sample_rate);
        let ratio = target_sample_rate as f32 / spec.sample_rate as f32;
        let new_length = (float_samples.len() as f32 * ratio) as usize;
        
        let mut resampled = Vec::with_capacity(new_length);
        for i in 0..new_length {
            let src_index = (i as f32 / ratio) as usize;
            if src_index < float_samples.len() {
                resampled.push(float_samples[src_index]);
            }
        }
        float_samples = resampled;
    }
    
    println!("âœ… éŸ³é¢‘å¤„ç†å®Œæˆï¼Œæ ·æœ¬æ•°: {}", float_samples.len());
    Ok(float_samples)
}

// è·å–æœ¬åœ°æ¨¡å‹æ–‡ä»¶è·¯å¾„
fn get_local_model_path(model: &str) -> String {
    let home_dir = std::env::var("HOME").unwrap_or_else(|_| ".".to_string());
    format!("{}/Library/Application Support/spokenly-clone/models/{}.bin", home_dir, model)
}

fn get_default_prompt(agent_type: &str) -> String {
    match agent_type {
        "speech-to-text" => "è¯·å°†ä»¥ä¸‹è¯­éŸ³å†…å®¹è½¬æ¢ä¸ºå‡†ç¡®çš„æ–‡æœ¬ï¼Œä¿æŒåŸæ„ä¸å˜ï¼š",
        "text-enhancer" => "è¯·ä¼˜åŒ–ä»¥ä¸‹æ–‡æœ¬ï¼Œä½¿å…¶æ›´æ¸…æ™°ã€å‡†ç¡®å’Œä¸“ä¸šï¼š",
        "translator" => "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘ä¸ºæŒ‡å®šçš„ç›®æ ‡è¯­è¨€ï¼Œä¿æŒåŸæ„å’Œè¯­è°ƒï¼š",
        "summarizer" => "è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆç®€æ´æ˜äº†çš„æ‘˜è¦ï¼Œçªå‡ºè¦ç‚¹ï¼š",
        "formatter" => "è¯·å°†ä»¥ä¸‹å†…å®¹æ ¼å¼åŒ–ï¼Œä½¿ç»“æ„æ¸…æ™°ï¼Œæ˜“äºé˜…è¯»ï¼š",
        "grammar-check" => "è¯·æ£€æŸ¥ä»¥ä¸‹æ–‡æœ¬çš„è¯­æ³•é”™è¯¯å¹¶æä¾›ä¿®æ­£å»ºè®®ï¼š",
        "tone-adjuster" => "è¯·è°ƒæ•´ä»¥ä¸‹æ–‡æœ¬çš„è¯­è°ƒå’Œé£æ ¼ï¼Œä½¿å…¶ç¬¦åˆæŒ‡å®šè¦æ±‚ï¼š",
        "auto-input" => "è¯·åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆåˆé€‚çš„æ–‡æœ¬è¾“å…¥å†…å®¹ï¼š",
        _ => "è¯·å¤„ç†ä»¥ä¸‹å†…å®¹ï¼š"
    }.to_string()
}

async fn call_openai_api(
    request: &AgentRequest,
    prompt_text: &str,
    state: &tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<String, String> {
    let (client, api_key) = {
        let app_state = state.lock();
        (app_state.http_client.clone(), app_state.openai_api_key.clone())
    };
    
    let api_key = api_key.ok_or("æœªè®¾ç½®OpenAI APIå¯†é’¥")?;
    
    // æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
    let mut context = String::new();
    if let Some(additional_context) = &request.additional_context {
        for (key, value) in additional_context {
            context.push_str(&format!("{}: {}\n", key, value));
        }
    }
    
    // æ„å»ºå®Œæ•´çš„æç¤ºè¯
    let full_prompt = if context.is_empty() {
        format!("{}\n\n{}", prompt_text, request.input_text)
    } else {
        format!("{}\n\nä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š\n{}\nå¾…å¤„ç†å†…å®¹ï¼š\n{}", prompt_text, context, request.input_text)
    };
    
    let openai_request = OpenAIRequest {
        model: "gpt-3.5-turbo".to_string(),  // ä½¿ç”¨ GPT-3.5 æ¨¡å‹è¿›è¡Œå¯¹è¯
        messages: vec![
            OpenAIMessage {
                role: "user".to_string(),
                content: full_prompt,
            }
        ],
        temperature: 0.7,
        max_tokens: Some(2000),
    };
    
    println!("ğŸ“¡ å‘é€OpenAI APIè¯·æ±‚...");
    
    let response = client
        .post("https://ttkk.inping.com/v1/chat/completions")
        .header("Authorization", format!("Bearer {}", api_key))
        .header("Content-Type", "application/json")
        .json(&openai_request)
        .send()
        .await
        .map_err(|e| format!("ç½‘ç»œè¯·æ±‚å¤±è´¥: {}", e))?;
    
    if !response.status().is_success() {
        let error_text = response.text().await.unwrap_or_default();
        return Err(format!("OpenAI APIé”™è¯¯: {}", error_text));
    }
    
    let openai_response: OpenAIResponse = response.json().await
        .map_err(|e| format!("è§£æå“åº”å¤±è´¥: {}", e))?;
    
    if let Some(choice) = openai_response.choices.first() {
        Ok(choice.message.content.clone())
    } else {
        Err("OpenAIå“åº”ä¸ºç©º".to_string())
    }
}

#[tauri::command]
async fn set_openai_api_key(
    api_key: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let mut app_state = state.lock();
    app_state.openai_api_key = Some(api_key);
    println!("ğŸ”‘ OpenAI APIå¯†é’¥å·²æ›´æ–°");
    Ok(())
}

#[tauri::command]
async fn get_agent_types() -> Result<Vec<String>, String> {
    Ok(vec![
        "speech-to-text".to_string(),
        "text-enhancer".to_string(),
        "translator".to_string(),
        "summarizer".to_string(),
        "formatter".to_string(),
        "grammar-check".to_string(),
        "tone-adjuster".to_string(),
        "auto-input".to_string(),
    ])
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentChain {
    pub chain_id: String,
    pub name: String,
    pub description: String,
    pub agents: Vec<String>, // Agentç±»å‹çš„æœ‰åºåˆ—è¡¨
    pub is_active: bool,
    pub created_at: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChainProcessRequest {
    pub chain_id: String,
    pub input_text: String,
    pub additional_context: Option<HashMap<String, String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChainProcessResponse {
    pub success: bool,
    pub final_output: String,
    pub chain_id: String,
    pub step_results: Vec<AgentResponse>,
    pub total_processing_time_ms: u64,
    pub error: Option<String>,
}

#[tauri::command]
async fn process_with_chain(
    request: ChainProcessRequest,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<ChainProcessResponse, String> {
    let start_time = SystemTime::now();
    
    println!("ğŸ”— å¼€å§‹é“¾å¼å¤„ç†: {}", request.chain_id);
    
    // è·å–é“¾é…ç½®
    let agents = {
        // è¿™é‡Œå¯ä»¥å­˜å‚¨åœ¨AppStateä¸­æˆ–ä»é…ç½®æ–‡ä»¶è¯»å–
        // æš‚æ—¶è¿”å›ä¸€ä¸ªç¤ºä¾‹é“¾
        match request.chain_id.as_str() {
            "enhance-translate-summarize" => vec![
                "text-enhancer".to_string(),
                "translator".to_string(),
                "summarizer".to_string()
            ],
            "grammar-format" => vec![
                "grammar-check".to_string(),
                "formatter".to_string()
            ],
            "speech-enhance-input" => vec![
                "speech-to-text".to_string(),
                "text-enhancer".to_string(),
                "auto-input".to_string()
            ],
            _ => return Err("æœªçŸ¥çš„å¤„ç†é“¾".to_string())
        }
    };
    
    let mut current_text = request.input_text;
    let mut step_results = Vec::new();
    
    // é€æ­¥å¤„ç†æ¯ä¸ªAgent
    for (index, agent_type) in agents.iter().enumerate() {
        println!("ğŸ¤– å¤„ç†æ­¥éª¤ {}/{}: {}", index + 1, agents.len(), agent_type);
        
        let agent_request = AgentRequest {
            agent_type: agent_type.clone(),
            input_text: current_text.clone(),
            prompt_id: None,
            additional_context: request.additional_context.clone(),
        };
        
        match process_with_agent(agent_request, state.clone()).await {
            Ok(result) => {
                if result.success {
                    current_text = result.output_text.clone();
                    step_results.push(result);
                } else {
                    let total_time = start_time.elapsed().unwrap().as_millis() as u64;
                    return Ok(ChainProcessResponse {
                        success: false,
                        final_output: String::new(),
                        chain_id: request.chain_id,
                        step_results,
                        total_processing_time_ms: total_time,
                        error: result.error,
                    });
                }
            },
            Err(e) => {
                let total_time = start_time.elapsed().unwrap().as_millis() as u64;
                return Ok(ChainProcessResponse {
                    success: false,
                    final_output: String::new(),
                    chain_id: request.chain_id,
                    step_results,
                    total_processing_time_ms: total_time,
                    error: Some(e),
                });
            }
        }
    }
    
    let total_time = start_time.elapsed().unwrap().as_millis() as u64;
    
    println!("âœ… é“¾å¼å¤„ç†å®Œæˆ: {} ({}ms)", request.chain_id, total_time);
    
    Ok(ChainProcessResponse {
        success: true,
        final_output: current_text,
        chain_id: request.chain_id,
        step_results,
        total_processing_time_ms: total_time,
        error: None,
    })
}

#[tauri::command]
async fn get_available_chains() -> Result<Vec<AgentChain>, String> {
    let timestamp = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
    
    Ok(vec![
        AgentChain {
            chain_id: "enhance-translate-summarize".to_string(),
            name: "å¢å¼º-ç¿»è¯‘-æ‘˜è¦".to_string(),
            description: "å…ˆä¼˜åŒ–æ–‡æœ¬ï¼Œç„¶åç¿»è¯‘ï¼Œæœ€åç”Ÿæˆæ‘˜è¦".to_string(),
            agents: vec!["text-enhancer".to_string(), "translator".to_string(), "summarizer".to_string()],
            is_active: true,
            created_at: timestamp,
        },
        AgentChain {
            chain_id: "grammar-format".to_string(),
            name: "è¯­æ³•æ£€æŸ¥-æ ¼å¼åŒ–".to_string(),
            description: "æ£€æŸ¥è¯­æ³•é”™è¯¯å¹¶æ ¼å¼åŒ–æ–‡æœ¬".to_string(),
            agents: vec!["grammar-check".to_string(), "formatter".to_string()],
            is_active: true,
            created_at: timestamp,
        },
        AgentChain {
            chain_id: "speech-enhance-input".to_string(),
            name: "è¯­éŸ³-å¢å¼º-è‡ªåŠ¨è¾“å…¥".to_string(),
            description: "è¯­éŸ³è½¬æ–‡å­—ï¼Œå¢å¼ºå†…å®¹ï¼Œç”Ÿæˆè¾“å…¥å†…å®¹".to_string(),
            agents: vec!["speech-to-text".to_string(), "text-enhancer".to_string(), "auto-input".to_string()],
            is_active: true,
            created_at: timestamp,
        },
    ])
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BatchProcessRequest {
    pub agent_type: String,
    pub input_texts: Vec<String>,
    pub prompt_id: Option<String>,
    pub additional_context: Option<HashMap<String, String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BatchProcessResponse {
    pub success: bool,
    pub results: Vec<AgentResponse>,
    pub total_processing_time_ms: u64,
    pub success_count: usize,
    pub error_count: usize,
}

#[tokio::main]
async fn main() {
    let app_state = Arc::new(Mutex::new(AppState::new()));
    
    println!("ğŸš€ å¯åŠ¨ Spokenly å…‹éš†åº”ç”¨ï¼ˆæ–‡ä»¶å¤„ç†ç‰ˆï¼‰...");
    
    // åˆ›å»ºç³»ç»Ÿæ‰˜ç›˜èœå•
    let quit = CustomMenuItem::new("quit".to_string(), "é€€å‡º Spokenly");
    let show = CustomMenuItem::new("show".to_string(), "æ˜¾ç¤ºçª—å£");
    let hide = CustomMenuItem::new("hide".to_string(), "éšè—çª—å£");
    let recording = CustomMenuItem::new("toggle_recording".to_string(), "å¼€å§‹/åœæ­¢å½•éŸ³");
    let ai_prompts = CustomMenuItem::new("ai_prompts".to_string(), "AIæç¤º");
    let transcription = CustomMenuItem::new("transcription".to_string(), "å¬å†™æ¨¡å‹");
    let settings = CustomMenuItem::new("settings".to_string(), "å¸¸è§„è®¾ç½®");
    let permissions = CustomMenuItem::new("permissions".to_string(), "æƒé™è®¾ç½®");
    let history = CustomMenuItem::new("history".to_string(), "å†å²è®°å½•");
    let shortcuts = CustomMenuItem::new("shortcuts".to_string(), "å¿«æ·é”®");
    let contact = CustomMenuItem::new("contact".to_string(), "è”ç³»æˆ‘ä»¬");
    
    let tray_menu = SystemTrayMenu::new()
        .add_item(show)
        .add_item(hide)
        .add_native_item(tauri::SystemTrayMenuItem::Separator)
        .add_item(recording)
        .add_native_item(tauri::SystemTrayMenuItem::Separator)
        .add_item(settings)
        .add_item(transcription)
        .add_item(ai_prompts)
        .add_item(permissions)
        .add_item(shortcuts)
        .add_item(history)
        .add_native_item(tauri::SystemTrayMenuItem::Separator)
        .add_item(contact)
        .add_native_item(tauri::SystemTrayMenuItem::Separator)
        .add_item(quit);

    let tray = SystemTray::new().with_menu(tray_menu);

    tauri::Builder::default()
        .system_tray(tray)
        .on_system_tray_event(|app, event| match event {
            SystemTrayEvent::LeftClick {
                position: _,
                size: _,
                ..
            } => {
                // å·¦é”®å•å‡»æ˜¾ç¤º/éšè—ä¸»çª—å£
                let window = app.get_window("main").unwrap();
                if window.is_visible().unwrap() {
                    window.hide().unwrap();
                } else {
                    window.show().unwrap();
                    window.set_focus().unwrap();
                }
            }
            SystemTrayEvent::RightClick {
                position: _,
                size: _,
                ..
            } => {
                // å³é”®å•å‡»æ˜¾ç¤ºèœå•ï¼ˆè‡ªåŠ¨å¤„ç†ï¼‰
            }
            SystemTrayEvent::MenuItemClick { id, .. } => {
                let window = app.get_window("main").unwrap();
                match id.as_str() {
                    "quit" => {
                        std::process::exit(0);
                    }
                    "show" => {
                        window.show().unwrap();
                        window.set_focus().unwrap();
                    }
                    "hide" => {
                        window.hide().unwrap();
                    }
                    "toggle_recording" => {
                        // åˆ‡æ¢å½•éŸ³çŠ¶æ€ - é€šè¿‡emitäº‹ä»¶é€šçŸ¥å‰ç«¯
                        app.emit_all("tray_toggle_recording", {}).unwrap();
                    }
                    "settings" => {
                        window.show().unwrap();
                        window.set_focus().unwrap();
                        app.emit_all("tray_navigate_to", "general").unwrap();
                    }
                    "transcription" => {
                        window.show().unwrap();
                        window.set_focus().unwrap();
                        app.emit_all("tray_navigate_to", "transcription").unwrap();
                    }
                    "ai_prompts" => {
                        window.show().unwrap();
                        window.set_focus().unwrap();
                        app.emit_all("tray_navigate_to", "ai-prompts").unwrap();
                    }
                    "shortcuts" => {
                        window.show().unwrap();
                        window.set_focus().unwrap();
                        app.emit_all("tray_navigate_to", "shortcuts").unwrap();
                    }
                    "history" => {
                        window.show().unwrap();
                        window.set_focus().unwrap();
                        app.emit_all("tray_navigate_to", "history").unwrap();
                    }
                    "contact" => {
                        window.show().unwrap();
                        window.set_focus().unwrap();
                        app.emit_all("tray_navigate_to", "contact").unwrap();
                    }
                    "permissions" => {
                        window.show().unwrap();
                        window.set_focus().unwrap();
                        app.emit_all("tray_show_permissions", {}).unwrap();
                    }
                    _ => {}
                }
            }
            _ => {}
        })
        .manage(app_state)
        .invoke_handler(tauri::generate_handler![
            upload_file,
            start_recording,
            stop_recording,
            delete_file,
            get_supported_formats,
            export_transcription,
            // æ–‡ä»¶å¤¹ç›‘æ§ç›¸å…³å‘½ä»¤
            add_watched_folder,
            remove_watched_folder,
            get_watched_folders,
            get_folder_watcher_stats,
            clear_all_watched_folders,
            // æ•°æ®åº“ç›¸å…³å‘½ä»¤
            get_transcription_history,
            update_transcription_text,
            search_transcriptions,
            get_database_stats,
            get_model_stats,
            export_database_json,
            check_permission,
            request_permission,
            open_system_preferences,
            // ç³»ç»Ÿæ‰˜ç›˜ç›¸å…³å‘½ä»¤
            set_tray_icon_recording,
            show_main_window,
            hide_main_window,
            quit_app,
            get_current_app_info,
            // æ€§èƒ½ä¼˜åŒ–ç›¸å…³å‘½ä»¤
            get_performance_metrics,
            get_cache_stats,
            clear_model_cache,
            configure_performance_optimizer,
            warmup_gpu,
            // AI Agent å‘½ä»¤
            get_ai_prompts,
            save_ai_prompt,
            delete_ai_prompt,
            activate_ai_prompt,
            process_with_agent,
            set_openai_api_key,
            get_agent_types,
            // é“¾å¼å¤„ç†å’Œæ‰¹é‡å¤„ç†
            process_with_chain,
            get_available_chains,
            process_batch,
            get_audio_devices,
        ])
        .setup(|app| {
            println!("âœ… Tauri åº”ç”¨å·²å¯åŠ¨");
            
            // åˆå§‹åŒ–æ–‡ä»¶å¤¹ç›‘æ§å™¨
{
    // FolderWatcher needs to be mutable to call initialize
    // We need to make it mutable, but it's wrapped in Arc<Mutex<>>
    // For now, we'll skip this initialization and handle it differently
    println!("âš ï¸ æ–‡ä»¶å¤¹ç›‘æ§å™¨å»¶è¿Ÿåˆå§‹åŒ–");
}
            
            let window = app.get_window("main").unwrap();
            
            // åœ¨macOSä¸Šï¼Œå¯åŠ¨æ—¶æ˜¾ç¤ºçª—å£ï¼Œå…³é—­æ—¶éšè—åˆ°æ‰˜ç›˜
            #[cfg(target_os = "macos")]
            {
                // å¯åŠ¨æ—¶æ˜¾ç¤ºçª—å£
                window.show().unwrap();
                window.set_focus().unwrap();
                
                // è®¾ç½®çª—å£å…³é—­è¡Œä¸ºä¸ºéšè—è€Œä¸æ˜¯é€€å‡º
                let window_clone = window.clone();
                window.on_window_event(move |event| {
                    match event {
                        WindowEvent::CloseRequested { api, .. } => {
                            // é˜»æ­¢çª—å£å…³é—­ï¼Œæ”¹ä¸ºéšè—åˆ°æ‰˜ç›˜
                            api.prevent_close();
                            window_clone.hide().unwrap();
                            println!("ğŸ”„ çª—å£å·²éšè—åˆ°ç³»ç»Ÿæ‰˜ç›˜");
                        }
                        _ => {}
                    }
                });
            }
            
#[cfg(not(target_os = "macos"))]
{
window.show().unwrap();
}

// Setup safe global shortcuts using Tauri's built-in system
let mut shortcut_manager = app.global_shortcut_manager();

// Get app handle for emitting events
let app_handle = app.handle();

// å°è¯•æ³¨å†Œå¤šä¸ªå¿«æ·é”®è¿›è¡Œæµ‹è¯•
let test_shortcuts = vec![
    "CommandOrControl+Shift+R",
    "CommandOrControl+Shift+T", 
    "F13",
    "CommandOrControl+F1"
];

for shortcut in test_shortcuts {
    let app_handle_clone = app_handle.clone();
    let shortcut_name = shortcut.to_string();
    
    match shortcut_manager.register(shortcut, move || {
        println!("ğŸ”¥ğŸ”¥ğŸ”¥ å¿«æ·é”®è¢«æŒ‰ä¸‹ï¼ï¼ï¼ {}", shortcut_name);
        eprintln!("ğŸ”¥ğŸ”¥ğŸ”¥ å¿«æ·é”®è¢«æŒ‰ä¸‹ï¼ï¼ï¼ {}", shortcut_name);
        
        // Emit event to frontend
        if let Err(emit_error) = app_handle_clone.emit_all("shortcut_pressed", serde_json::json!({
            "shortcut": &shortcut_name,
            "action": "toggle_recording"
        })) {
            eprintln!("âŒ å¿«æ·é”®äº‹ä»¶å‘é€å¤±è´¥: {:?}", emit_error);
        } else {
            println!("âœ… å¿«æ·é”®äº‹ä»¶å·²å‘é€åˆ°å‰ç«¯: {}", shortcut_name);
            eprintln!("âœ… å¿«æ·é”®äº‹ä»¶å·²å‘é€åˆ°å‰ç«¯: {}", shortcut_name);
        }
    }) {
        Ok(_) => println!("âœ… æˆåŠŸæ³¨å†Œå¿«æ·é”®: {}", shortcut),
        Err(e) => eprintln!("âŒ æ³¨å†Œå¿«æ·é”®å¤±è´¥ {}: {:?}", shortcut, e),
    }
}

println!("âŒ¨ï¸ å®‰å…¨å¿«æ·é”®ç³»ç»Ÿå·²å¯ç”¨ (CommandOrControl+Shift+R)");

// æ·»åŠ è¾…åŠ©åŠŸèƒ½æƒé™æ£€æŸ¥ (macOS)
#[cfg(target_os = "macos")]
{
    println!("ğŸ” æ£€æŸ¥macOSè¾…åŠ©åŠŸèƒ½æƒé™...");
    let has_accessibility = check_accessibility_permission();
    if !has_accessibility {
        eprintln!("âŒ ç¼ºå°‘è¾…åŠ©åŠŸèƒ½æƒé™ï¼è¯·åœ¨ ç³»ç»Ÿåå¥½è®¾ç½® > å®‰å…¨æ€§ä¸éšç§ > éšç§ > è¾…åŠ©åŠŸèƒ½ ä¸­å¯ç”¨æ­¤åº”ç”¨");
    } else {
        println!("âœ… è¾…åŠ©åŠŸèƒ½æƒé™å·²å¯ç”¨");
    }
}
            
            Ok(())
        })
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
