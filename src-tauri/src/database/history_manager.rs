// å†å²è®°å½•ç®¡ç†å™¨ - é«˜çº§æµè§ˆã€æœç´¢å’Œæ‰¹é‡ç®¡ç†åŠŸèƒ½
// æä¾›å®Œæ•´çš„è½¬å½•å†å²è®°å½•ç®¡ç†è§£å†³æ–¹æ¡ˆ

use std::collections::HashMap;
use std::sync::Arc;
use std::time::{SystemTime, UNIX_EPOCH};
use parking_lot::Mutex;
use serde::{Deserialize, Serialize};
use uuid::Uuid;
use crate::errors::{AppError, AppResult};
use crate::types::TranscriptionEntry;
use super::{DatabaseManager, SearchFilter, SearchResult, Tag};

/// é«˜çº§æœç´¢é€‰é¡¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AdvancedSearchOptions {
    /// åŸºç¡€æœç´¢è¿‡æ»¤å™¨
    pub filter: SearchFilter,
    /// æ’åºé€‰é¡¹
    pub sort_by: SortOption,
    /// æ’åºæ–¹å‘
    pub sort_order: SortOrder,
    /// åˆ†é¡µå¤§å°
    pub page_size: usize,
    /// é¡µç ï¼ˆä»0å¼€å§‹ï¼‰
    pub page: usize,
    /// æ˜¯å¦åŒ…å«å·²åˆ é™¤çš„è®°å½•
    pub include_deleted: bool,
    /// å…¨æ–‡æœç´¢é€‰é¡¹
    pub full_text_search: Option<FullTextSearchOptions>,
    /// åˆ†ç»„é€‰é¡¹
    pub group_by: Option<GroupByOption>,
}

/// æ’åºé€‰é¡¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SortOption {
    Timestamp,
    Duration,
    Confidence,
    Model,
    TextLength,
    CreatedAt,
    UpdatedAt,
    Relevance, // ç”¨äºå…¨æ–‡æœç´¢
}

/// æ’åºæ–¹å‘
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SortOrder {
    Ascending,
    Descending,
}

/// å…¨æ–‡æœç´¢é€‰é¡¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FullTextSearchOptions {
    /// æœç´¢æŸ¥è¯¢
    pub query: String,
    /// æ˜¯å¦å¯ç”¨æ¨¡ç³Šæœç´¢
    pub fuzzy_search: bool,
    /// é«˜äº®åŒ¹é…æ–‡æœ¬
    pub highlight: bool,
    /// æœç´¢èŒƒå›´
    pub search_fields: Vec<SearchField>,
    /// æœ€å°åŒ¹é…åº¦
    pub min_score: f64,
}

/// æœç´¢å­—æ®µ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SearchField {
    Text,
    Tags,
    Metadata,
    AudioFileName,
}

/// åˆ†ç»„é€‰é¡¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum GroupByOption {
    Date,        // æŒ‰æ—¥æœŸåˆ†ç»„
    Model,       // æŒ‰æ¨¡å‹åˆ†ç»„
    Duration,    // æŒ‰æ—¶é•¿åˆ†ç»„
    Confidence,  // æŒ‰ç½®ä¿¡åº¦åˆ†ç»„
    Tags,        // æŒ‰æ ‡ç­¾åˆ†ç»„
}

/// æ‰¹é‡æ“ä½œç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BulkOperation {
    Delete,
    Archive,
    Unarchive,
    AddTag { tag: String },
    RemoveTag { tag: String },
    UpdateModel { new_model: String },
    Export { format: ExportFormat },
}

/// å¯¼å‡ºæ ¼å¼
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ExportFormat {
    Json,
    Csv,
    Txt,
    Srt, // å­—å¹•æ ¼å¼
    Docx,
}

/// æ‰¹é‡æ“ä½œç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BulkOperationResult {
    pub operation: BulkOperation,
    pub total_items: usize,
    pub successful_items: usize,
    pub failed_items: usize,
    pub errors: Vec<String>,
    pub execution_time_ms: u64,
}

/// åˆ†ç»„æœç´¢ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GroupedSearchResult {
    pub groups: HashMap<String, Vec<TranscriptionEntry>>,
    pub total_count: usize,
    pub group_counts: HashMap<String, usize>,
}

/// å†å²è®°å½•ç»Ÿè®¡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HistoryStatistics {
    pub total_entries: usize,
    pub total_duration_hours: f64,
    pub average_confidence: f64,
    pub most_used_models: Vec<(String, usize)>,
    pub entries_by_date: HashMap<String, usize>, // YYYY-MM-DD
    pub entries_by_hour: HashMap<u8, usize>,     // 0-23
    pub tag_usage: HashMap<String, usize>,
    pub recent_activity: Vec<RecentActivity>,
}

/// æœ€è¿‘æ´»åŠ¨
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RecentActivity {
    pub activity_type: ActivityType,
    pub entry_id: String,
    pub timestamp: i64,
    pub description: String,
}

/// æ´»åŠ¨ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ActivityType {
    Created,
    Updated,
    Deleted,
    Tagged,
    Exported,
}

/// æ™ºèƒ½å»ºè®®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SmartSuggestions {
    pub suggested_tags: Vec<String>,
    pub similar_entries: Vec<String>, // Entry IDs
    pub cleanup_suggestions: Vec<CleanupSuggestion>,
}

/// æ¸…ç†å»ºè®®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CleanupSuggestion {
    pub suggestion_type: CleanupType,
    pub affected_entries: Vec<String>,
    pub description: String,
    pub potential_savings: String, // ä¾‹å¦‚ "èŠ‚çœ 50MB å­˜å‚¨ç©ºé—´"
}

/// æ¸…ç†ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CleanupType {
    DuplicateText,
    LowConfidenceEntries,
    OldUntaggedEntries,
    LargeAudioFiles,
    BrokenAudioLinks,
}

/// é«˜çº§å†å²è®°å½•ç®¡ç†å™¨
#[derive(Debug)]
pub struct HistoryManager {
    db_manager: Arc<DatabaseManager>,
    search_cache: Arc<Mutex<HashMap<String, SearchResult>>>,
    recent_activities: Arc<Mutex<Vec<RecentActivity>>>,
    max_cache_size: usize,
    max_recent_activities: usize,
}

impl Default for AdvancedSearchOptions {
    fn default() -> Self {
        Self {
            filter: SearchFilter::default(),
            sort_by: SortOption::Timestamp,
            sort_order: SortOrder::Descending,
            page_size: 50,
            page: 0,
            include_deleted: false,
            full_text_search: None,
            group_by: None,
        }
    }
}

impl HistoryManager {
    pub fn new(db_manager: Arc<DatabaseManager>) -> Self {
        Self {
            db_manager,
            search_cache: Arc::new(Mutex::new(HashMap::new())),
            recent_activities: Arc::new(Mutex::new(Vec::new())),
            max_cache_size: 100,
            max_recent_activities: 1000,
        }
    }

    /// é«˜çº§æœç´¢åŠŸèƒ½
    pub async fn advanced_search(
        &self,
        options: &AdvancedSearchOptions,
    ) -> AppResult<SearchResult> {
        // ç”Ÿæˆç¼“å­˜é”®
        let cache_key = self.generate_cache_key(options);
        
        // æ£€æŸ¥ç¼“å­˜
        if let Some(cached_result) = self.search_cache.lock().get(&cache_key) {
            return Ok(cached_result.clone());
        }

        // æ„å»ºæœç´¢å‚æ•°
        let limit = Some(options.page_size);
        let offset = Some(options.page * options.page_size);
        
        // æ‰§è¡ŒåŸºç¡€æœç´¢
        let query = if let Some(full_text) = &options.full_text_search {
            &full_text.query
        } else {
            ""
        };
        
        let mut result = self.db_manager.search_transcriptions(
            query, 
            &options.filter, 
            limit, 
            offset
        )?;

        // åº”ç”¨é«˜çº§æœç´¢åŠŸèƒ½
        if let Some(full_text_opts) = &options.full_text_search {
            result = self.apply_full_text_search(result, full_text_opts).await?;
        }

        // åº”ç”¨æ’åº
        self.apply_sorting(&mut result, &options.sort_by, &options.sort_order);

        // åº”ç”¨é«˜äº®
        if let Some(full_text_opts) = &options.full_text_search {
            if full_text_opts.highlight {
                self.apply_highlighting(&mut result, &full_text_opts.query);
            }
        }

        // ç¼“å­˜ç»“æœ
        self.cache_search_result(cache_key, result.clone());

        println!("ğŸ” é«˜çº§æœç´¢å®Œæˆ: æ‰¾åˆ° {} ä¸ªç»“æœ", result.entries.len());
        Ok(result)
    }

    /// åˆ†ç»„æœç´¢
    pub async fn grouped_search(
        &self,
        options: &AdvancedSearchOptions,
    ) -> AppResult<GroupedSearchResult> {
        if options.group_by.is_none() {
            return Err(AppError::ValidationError("åˆ†ç»„é€‰é¡¹æœªæŒ‡å®š".to_string()));
        }

        // è·å–æ‰€æœ‰åŒ¹é…çš„è®°å½•ï¼ˆä¸åˆ†é¡µï¼‰
        let all_options = AdvancedSearchOptions {
            page_size: 10000, // è·å–å¤§é‡ç»“æœ
            page: 0,
            ..options.clone()
        };
        
        let search_result = self.advanced_search(&all_options).await?;
        let group_by = options.group_by.as_ref().unwrap();

        let mut groups: HashMap<String, Vec<TranscriptionEntry>> = HashMap::new();
        let mut group_counts: HashMap<String, usize> = HashMap::new();

        for entry in search_result.entries {
            let group_key = self.get_group_key(&entry, group_by);
            
            let group_entries = groups.entry(group_key.clone()).or_insert_with(Vec::new);
            group_entries.push(entry);
            
            *group_counts.entry(group_key).or_insert(0) += 1;
        }

        println!("ğŸ“Š åˆ†ç»„æœç´¢å®Œæˆ: {} ä¸ªåˆ†ç»„", groups.len());
        
        Ok(GroupedSearchResult {
            groups,
            total_count: search_result.total_count,
            group_counts,
        })
    }

    /// æ‰¹é‡æ“ä½œ
    pub async fn bulk_operation(
        &self,
        entry_ids: &[String],
        operation: BulkOperation,
    ) -> AppResult<BulkOperationResult> {
        let start_time = SystemTime::now();
        let mut successful_items = 0;
        let mut failed_items = 0;
        let mut errors = Vec::new();

        for entry_id in entry_ids {
            match self.execute_single_operation(entry_id, &operation).await {
                Ok(_) => {
                    successful_items += 1;
                    self.record_activity(ActivityType::Updated, entry_id.clone(), "æ‰¹é‡æ“ä½œ".to_string());
                }
                Err(e) => {
                    failed_items += 1;
                    errors.push(format!("æ¡ç›® {}: {}", entry_id, e));
                }
            }
        }

        let execution_time_ms = start_time.elapsed()
            .map(|d| d.as_millis() as u64)
            .unwrap_or(0);

        println!("âš¡ æ‰¹é‡æ“ä½œå®Œæˆ: {}/{} æˆåŠŸ", successful_items, entry_ids.len());

        Ok(BulkOperationResult {
            operation,
            total_items: entry_ids.len(),
            successful_items,
            failed_items,
            errors,
            execution_time_ms,
        })
    }

    /// è·å–å†å²ç»Ÿè®¡
    pub async fn get_history_statistics(&self) -> AppResult<HistoryStatistics> {
        let all_entries = self.db_manager.get_all_transcriptions()?;
        
        let total_entries = all_entries.len();
        let total_duration_hours: f64 = all_entries.iter().map(|e| e.duration).sum::<f64>() / 3600.0;
        let average_confidence = if total_entries > 0 {
            all_entries.iter().map(|e| e.confidence).sum::<f64>() / total_entries as f64
        } else {
            0.0
        };

        // æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
        let mut model_counts: HashMap<String, usize> = HashMap::new();
        for entry in &all_entries {
            *model_counts.entry(entry.model.clone()).or_insert(0) += 1;
        }
        let mut most_used_models: Vec<(String, usize)> = model_counts.into_iter().collect();
        most_used_models.sort_by(|a, b| b.1.cmp(&a.1));
        most_used_models.truncate(10);

        // æŒ‰æ—¥æœŸç»Ÿè®¡
        let mut entries_by_date: HashMap<String, usize> = HashMap::new();
        let mut entries_by_hour: HashMap<u8, usize> = HashMap::new();
        
        for entry in &all_entries {
            // è½¬æ¢æ—¶é—´æˆ³ä¸ºæ—¥æœŸ
            let date = self.timestamp_to_date(entry.timestamp);
            let hour = self.timestamp_to_hour(entry.timestamp);
            
            *entries_by_date.entry(date).or_insert(0) += 1;
            *entries_by_hour.entry(hour).or_insert(0) += 1;
        }

        // æ ‡ç­¾ä½¿ç”¨ç»Ÿè®¡
        let tag_usage = self.calculate_tag_usage(&all_entries);

        // æœ€è¿‘æ´»åŠ¨
        let recent_activity = self.recent_activities.lock().clone();

        Ok(HistoryStatistics {
            total_entries,
            total_duration_hours,
            average_confidence,
            most_used_models,
            entries_by_date,
            entries_by_hour,
            tag_usage,
            recent_activity,
        })
    }

    /// è·å–æ™ºèƒ½å»ºè®®
    pub async fn get_smart_suggestions(&self, entry_id: Option<&str>) -> AppResult<SmartSuggestions> {
        let all_entries = self.db_manager.get_all_transcriptions()?;

        // å»ºè®®æ ‡ç­¾
        let suggested_tags = self.generate_tag_suggestions(&all_entries, entry_id);

        // ç›¸ä¼¼æ¡ç›®
        let similar_entries = if let Some(id) = entry_id {
            self.find_similar_entries(&all_entries, id)?
        } else {
            Vec::new()
        };

        // æ¸…ç†å»ºè®®
        let cleanup_suggestions = self.generate_cleanup_suggestions(&all_entries);

        Ok(SmartSuggestions {
            suggested_tags,
            similar_entries,
            cleanup_suggestions,
        })
    }

    /// å¯¼å‡ºå†å²è®°å½•
    pub async fn export_entries(
        &self,
        entry_ids: &[String],
        format: ExportFormat,
        output_path: &str,
    ) -> AppResult<()> {
        let entries: Vec<TranscriptionEntry> = entry_ids.iter()
            .filter_map(|id| {
                // è¿™é‡Œéœ€è¦å®ç°æ ¹æ®IDè·å–æ¡ç›®çš„åŠŸèƒ½
                // ç›®å‰å…ˆä»æ‰€æœ‰æ¡ç›®ä¸­è¿‡æ»¤
                if let Ok(all_entries) = self.db_manager.get_all_transcriptions() {
                    all_entries.into_iter().find(|e| &e.id == id)
                } else {
                    None
                }
            })
            .collect();

        match format {
            ExportFormat::Json => {
                let json_data = serde_json::to_string_pretty(&entries)
                    .map_err(|e| AppError::DataSerializationError(format!("JSONåºåˆ—åŒ–å¤±è´¥: {}", e)))?;
                std::fs::write(output_path, json_data)
                    .map_err(|e| AppError::FileSystemError(format!("å†™å…¥æ–‡ä»¶å¤±è´¥: {}", e)))?;
            }
            ExportFormat::Csv => {
                self.export_to_csv(&entries, output_path)?;
            }
            ExportFormat::Txt => {
                self.export_to_txt(&entries, output_path)?;
            }
            ExportFormat::Srt => {
                self.export_to_srt(&entries, output_path)?;
            }
            ExportFormat::Docx => {
                return Err(AppError::ValidationError("DOCXå¯¼å‡ºæš‚æœªå®ç°".to_string()));
            }
        }

        // è®°å½•å¯¼å‡ºæ´»åŠ¨
        for entry_id in entry_ids {
            self.record_activity(ActivityType::Exported, entry_id.clone(), format!("å¯¼å‡ºä¸º {:?}", format));
        }

        println!("ğŸ“¤ å¯¼å‡ºå®Œæˆ: {} ä¸ªæ¡ç›®å¯¼å‡ºåˆ° {}", entries.len(), output_path);
        Ok(())
    }

    /// æ¸…ç†å†å²è®°å½•
    pub async fn cleanup_history(&self, cleanup_type: CleanupType, dry_run: bool) -> AppResult<CleanupSuggestion> {
        let all_entries = self.db_manager.get_all_transcriptions()?;
        
        let (affected_entries, description, savings) = match cleanup_type {
            CleanupType::DuplicateText => {
                let duplicates = self.find_duplicate_text_entries(&all_entries);
                (
                    duplicates,
                    "åˆ é™¤é‡å¤çš„è½¬å½•æ–‡æœ¬".to_string(),
                    "èŠ‚çœå­˜å‚¨ç©ºé—´".to_string(),
                )
            }
            CleanupType::LowConfidenceEntries => {
                let low_confidence: Vec<String> = all_entries
                    .iter()
                    .filter(|e| e.confidence < 0.3)
                    .map(|e| e.id.clone())
                    .collect();
                (
                    low_confidence.clone(),
                    format!("åˆ é™¤ {} ä¸ªä½ç½®ä¿¡åº¦æ¡ç›®", low_confidence.len()),
                    "æå‡æ•°æ®è´¨é‡".to_string(),
                )
            }
            CleanupType::OldUntaggedEntries => {
                let cutoff_time = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs() as i64 - (30 * 24 * 3600); // 30å¤©å‰
                let old_untagged: Vec<String> = all_entries
                    .iter()
                    .filter(|e| e.timestamp < cutoff_time && (e.tags.is_none() || e.tags.as_ref().unwrap().trim().is_empty()))
                    .map(|e| e.id.clone())
                    .collect();
                (
                    old_untagged.clone(),
                    format!("åˆ é™¤ {} ä¸ª30å¤©å‰çš„æ— æ ‡ç­¾æ¡ç›®", old_untagged.len()),
                    "æ•´ç†å†å²è®°å½•".to_string(),
                )
            }
            CleanupType::LargeAudioFiles => {
                // è¿™é‡Œéœ€è¦æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°ï¼Œæš‚æ—¶è¿”å›ç©º
                (Vec::new(), "æ¸…ç†å¤§éŸ³é¢‘æ–‡ä»¶".to_string(), "èŠ‚çœç£ç›˜ç©ºé—´".to_string())
            }
            CleanupType::BrokenAudioLinks => {
                let broken_links = self.find_broken_audio_links(&all_entries);
                (
                    broken_links.clone(),
                    format!("ä¿®å¤ {} ä¸ªæŸåçš„éŸ³é¢‘é“¾æ¥", broken_links.len()),
                    "ä¿®å¤æ•°æ®å®Œæ•´æ€§".to_string(),
                )
            }
        };

        if !dry_run && !affected_entries.is_empty() {
            // æ‰§è¡Œå®é™…æ¸…ç†
            match cleanup_type {
                CleanupType::DuplicateText | 
                CleanupType::LowConfidenceEntries | 
                CleanupType::OldUntaggedEntries => {
                    for entry_id in &affected_entries {
                        let _ = self.db_manager.delete_transcription(entry_id);
                    }
                }
                _ => {
                    // å…¶ä»–ç±»å‹çš„æ¸…ç†é€»è¾‘
                }
            }
        }

        Ok(CleanupSuggestion {
            suggestion_type: cleanup_type,
            affected_entries,
            description,
            potential_savings: savings,
        })
    }

    // =================== ç§æœ‰è¾…åŠ©æ–¹æ³• ===================

    /// ç”Ÿæˆæœç´¢ç¼“å­˜é”®
    fn generate_cache_key(&self, options: &AdvancedSearchOptions) -> String {
        format!("{:?}", options) // ç®€åŒ–çš„ç¼“å­˜é”®ç”Ÿæˆ
    }

    /// ç¼“å­˜æœç´¢ç»“æœ
    fn cache_search_result(&self, key: String, result: SearchResult) {
        let mut cache = self.search_cache.lock();
        
        // é™åˆ¶ç¼“å­˜å¤§å°
        if cache.len() >= self.max_cache_size {
            // ç®€å•çš„LRUæ¸…ç†ï¼Œåˆ é™¤ç¬¬ä¸€ä¸ªæ¡ç›®
            if let Some(first_key) = cache.keys().next().cloned() {
                cache.remove(&first_key);
            }
        }
        
        cache.insert(key, result);
    }

    /// åº”ç”¨å…¨æ–‡æœç´¢
    async fn apply_full_text_search(
        &self,
        mut result: SearchResult,
        options: &FullTextSearchOptions,
    ) -> AppResult<SearchResult> {
        if options.fuzzy_search {
            // å®ç°æ¨¡ç³Šæœç´¢é€»è¾‘
            result.entries = result.entries.into_iter()
                .filter(|entry| self.fuzzy_match(&entry.text, &options.query))
                .collect();
        }

        // æ ¹æ®åŒ¹é…åº¦é‡æ–°æ’åº
        if options.min_score > 0.0 {
            result.entries = result.entries.into_iter()
                .map(|entry| {
                    let score = self.calculate_relevance_score(&entry.text, &options.query);
                    (entry, score)
                })
                .filter(|(_, score)| *score >= options.min_score)
                .map(|(entry, _)| entry)
                .collect();
        }

        Ok(result)
    }

    /// åº”ç”¨æ’åº
    fn apply_sorting(&self, result: &mut SearchResult, sort_by: &SortOption, sort_order: &SortOrder) {
        result.entries.sort_by(|a, b| {
            let cmp = match sort_by {
                SortOption::Timestamp => a.timestamp.cmp(&b.timestamp),
                SortOption::Duration => a.duration.partial_cmp(&b.duration).unwrap_or(std::cmp::Ordering::Equal),
                SortOption::Confidence => a.confidence.partial_cmp(&b.confidence).unwrap_or(std::cmp::Ordering::Equal),
                SortOption::Model => a.model.cmp(&b.model),
                SortOption::TextLength => a.text.len().cmp(&b.text.len()),
                SortOption::CreatedAt => a.created_at.cmp(&b.created_at),
                SortOption::UpdatedAt => a.updated_at.cmp(&b.updated_at),
                SortOption::Relevance => std::cmp::Ordering::Equal, // éœ€è¦é¢å¤–çš„ç›¸å…³æ€§åˆ†æ•°
            };

            match sort_order {
                SortOrder::Ascending => cmp,
                SortOrder::Descending => cmp.reverse(),
            }
        });
    }

    /// åº”ç”¨é«˜äº®
    fn apply_highlighting(&self, result: &mut SearchResult, query: &str) {
        let query_lower = query.to_lowercase();
        for entry in &mut result.entries {
            if entry.text.to_lowercase().contains(&query_lower) {
                // ç®€å•çš„é«˜äº®å®ç°
                entry.text = entry.text.replace(query, &format!("<mark>{}</mark>", query));
            }
        }
    }

    /// è·å–åˆ†ç»„é”®
    fn get_group_key(&self, entry: &TranscriptionEntry, group_by: &GroupByOption) -> String {
        match group_by {
            GroupByOption::Date => self.timestamp_to_date(entry.timestamp),
            GroupByOption::Model => entry.model.clone(),
            GroupByOption::Duration => {
                if entry.duration < 60.0 {
                    "çŸ­æ—¶é—´ (<1åˆ†é’Ÿ)".to_string()
                } else if entry.duration < 300.0 {
                    "ä¸­ç­‰æ—¶é—´ (1-5åˆ†é’Ÿ)".to_string()
                } else {
                    "é•¿æ—¶é—´ (>5åˆ†é’Ÿ)".to_string()
                }
            }
            GroupByOption::Confidence => {
                if entry.confidence < 0.5 {
                    "ä½ç½®ä¿¡åº¦ (<50%)".to_string()
                } else if entry.confidence < 0.8 {
                    "ä¸­ç­‰ç½®ä¿¡åº¦ (50-80%)".to_string()
                } else {
                    "é«˜ç½®ä¿¡åº¦ (>80%)".to_string()
                }
            }
            GroupByOption::Tags => {
                entry.tags.clone().unwrap_or_else(|| "æ— æ ‡ç­¾".to_string())
            }
        }
    }

    /// æ‰§è¡Œå•ä¸ªæ“ä½œ
    async fn execute_single_operation(&self, entry_id: &str, operation: &BulkOperation) -> AppResult<()> {
        match operation {
            BulkOperation::Delete => {
                self.db_manager.delete_transcription(entry_id)?;
            }
            BulkOperation::AddTag { tag } => {
                // è¿™é‡Œéœ€è¦å®ç°æ ‡ç­¾æ·»åŠ é€»è¾‘
                // å½“å‰æ•°æ®åº“æ¨¡å‹ä¸­æ ‡ç­¾æ˜¯JSONå­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æå’Œæ›´æ–°
                println!("ä¸ºæ¡ç›® {} æ·»åŠ æ ‡ç­¾: {}", entry_id, tag);
            }
            BulkOperation::RemoveTag { tag } => {
                println!("ä»æ¡ç›® {} ç§»é™¤æ ‡ç­¾: {}", entry_id, tag);
            }
            BulkOperation::UpdateModel { new_model } => {
                // éœ€è¦æ·»åŠ æ›´æ–°æ¨¡å‹çš„æ•°æ®åº“æ–¹æ³•
                println!("æ›´æ–°æ¡ç›® {} çš„æ¨¡å‹ä¸º: {}", entry_id, new_model);
            }
            BulkOperation::Archive => {
                // éœ€è¦æ·»åŠ å½’æ¡£åŠŸèƒ½
                println!("å½’æ¡£æ¡ç›®: {}", entry_id);
            }
            BulkOperation::Unarchive => {
                println!("å–æ¶ˆå½’æ¡£æ¡ç›®: {}", entry_id);
            }
            BulkOperation::Export { format } => {
                // å•ä¸ªæ¡ç›®å¯¼å‡º
                println!("å¯¼å‡ºæ¡ç›® {} ä¸º {:?} æ ¼å¼", entry_id, format);
            }
        }
        Ok(())
    }

    /// è®°å½•æ´»åŠ¨
    fn record_activity(&self, activity_type: ActivityType, entry_id: String, description: String) {
        let activity = RecentActivity {
            activity_type,
            entry_id,
            timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs() as i64,
            description,
        };

        let mut activities = self.recent_activities.lock();
        activities.push(activity);

        // é™åˆ¶æ´»åŠ¨è®°å½•æ•°é‡
        if activities.len() > self.max_recent_activities {
            let len = activities.len();
            activities.drain(0..len - self.max_recent_activities);
        }
    }

    /// æ—¶é—´æˆ³è½¬æ—¥æœŸ
    fn timestamp_to_date(&self, timestamp: i64) -> String {
        // ç®€åŒ–çš„æ—¥æœŸè½¬æ¢ï¼Œå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨properçš„æ—¶é—´åº“
        let date = std::time::UNIX_EPOCH + std::time::Duration::from_secs(timestamp as u64);
        let datetime = date.duration_since(std::time::UNIX_EPOCH).unwrap().as_secs();
        let days = datetime / 86400;
        format!("{}-{:02}-{:02}", 1970 + days / 365, (days % 365) / 30 + 1, days % 30 + 1)
    }

    /// æ—¶é—´æˆ³è½¬å°æ—¶
    fn timestamp_to_hour(&self, timestamp: i64) -> u8 {
        ((timestamp % 86400) / 3600) as u8
    }

    /// è®¡ç®—æ ‡ç­¾ä½¿ç”¨ç»Ÿè®¡
    fn calculate_tag_usage(&self, entries: &[TranscriptionEntry]) -> HashMap<String, usize> {
        let mut tag_counts = HashMap::new();
        
        for entry in entries {
            if let Some(tags_str) = &entry.tags {
                // å‡è®¾æ ‡ç­¾æ˜¯é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
                for tag in tags_str.split(',').map(|s| s.trim()) {
                    if !tag.is_empty() {
                        *tag_counts.entry(tag.to_string()).or_insert(0) += 1;
                    }
                }
            }
        }
        
        tag_counts
    }

    /// ç”Ÿæˆæ ‡ç­¾å»ºè®®
    fn generate_tag_suggestions(&self, entries: &[TranscriptionEntry], entry_id: Option<&str>) -> Vec<String> {
        // åŸºäºæ–‡æœ¬å†…å®¹å’Œå†å²æ ‡ç­¾ç”Ÿæˆå»ºè®®
        let mut suggestions = Vec::new();
        
        // ä»å†å²è®°å½•ä¸­æå–å¸¸ç”¨æ ‡ç­¾
        let tag_usage = self.calculate_tag_usage(entries);
        let mut popular_tags: Vec<(String, usize)> = tag_usage.into_iter().collect();
        popular_tags.sort_by(|a, b| b.1.cmp(&a.1));
        
        for (tag, _) in popular_tags.into_iter().take(10) {
            suggestions.push(tag);
        }
        
        suggestions
    }

    /// æŸ¥æ‰¾ç›¸ä¼¼æ¡ç›®
    fn find_similar_entries(&self, entries: &[TranscriptionEntry], entry_id: &str) -> AppResult<Vec<String>> {
        let target_entry = entries.iter()
            .find(|e| e.id == entry_id)
            .ok_or_else(|| AppError::ValidationError("ç›®æ ‡æ¡ç›®æœªæ‰¾åˆ°".to_string()))?;

        let mut similar = Vec::new();
        
        for entry in entries {
            if entry.id != entry_id {
                let similarity = self.calculate_text_similarity(&target_entry.text, &entry.text);
                if similarity > 0.7 {
                    similar.push(entry.id.clone());
                }
            }
        }
        
        similar.truncate(5); // æœ€å¤šè¿”å›5ä¸ªç›¸ä¼¼æ¡ç›®
        Ok(similar)
    }

    /// ç”Ÿæˆæ¸…ç†å»ºè®®
    fn generate_cleanup_suggestions(&self, entries: &[TranscriptionEntry]) -> Vec<CleanupSuggestion> {
        let mut suggestions = Vec::new();

        // é‡å¤æ–‡æœ¬æ£€æµ‹
        let duplicates = self.find_duplicate_text_entries(entries);
        if !duplicates.is_empty() {
            suggestions.push(CleanupSuggestion {
                suggestion_type: CleanupType::DuplicateText,
                affected_entries: duplicates.clone(),
                description: format!("å‘ç° {} ä¸ªé‡å¤æ–‡æœ¬æ¡ç›®", duplicates.len()),
                potential_savings: "èŠ‚çœå­˜å‚¨ç©ºé—´".to_string(),
            });
        }

        // ä½ç½®ä¿¡åº¦æ¡ç›®
        let low_confidence: Vec<String> = entries
            .iter()
            .filter(|e| e.confidence < 0.3)
            .map(|e| e.id.clone())
            .collect();
        
        if !low_confidence.is_empty() {
            suggestions.push(CleanupSuggestion {
                suggestion_type: CleanupType::LowConfidenceEntries,
                affected_entries: low_confidence.clone(),
                description: format!("å‘ç° {} ä¸ªä½ç½®ä¿¡åº¦æ¡ç›®", low_confidence.len()),
                potential_savings: "æå‡æ•°æ®è´¨é‡".to_string(),
            });
        }

        suggestions
    }

    /// æŸ¥æ‰¾é‡å¤æ–‡æœ¬æ¡ç›®
    fn find_duplicate_text_entries(&self, entries: &[TranscriptionEntry]) -> Vec<String> {
        let mut text_to_ids: HashMap<String, Vec<String>> = HashMap::new();
        let mut duplicates = Vec::new();

        for entry in entries {
            let normalized_text = entry.text.trim().to_lowercase();
            text_to_ids.entry(normalized_text).or_insert_with(Vec::new).push(entry.id.clone());
        }

        for (_, ids) in text_to_ids {
            if ids.len() > 1 {
                duplicates.extend(ids.into_iter().skip(1)); // ä¿ç•™ç¬¬ä¸€ä¸ªï¼Œå…¶ä½™æ ‡è®°ä¸ºé‡å¤
            }
        }

        duplicates
    }

    /// æŸ¥æ‰¾æŸåçš„éŸ³é¢‘é“¾æ¥
    fn find_broken_audio_links(&self, entries: &[TranscriptionEntry]) -> Vec<String> {
        let mut broken = Vec::new();
        
        for entry in entries {
            if let Some(audio_path) = &entry.audio_file_path {
                if !std::path::Path::new(audio_path).exists() {
                    broken.push(entry.id.clone());
                }
            }
        }
        
        broken
    }

    /// æ¨¡ç³ŠåŒ¹é…
    fn fuzzy_match(&self, text: &str, query: &str) -> bool {
        let text_lower = text.to_lowercase();
        let query_lower = query.to_lowercase();
        
        // ç®€å•çš„æ¨¡ç³ŠåŒ¹é…ï¼šæ£€æŸ¥æ‰€æœ‰æŸ¥è¯¢è¯æ˜¯å¦éƒ½åœ¨æ–‡æœ¬ä¸­
        query_lower.split_whitespace()
            .all(|word| text_lower.contains(word))
    }

    /// è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
    fn calculate_relevance_score(&self, text: &str, query: &str) -> f64 {
        let text_lower = text.to_lowercase();
        let query_lower = query.to_lowercase();
        let query_words: Vec<&str> = query_lower.split_whitespace().collect();
        
        if query_words.is_empty() {
            return 0.0;
        }
        
        let matches = query_words.iter()
            .filter(|word| text_lower.contains(*word))
            .count();
            
        matches as f64 / query_words.len() as f64
    }

    /// è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
    fn calculate_text_similarity(&self, text1: &str, text2: &str) -> f64 {
        let words1: std::collections::HashSet<&str> = text1.split_whitespace().collect();
        let words2: std::collections::HashSet<&str> = text2.split_whitespace().collect();
        
        let intersection = words1.intersection(&words2).count();
        let union = words1.union(&words2).count();
        
        if union == 0 {
            0.0
        } else {
            intersection as f64 / union as f64
        }
    }

    /// å¯¼å‡ºåˆ°CSV
    fn export_to_csv(&self, entries: &[TranscriptionEntry], output_path: &str) -> AppResult<()> {
        let mut csv_content = String::from("ID,Text,Timestamp,Duration,Model,Confidence,AudioFile,CreatedAt,UpdatedAt,Tags\n");
        
        for entry in entries {
            let line = format!(
                "{},{},{},{},{},{},{},{},{},{}\n",
                entry.id,
                entry.text.replace(",", "ï¼Œ").replace("\n", " "), // è½¬ä¹‰é€—å·å’Œæ¢è¡Œ
                entry.timestamp,
                entry.duration,
                entry.model,
                entry.confidence,
                entry.audio_file_path.as_deref().unwrap_or(""),
                entry.created_at.as_deref().unwrap_or(""),
                entry.updated_at.as_deref().unwrap_or(""),
                entry.tags.as_deref().unwrap_or("")
            );
            csv_content.push_str(&line);
        }
        
        std::fs::write(output_path, csv_content)
            .map_err(|e| AppError::FileSystemError(format!("å†™å…¥CSVæ–‡ä»¶å¤±è´¥: {}", e)))?;
            
        Ok(())
    }

    /// å¯¼å‡ºåˆ°TXT
    fn export_to_txt(&self, entries: &[TranscriptionEntry], output_path: &str) -> AppResult<()> {
        let mut txt_content = String::new();
        
        for entry in entries {
            txt_content.push_str(&format!(
                "=== {} ===\næ—¶é—´: {}\næ¨¡å‹: {}\nç½®ä¿¡åº¦: {:.2}\nå†…å®¹:\n{}\n\n",
                entry.id,
                entry.created_at.as_deref().unwrap_or(""),
                entry.model,
                entry.confidence,
                entry.text
            ));
        }
        
        std::fs::write(output_path, txt_content)
            .map_err(|e| AppError::FileSystemError(format!("å†™å…¥TXTæ–‡ä»¶å¤±è´¥: {}", e)))?;
            
        Ok(())
    }

    /// å¯¼å‡ºåˆ°SRTå­—å¹•æ ¼å¼
    fn export_to_srt(&self, entries: &[TranscriptionEntry], output_path: &str) -> AppResult<()> {
        let mut srt_content = String::new();
        
        for (index, entry) in entries.iter().enumerate() {
            let start_time = "00:00:00,000"; // éœ€è¦æ ¹æ®å®é™…æ—¶é—´æˆ³è®¡ç®—
            let end_time = format!("00:00:{:02},{:03}", 
                (entry.duration as u32) / 60, 
                ((entry.duration * 1000.0) as u32) % 1000);
            
            srt_content.push_str(&format!(
                "{}\n{} --> {}\n{}\n\n",
                index + 1,
                start_time,
                end_time,
                entry.text
            ));
        }
        
        std::fs::write(output_path, srt_content)
            .map_err(|e| AppError::FileSystemError(format!("å†™å…¥SRTæ–‡ä»¶å¤±è´¥: {}", e)))?;
            
        Ok(())
    }
}