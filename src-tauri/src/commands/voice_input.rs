use serde::{Deserialize, Serialize};
use tauri::command;
use crate::types::TranscriptionConfig;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ActiveAppInfo {
    pub name: String,
    pub bundle_id: Option<String>,
}

/// è·å–å½“å‰æ´»åŠ¨åº”ç”¨ä¿¡æ¯
#[command]
pub async fn get_active_app_info_for_voice() -> Result<ActiveAppInfo, String> {
    #[cfg(target_os = "macos")]
    {
        use cocoa::base::{id, nil};
        use cocoa::foundation::{NSString, NSAutoreleasePool};
        use objc::{msg_send, sel, sel_impl};
        
        unsafe {
            let pool = NSAutoreleasePool::new(nil);
            let workspace: id = msg_send![objc::class!(NSWorkspace), sharedWorkspace];
            let active_app: id = msg_send![workspace, frontmostApplication];
            
            if active_app != nil {
                let name: id = msg_send![active_app, localizedName];
                let bundle_id: id = msg_send![active_app, bundleIdentifier];
                
                let app_name = if name != nil {
                    std::ffi::CStr::from_ptr(NSString::UTF8String(name))
                        .to_string_lossy()
                        .to_string()
                } else {
                    "Unknown".to_string()
                };
                
                let app_bundle_id = if bundle_id != nil {
                    Some(std::ffi::CStr::from_ptr(NSString::UTF8String(bundle_id))
                        .to_string_lossy()
                        .to_string())
                } else {
                    None
                };
                
                pool.drain();
                return Ok(ActiveAppInfo {
                    name: app_name,
                    bundle_id: app_bundle_id,
                });
            }
            pool.drain();
        }
    }
    
    Err("æ— æ³•è·å–æ´»åŠ¨åº”ç”¨ä¿¡æ¯".to_string())
}

/// å¼€å§‹è¯­éŸ³å½•éŸ³
#[command]
pub async fn start_voice_recording(
    app: tauri::AppHandle,
) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    
    // æ£€æŸ¥å½•éŸ³çŠ¶æ€
    {
        let is_recording = state.is_recording.lock();
        if *is_recording {
            return Ok("å½•éŸ³å·²åœ¨è¿›è¡Œä¸­".to_string());
        }
    }
    
    // å¯åŠ¨å½•éŸ³
    {
        let mut recorder = state.audio_recorder.lock();
        recorder.reset_silence_detection();
        recorder.start_recording()
            .map_err(|e| format!("å¯åŠ¨å½•éŸ³å¤±è´¥: {}", e))?;
    }
    
    // æ›´æ–°çŠ¶æ€
    {
        let mut is_recording = state.is_recording.lock();
        *is_recording = true;
    }
    
    // å¯åŠ¨VADç›‘æµ‹
    start_vad_monitor(app).await;
    
    Ok("å½•éŸ³å·²å¼€å§‹".to_string())
}

/// VADç›‘æµ‹ä»»åŠ¡
async fn start_vad_monitor(app: tauri::AppHandle) {
    use crate::AppState;
    use tauri::Manager;
    use std::sync::Arc;
    use std::time::Duration;
    
    let state = app.state::<AppState>();
    let app_handle = app.clone();
    let recorder_clone = Arc::clone(&state.audio_recorder);
    let is_recording_clone = Arc::clone(&state.is_recording);
    
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(Duration::from_millis(100));
        const MAX_SILENCE: Duration = Duration::from_secs(2);
        const MIN_DURATION: Duration = Duration::from_millis(500);
        
        let start_time = std::time::Instant::now();
        let mut has_sound = false;
        
        loop {
            interval.tick().await;
            
            let (is_recording, audio_level, silence_duration) = {
                let recorder = recorder_clone.lock();
                (
                    recorder.is_recording(),
                    recorder.get_current_audio_level().unwrap_or(0.0),
                    recorder.get_silence_duration(),
                )
            };
            
            if !is_recording {
                break;
            }
            
            if audio_level > 0.01 {
                has_sound = true;
            }
            
            // è‡ªåŠ¨åœæ­¢æ¡ä»¶
            let duration = start_time.elapsed();
            if duration > MIN_DURATION && has_sound && silence_duration > MAX_SILENCE {
                crate::commands::stop_voice_recording(app_handle.clone()).await.ok();
                break;
            }
            
            // å‘é€çŠ¶æ€æ›´æ–°
            app_handle.emit_all("vad_status", serde_json::json!({
                "is_speaking": audio_level > 0.01,
                "audio_level": audio_level,
                "silence_duration": silence_duration.as_millis(),
            })).ok();
        }
        
        let mut is_recording = is_recording_clone.lock();
        *is_recording = false;
    });
}

/// åœæ­¢è¯­éŸ³å½•éŸ³å¹¶è½¬å½•
#[command]
pub async fn stop_voice_recording(app: tauri::AppHandle) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    
    // æ£€æŸ¥å½•éŸ³çŠ¶æ€
    {
        let is_recording = state.is_recording.lock();
        if !*is_recording {
            return Ok(String::new());
        }
    }
    
    // åœæ­¢å½•éŸ³
    let (audio_data, sample_rate) = {
        let mut recorder = state.audio_recorder.lock();
        let sr = recorder.get_sample_rate();
        let audio = recorder.stop_recording()
            .map_err(|e| format!("åœæ­¢å½•éŸ³å¤±è´¥: {}", e))?;
        (audio, sr)
    };
    
    // é‡ç½®çŠ¶æ€
    {
        let mut is_recording = state.is_recording.lock();
        *is_recording = false;
    }
    
    if audio_data.is_empty() || audio_data.len() < sample_rate as usize {
        return Ok(String::new());
    }
    
    // è½¬å½•éŸ³é¢‘
    let result = transcribe_audio(app.clone(), audio_data, sample_rate).await?;
    
    Ok(result)
}

/// è½¬å½•éŸ³é¢‘
async fn transcribe_audio(
    app: tauri::AppHandle,
    audio_data: Vec<f32>,
    sample_rate: u32,
) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    
    // åˆ›å»ºWAVæ–‡ä»¶
    let temp_file = create_temp_wav(&audio_data, sample_rate)?;
    
    // è·å–æ¨¡å‹é…ç½®
    let model = {
        let settings = state.settings.lock();
        settings.transcription.default_model.clone()
    };
    
    let config = create_transcription_config(&model);
    
    // è½¬å½•
    let result = state.transcription_service
        .transcribe_audio(temp_file.to_str().unwrap(), &config)
        .await
        .map_err(|e| format!("è½¬å½•å¤±è´¥: {}", e))?;
    
    let text = result.text.trim().to_string();
    
    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    std::fs::remove_file(&temp_file).ok();
    
    // ä¿å­˜åˆ°å†å²è®°å½•
    if !text.is_empty() {
        save_transcription_history(&app, &text, &model, audio_data.len() as f64 / sample_rate as f64).await;
    }
    
    Ok(text)
}

/// åˆ›å»ºä¸´æ—¶WAVæ–‡ä»¶
fn create_temp_wav(audio_data: &[f32], sample_rate: u32) -> Result<std::path::PathBuf, String> {
    let temp_dir = std::env::temp_dir();
    let temp_file = temp_dir.join(format!("voice_{}.wav", 
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs()
    ));
    
    // é‡é‡‡æ ·åˆ°16kHz
    let audio_16k = if sample_rate != 16000 {
        crate::commands::resample_audio(audio_data, sample_rate, 16000)
    } else {
        audio_data.to_vec()
    };
    
    crate::commands::create_wav_file(&temp_file, &audio_16k, 16000, 1)
        .map_err(|e| format!("åˆ›å»ºWAVæ–‡ä»¶å¤±è´¥: {}", e))?;
    
    Ok(temp_file)
}

/// ä¿å­˜è½¬å½•å†å²
async fn save_transcription_history(
    app: &tauri::AppHandle,
    text: &str,
    model: &str,
    duration: f64,
) {
    use crate::{AppState, types::TranscriptionEntry};
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    
    let entry = TranscriptionEntry {
        id: uuid::Uuid::new_v4().to_string(),
        text: text.to_string(),
        timestamp: chrono::Utc::now().timestamp_millis(),
        duration,
        model: model.to_string(),
        confidence: 0.95,
        audio_file_path: None,
        created_at: Some(chrono::Utc::now().to_rfc3339()),
        updated_at: Some(chrono::Utc::now().to_rfc3339()),
        tags: None,
        metadata: None,
    };
    
    // ä¿å­˜åˆ°æ•°æ®åº“
    let db = &state.database;
    db.insert_transcription(&entry).ok();
    
    // å‘é€äº‹ä»¶
    app.emit_all("transcription_result", &entry).ok();
}

/// æ–‡æœ¬æ³¨å…¥åˆ°æ´»åŠ¨åº”ç”¨
#[command]
pub async fn inject_text_to_active_app(
    text: String,
    target_bundle_id: Option<String>,
) -> Result<(), String> {
    // å®‰å…¨æ£€æŸ¥
    if let Some(ref bundle_id) = target_bundle_id {
        if bundle_id.contains("recordingking") {
            return Err("æ— æ³•å‘Recording Kingè‡ªèº«æ³¨å…¥æ–‡æœ¬".to_string());
        }
    }
    
    #[cfg(target_os = "macos")]
    {
        inject_text_macos(&text).await
    }
    
    #[cfg(not(target_os = "macos"))]
    {
        Err("å½“å‰å¹³å°ä¸æ”¯æŒæ–‡æœ¬æ³¨å…¥".to_string())
    }
}

/// macOSæ–‡æœ¬æ³¨å…¥å®ç°
#[cfg(target_os = "macos")]
async fn inject_text_macos(text: &str) -> Result<(), String> {
    use cocoa::base::{id, nil};
    use cocoa::foundation::{NSAutoreleasePool, NSString};
    use objc::{msg_send, sel, sel_impl};
    use core_graphics::event::{CGEvent, CGEventFlags};
    use core_graphics::event_source::{CGEventSource, CGEventSourceStateID};
    
    unsafe {
        let pool = NSAutoreleasePool::new(nil);
        
        // 1. å¤‡ä»½å‰ªè´´æ¿
        let pasteboard: id = msg_send![objc::class!(NSPasteboard), generalPasteboard];
        let string_type = NSString::alloc(nil).init_str("NSStringPboardType");
        let old_contents: id = msg_send![pasteboard, stringForType:string_type];
        
        // 2. å†™å…¥æ–‡æœ¬
        let text_string = NSString::alloc(nil).init_str(text);
        let _: () = msg_send![pasteboard, clearContents];
        let success: bool = msg_send![pasteboard, setString:text_string forType:string_type];
        
        if !success {
            pool.drain();
            return Err("å†™å…¥å‰ªè´´æ¿å¤±è´¥".to_string());
        }
        
        // 3. ç­‰å¾…
        std::thread::sleep(std::time::Duration::from_millis(100));
        
        // 4. å‘é€Cmd+V
        if let Ok(source) = CGEventSource::new(CGEventSourceStateID::HIDSystemState) {
            if let Ok(key_down) = CGEvent::new_keyboard_event(source.clone(), 9, true) {
                key_down.set_flags(CGEventFlags::CGEventFlagCommand);
                key_down.post(core_graphics::event::CGEventTapLocation::HID);
                
                std::thread::sleep(std::time::Duration::from_millis(50));
                
                if let Ok(key_up) = CGEvent::new_keyboard_event(source, 9, false) {
                    key_up.set_flags(CGEventFlags::CGEventFlagCommand);
                    key_up.post(core_graphics::event::CGEventTapLocation::HID);
                }
            }
        }
        
        // 5. æ¢å¤å‰ªè´´æ¿
        std::thread::sleep(std::time::Duration::from_millis(200));
        if old_contents != nil {
            let _: () = msg_send![pasteboard, clearContents];
            let _: bool = msg_send![pasteboard, setString:old_contents forType:string_type];
        }
        
        pool.drain();
    }
    
    Ok(())
}

/// åˆ›å»ºè½¬å½•é…ç½®
fn create_transcription_config(model_name: &str) -> TranscriptionConfig {
    match model_name {
        "luyingwang-online" => TranscriptionConfig {
            model_name: "luyin-api".to_string(),
            language: Some("auto".to_string()),
            temperature: Some(0.0),
            is_local: false,
            api_endpoint: None,
        },
        "gpt-4o-mini" => TranscriptionConfig {
            model_name: "gpt-4o-mini".to_string(),
            language: Some("auto".to_string()),
            temperature: Some(0.0),
            is_local: false,
            api_endpoint: None,
        },
        _ => TranscriptionConfig {
            model_name: "luyin-api".to_string(),
            language: Some("auto".to_string()),
            temperature: Some(0.0),
            is_local: false,
            api_endpoint: None,
        }
    }
}

/// å¼€å§‹æµå¼è¯­éŸ³å½•éŸ³ï¼ˆå®æ—¶è½¬å½•å’Œé€å­—æ³¨å…¥ï¼‰
#[command]
pub async fn start_streaming_voice_input(
    target_bundle_id: Option<String>,
    app: tauri::AppHandle,
) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    use std::sync::Arc;
    
    let state = app.state::<AppState>();
    
    // æ£€æŸ¥æ˜¯å¦å·²åœ¨å½•éŸ³
    {
        let is_recording = state.is_recording.lock();
        if *is_recording {
            println!("âš ï¸ å·²åœ¨æµå¼å½•éŸ³ä¸­ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–");
            return Ok("æµå¼å½•éŸ³å·²åœ¨è¿›è¡Œä¸­".to_string());
        }
    }
    
    println!("ğŸ™ï¸ å¯åŠ¨æµå¼è¯­éŸ³è¾“å…¥ï¼Œç›®æ ‡åº”ç”¨: {:?}", target_bundle_id);
    
    // æš‚æ—¶è¿”å›æˆåŠŸçŠ¶æ€ï¼Œæµå¼è½¬å½•åŠŸèƒ½å°†åœ¨æ¥ä¸‹æ¥çš„å¼€å‘ä¸­å®Œå–„
    // TODO: é›†æˆRealtimeAudioStreamerå’Œæµå¼è½¬å½•é€»è¾‘
    
    Ok("æµå¼è¯­éŸ³è¾“å…¥åŠŸèƒ½å·²å¯åŠ¨ - Week 1 å¼€å‘ä¸­".to_string())
}