use serde::{Deserialize, Serialize};
use tauri::command;
use crate::types::TranscriptionConfig;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ActiveAppInfo {
    pub name: String,
    pub icon: Option<String>,
    pub bundle_id: Option<String>,
}

/// è·å–å½“å‰æ´»åŠ¨åº”ç”¨çš„ä¿¡æ¯ï¼ˆè¯­éŸ³è¾“å…¥ç”¨ï¼‰
#[command]
pub async fn get_active_app_info_for_voice() -> Result<ActiveAppInfo, String> {
    #[cfg(target_os = "macos")]
    {
        use cocoa::base::{id, nil};
        use cocoa::foundation::{NSString, NSAutoreleasePool};
        use objc::{msg_send, sel, sel_impl};
        
        unsafe {
            let pool = NSAutoreleasePool::new(nil);
            
            // è·å– NSWorkspace
            let workspace_class = objc::class!(NSWorkspace);
            let workspace: id = msg_send![workspace_class, sharedWorkspace];
            
            // è·å–å½“å‰æ´»åŠ¨åº”ç”¨
            let active_app: id = msg_send![workspace, frontmostApplication];
            
            if active_app != nil {
                // è·å–åº”ç”¨åç§°
                let localized_name: id = msg_send![active_app, localizedName];
                let name = if localized_name != nil {
                    let name_str = NSString::UTF8String(localized_name);
                    if !name_str.is_null() {
                        std::ffi::CStr::from_ptr(name_str)
                            .to_string_lossy()
                            .to_string()
                    } else {
                        "Unknown".to_string()
                    }
                } else {
                    "Unknown".to_string()
                };
                
                // è·å– bundle identifier
                let bundle_id_ns: id = msg_send![active_app, bundleIdentifier];
                let bundle_id = if bundle_id_ns != nil {
                    let bundle_str = NSString::UTF8String(bundle_id_ns);
                    if !bundle_str.is_null() {
                        Some(std::ffi::CStr::from_ptr(bundle_str)
                            .to_string_lossy()
                            .to_string())
                    } else {
                        None
                    }
                } else {
                    None
                };
                
                // è·å–åº”ç”¨å›¾æ ‡ï¼ˆå¯é€‰ï¼Œè¾ƒå¤æ‚ï¼‰
                // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œè¿”å›None
                let icon = None;
                
                pool.drain();
                
                return Ok(ActiveAppInfo {
                    name,
                    icon,
                    bundle_id,
                });
            }
            
            pool.drain();
        }
    }
    
    #[cfg(not(target_os = "macos"))]
    {
        // å…¶ä»–å¹³å°çš„å®ç°
        return Ok(ActiveAppInfo {
            name: "Current Application".to_string(),
            icon: None,
            bundle_id: None,
        });
    }
    
    Err("æ— æ³•è·å–æ´»åŠ¨åº”ç”¨ä¿¡æ¯".to_string())
}

/// å¼€å§‹è¯­éŸ³å½•éŸ³ï¼ˆæ”¯æŒå®æ—¶è½¬å½•å’ŒVADï¼‰
#[command]
pub async fn start_voice_recording(
    _device_id: String,
    realtime: bool,
    app: tauri::AppHandle,
) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    use std::sync::Arc;
    use std::time::Duration;
    
    let state = app.state::<AppState>();
    
    // æ£€æŸ¥æ˜¯å¦å·²åœ¨å½•éŸ³
    {
        let is_recording = state.is_recording.lock();
        if *is_recording {
            println!("âš ï¸ å·²åœ¨å½•éŸ³ä¸­ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–");
            return Ok("å½•éŸ³å·²åœ¨è¿›è¡Œä¸­".to_string());
        }
    }
    
    // è·å–å½•éŸ³å™¨å¹¶å¯åŠ¨å½•éŸ³
    {
        let mut recorder = state.audio_recorder.lock();
        
        // é‡ç½®é™éŸ³æ£€æµ‹
        recorder.reset_silence_detection();
        
        // å¼€å§‹å½•éŸ³
        recorder.start_recording()
            .map_err(|e| format!("å¯åŠ¨å½•éŸ³å¤±è´¥: {}", e))?;
    }
    
    // è®¾ç½®å½•éŸ³çŠ¶æ€
    {
        let mut is_recording = state.is_recording.lock();
        *is_recording = true;
    }
    
    println!("ğŸ™ï¸ è¯­éŸ³å½•éŸ³å·²å¯åŠ¨ï¼ˆVADæ¨¡å¼ï¼‰");
    
    // å¯åŠ¨VADç›‘æµ‹å’Œè‡ªåŠ¨åœæ­¢
    if realtime {
        let app_handle = app.clone();
        let recorder_clone = Arc::clone(&state.audio_recorder);
        let is_recording_clone = Arc::clone(&state.is_recording);
        
        // å¯åŠ¨åå°ä»»åŠ¡ç›‘æµ‹éŸ³é¢‘ç”µå¹³å’Œé™éŸ³
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_millis(100));
            const MAX_SILENCE_DURATION: Duration = Duration::from_secs(2); // 2ç§’é™éŸ³åè‡ªåŠ¨åœæ­¢
            const MIN_RECORDING_DURATION: Duration = Duration::from_millis(500); // æœ€å°‘å½•éŸ³0.5ç§’
            let start_time = std::time::Instant::now();
            let mut has_sound = false;
            
            loop {
                interval.tick().await;
                
                // æ£€æŸ¥æ˜¯å¦è¿˜åœ¨å½•éŸ³
                let (is_recording, audio_level, silence_duration) = {
                    let recorder = recorder_clone.lock();
                    (
                        recorder.is_recording(),
                        recorder.get_current_audio_level().unwrap_or(0.0),
                        recorder.get_silence_duration(),
                    )
                };
                
                if !is_recording {
                    println!("ğŸ›‘ å½•éŸ³å·²åœæ­¢ï¼ˆå¤–éƒ¨è§¦å‘ï¼‰");
                    break;
                }
                
                // æ£€æµ‹åˆ°å£°éŸ³
                if audio_level > 0.01 {
                    has_sound = true;
                }
                
                // å‘é€éŸ³é¢‘ç”µå¹³äº‹ä»¶åˆ°å‰ç«¯
                if let Err(e) = app_handle.emit_all("audio_level", audio_level) {
                    eprintln!("å‘é€éŸ³é¢‘ç”µå¹³äº‹ä»¶å¤±è´¥: {}", e);
                }
                
                // æ£€æŸ¥æ˜¯å¦åº”è¯¥è‡ªåŠ¨åœæ­¢å½•éŸ³
                let recording_duration = std::time::Instant::now().duration_since(start_time);
                
                // æ¡ä»¶ï¼šå½•éŸ³è¶…è¿‡æœ€å°æ—¶é•¿ + æ£€æµ‹åˆ°è¿‡å£°éŸ³ + é™éŸ³è¶…è¿‡é˜ˆå€¼
                if recording_duration > MIN_RECORDING_DURATION 
                    && has_sound 
                    && silence_duration > MAX_SILENCE_DURATION {
                    
                    println!("ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³è¶…è¿‡{}ç§’ï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³", MAX_SILENCE_DURATION.as_secs());
                    
                    // è§¦å‘åœæ­¢å½•éŸ³
                    if let Err(e) = app_handle.emit_all("auto_stop_recording", true) {
                        eprintln!("å‘é€è‡ªåŠ¨åœæ­¢äº‹ä»¶å¤±è´¥: {}", e);
                    }
                    
                    // ç›´æ¥è°ƒç”¨åœæ­¢å‡½æ•°
                    match crate::commands::stop_voice_recording(app_handle.clone()).await {
                        Ok(text) => {
                            println!("âœ… è¯­éŸ³è¾“å…¥å®Œæˆ: {}", text);
                        }
                        Err(e) => {
                            eprintln!("âŒ åœæ­¢å½•éŸ³å¤±è´¥: {}", e);
                        }
                    }
                    
                    break;
                }
                
                // å‘é€VADçŠ¶æ€åˆ°å‰ç«¯
                let vad_status = serde_json::json!({
                    "is_speaking": audio_level > 0.01,
                    "audio_level": audio_level,
                    "silence_duration": silence_duration.as_millis(),
                    "recording_duration": recording_duration.as_millis(),
                });
                
                if let Err(e) = app_handle.emit_all("vad_status", vad_status) {
                    eprintln!("å‘é€VADçŠ¶æ€å¤±è´¥: {}", e);
                }
            }
            
            // ç¡®ä¿çŠ¶æ€æ­£ç¡®é‡ç½®
            {
                let mut is_recording = is_recording_clone.lock();
                *is_recording = false;
            }
        });
        
        println!("âœ… å¯åŠ¨VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰æ¨¡å¼");
    }
    
    Ok("å½•éŸ³å·²å¼€å§‹".to_string())
}

/// åœæ­¢è¯­éŸ³å½•éŸ³å¹¶è¿”å›æœ€ç»ˆè½¬å½•ç»“æœ
#[command]
pub async fn stop_voice_recording(app: tauri::AppHandle) -> Result<String, String> {
    use crate::{AppState, types::TranscriptionConfig};
    use tauri::Manager;
    use std::path::PathBuf;
    
    let state = app.state::<AppState>();
    
    // è·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹è®¾ç½®ï¼Œå¦‚æœç”¨æˆ·è®¾ç½®çš„æ˜¯æ—§æ¨¡å‹åˆ™å›é€€åˆ°LuYinWang
    let user_selected_model = {
        let settings = state.settings.lock();
        let configured_model = settings.transcription.default_model.clone();
        
        // å¦‚æœç”¨æˆ·é…ç½®çš„æ˜¯æ—§çš„whisperæ¨¡å‹ï¼Œè‡ªåŠ¨å›é€€åˆ°LuYinWangåœ¨çº¿æœåŠ¡
        if configured_model == "whisper-1" || configured_model.starts_with("whisper-") {
            println!("âš ï¸ æ£€æµ‹åˆ°æ—§çš„æ¨¡å‹é…ç½® '{}', è‡ªåŠ¨ä½¿ç”¨LuYinWangåœ¨çº¿æœåŠ¡", configured_model);
            "luyingwang-online".to_string()
        } else {
            configured_model
        }
    };
    
    // æ£€æŸ¥æ˜¯å¦åœ¨å½•éŸ³
    {
        let is_recording = state.is_recording.lock();
        if !*is_recording {
            println!("âš ï¸ å½“å‰æ²¡æœ‰åœ¨å½•éŸ³");
            return Ok(String::new());
        }
    }
    
    // åœæ­¢å½•éŸ³å¹¶è·å–éŸ³é¢‘æ•°æ®å’Œé‡‡æ ·ç‡
    let (audio_data, actual_sample_rate) = {
        let mut recorder = state.audio_recorder.lock();
        
        // è·å–å®é™…é‡‡æ ·ç‡
        let sample_rate = recorder.get_sample_rate();
        
        println!("ğŸ›‘ åœæ­¢å½•éŸ³");
        let audio = recorder.stop_recording()
            .map_err(|e| format!("åœæ­¢å½•éŸ³å¤±è´¥: {}", e))?;
        
        (audio, sample_rate)
    };
    
    // é‡ç½®å½•éŸ³çŠ¶æ€
    {
        let mut is_recording = state.is_recording.lock();
        *is_recording = false;
    }
    
    if audio_data.is_empty() {
        return Ok(String::new());
    }
    
    println!("ğŸ“Š å½•éŸ³å·²åœæ­¢ï¼ŒéŸ³é¢‘æ ·æœ¬æ•°: {}", audio_data.len());
    println!("ğŸ¤ éŸ³é¢‘æ—¶é•¿: {:.2}ç§’", audio_data.len() as f32 / actual_sample_rate as f32);
    println!("ğŸ“Š å®é™…é‡‡æ ·ç‡: {} Hz", actual_sample_rate);
    println!("ğŸ”Š éŸ³é¢‘æ•°æ®å‰10ä¸ªæ ·æœ¬: {:?}", &audio_data[..10.min(audio_data.len())]);
    
    // å¦‚æœéŸ³é¢‘æ•°æ®å¤ªçŸ­ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆåŸºäºå®é™…é‡‡æ ·ç‡åˆ¤æ–­ï¼‰
    if audio_data.len() < actual_sample_rate as usize { // å°äº1ç§’çš„éŸ³é¢‘
        println!("âš ï¸ éŸ³é¢‘å¤ªçŸ­ï¼ˆå°äº1ç§’ï¼‰ï¼Œè·³è¿‡è½¬å½•");
        return Ok(String::new());
    }
    
    // åˆ›å»ºä¸´æ—¶WAVæ–‡ä»¶
    let temp_dir = std::env::temp_dir();
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs();
    let temp_file = temp_dir.join(format!("voice_input_{}.wav", timestamp));
    
    // å¦‚æœé‡‡æ ·ç‡ä¸æ˜¯16kHzï¼Œè¿›è¡Œé‡é‡‡æ ·ä»¥å…¼å®¹è½¬å½•æœåŠ¡
    let (audio_for_transcription, transcription_sample_rate) = if actual_sample_rate != 16000 {
        println!("ğŸ”„ é‡é‡‡æ ·éŸ³é¢‘ä» {} Hz åˆ° 16000 Hz ä»¥å…¼å®¹è½¬å½•æœåŠ¡", actual_sample_rate);
        let resampled = crate::commands::resample_audio(&audio_data, actual_sample_rate, 16000);
        (resampled, 16000)
    } else {
        (audio_data.clone(), actual_sample_rate)
    };
    
    // å†™å…¥WAVæ–‡ä»¶ - ä½¿ç”¨16kHzé‡‡æ ·ç‡ä»¥å…¼å®¹è½¬å½•æœåŠ¡
    println!("ğŸ’¾ å‡†å¤‡ä¿å­˜WAVæ–‡ä»¶åˆ°: {:?}", temp_file);
    crate::commands::create_wav_file(&temp_file, &audio_for_transcription, transcription_sample_rate, 1)
        .map_err(|e| {
            eprintln!("âŒ åˆ›å»ºWAVæ–‡ä»¶å¤±è´¥: {}", e);
            format!("åˆ›å»ºWAVæ–‡ä»¶å¤±è´¥: {}", e)
        })?;
    
    // éªŒè¯æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
    if temp_file.exists() {
        let file_size = std::fs::metadata(&temp_file).unwrap().len();
        println!("âœ… WAVæ–‡ä»¶åˆ›å»ºæˆåŠŸï¼Œå¤§å°: {} å­—èŠ‚", file_size);
    } else {
        eprintln!("âŒ WAVæ–‡ä»¶æœªåˆ›å»ºï¼");
    }
    
    // æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹åˆ›å»ºè½¬å½•é…ç½®
    let config = create_transcription_config(&user_selected_model);
    
    println!("ğŸ¯ ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹: {}", user_selected_model);
    println!("ğŸ”§ è½¬å½•é…ç½® - æ¨¡å‹å: {}, æ˜¯å¦æœ¬åœ°: {}", config.model_name, config.is_local);
    
    // è¿›è¡Œè½¬å½•
    println!("ğŸ¯ å¼€å§‹è½¬å½•ï¼Œæ¨¡å‹: {}, è¯­è¨€: {:?}", config.model_name, config.language);
    println!("ğŸ“‚ WAVæ–‡ä»¶: {:?}, å¤§å°: {} æ ·æœ¬", temp_file, audio_data.len());
    
    let result = state.transcription_service
        .transcribe_audio(temp_file.to_str().unwrap(), &config)
        .await
        .map_err(|e| {
            eprintln!("âŒ è½¬å½•æœåŠ¡é”™è¯¯: {}", e);
            // å¦‚æœæ˜¯APIé”™è¯¯ï¼Œä¸è¦æŠ›å‡ºé”™è¯¯ï¼Œè€Œæ˜¯è¿”å›ç©ºå­—ç¬¦ä¸²è®©å‰ç«¯é‡è¯•
            println!("âš ï¸ è½¬å½•å¤±è´¥ï¼Œå°†è¿”å›ç©ºå­—ç¬¦ä¸²ä»¥ä¾¿å‰ç«¯é‡è¯•");
            format!("è½¬å½•å¤±è´¥: {}", e)
        })?;
    
    let final_text = result.text.trim().to_string();
    
    // å¤‡ä»½æœºåˆ¶ï¼šæ— è®ºæˆåŠŸä¸å¦éƒ½å…ˆå¤‡ä»½ï¼Œæ–¹ä¾¿è°ƒè¯•
    let backup_dir = directories::UserDirs::new()
        .and_then(|dirs| Some(dirs.document_dir()?.to_path_buf()))
        .unwrap_or_else(|| std::path::PathBuf::from("/tmp"))
        .join("RecordingKing")
        .join(if final_text.is_empty() { "failed_transcriptions" } else { "successful_transcriptions" });
    
    if !backup_dir.exists() {
        std::fs::create_dir_all(&backup_dir).ok();
    }
    
    let backup_file = backup_dir.join(format!("voice_input_{}.wav", timestamp));
    if let Err(e) = std::fs::copy(&temp_file, &backup_file) {
        eprintln!("âŒ å¤‡ä»½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {}", e);
    } else {
        println!("ğŸ’¾ éŸ³é¢‘å·²å¤‡ä»½åˆ°: {:?}", backup_file);
        
        // åŒæ—¶ä¿å­˜è½¬å½•ç»“æœåˆ°æ–‡æœ¬æ–‡ä»¶
        let result_file = backup_dir.join(format!("voice_input_{}_result.txt", timestamp));
        let result_content = if final_text.is_empty() {
            format!("è½¬å½•å¤±è´¥\næ—¶é—´: {}\næ¨¡å‹: {}\néŸ³é¢‘å¤§å°: {} bytes", 
                    timestamp, user_selected_model, audio_data.len() * 2)
        } else {
            format!("è½¬å½•æˆåŠŸ\næ—¶é—´: {}\næ¨¡å‹: {}\néŸ³é¢‘å¤§å°: {} bytes\nç»“æœ: {}", 
                    timestamp, user_selected_model, audio_data.len() * 2, final_text)
        };
        
        if let Err(e) = std::fs::write(&result_file, result_content) {
            eprintln!("âŒ ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {}", e);
        } else {
            println!("ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {:?}", result_file);
        }
    }
    
    // åªæœ‰åœ¨è½¬å½•æˆåŠŸåæ‰åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    if !final_text.is_empty() {
        if let Err(e) = std::fs::remove_file(&temp_file) {
            eprintln!("æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {}", e);
        } else {
            println!("ğŸ—‘ï¸ å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶");
        }
    } else {
        println!("ğŸ’¾ ä¿ç•™ä¸´æ—¶æ–‡ä»¶ä»¥ä¾¿é‡è¯•: {:?}", temp_file);
    }
    
    if final_text.is_empty() {
        println!("âš ï¸ è½¬å½•ç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯APIé—®é¢˜ã€é™éŸ³æˆ–è¯†åˆ«å¤±è´¥");
        println!("ğŸ” éŸ³é¢‘æ–‡ä»¶å¤§å°: {} å­—èŠ‚", audio_data.len() * 2);  // æ¯ä¸ªæ ·æœ¬2å­—èŠ‚
    } else {
        println!("âœ… è¯­éŸ³è½¬å½•æˆåŠŸ: '{}'", final_text);
        
        // å‘é€è½¬å½•ç»“æœäº‹ä»¶åˆ°å‰ç«¯ï¼Œä»¥ä¾¿æ·»åŠ åˆ°å†å²è®°å½•
        // æ³¨æ„ï¼šä¸è®¾ç½® audio_file_pathï¼Œè¿™æ ·ä¼šè¢«åˆ†ç±»ä¸º LIVEï¼ˆå®æ—¶å¬å†™ï¼‰
        let transcription_entry = crate::types::TranscriptionEntry {
            id: uuid::Uuid::new_v4().to_string(),
            text: final_text.clone(),
            timestamp: chrono::Utc::now().timestamp_millis(),
            duration: audio_data.len() as f64 / actual_sample_rate as f64,
            model: user_selected_model.clone(),
            confidence: 0.95,
            audio_file_path: None,  // é‡è¦ï¼šè®¾ç½®ä¸º None ä»¥æ ‡è®°ä¸º LIVE ç±»å‹
            created_at: Some(chrono::Utc::now().to_rfc3339()),
            updated_at: Some(chrono::Utc::now().to_rfc3339()),
            tags: None,
            metadata: None,
        };
        
        // ä¿å­˜åˆ°æ•°æ®åº“
        {
            let db_manager = state.database.clone();
            if let Err(e) = db_manager.insert_transcription(&transcription_entry) {
                eprintln!("âŒ ä¿å­˜è¯­éŸ³è¾“å…¥å†å²è®°å½•å¤±è´¥: {}", e);
            } else {
                println!("âœ… è¯­éŸ³è¾“å…¥å†å²è®°å½•å·²ä¿å­˜");
            }
        }
        
        // å‘é€äº‹ä»¶åˆ°å‰ç«¯
        if let Err(e) = app.emit_all("transcription_result", &transcription_entry) {
            eprintln!("âŒ å‘é€è¯­éŸ³è¾“å…¥è½¬å½•ç»“æœäº‹ä»¶å¤±è´¥: {}", e);
        } else {
            println!("âœ… è¯­éŸ³è¾“å…¥è½¬å½•ç»“æœäº‹ä»¶å·²å‘é€åˆ°å‰ç«¯");
        }
    }
    
    Ok(final_text)
}

/// è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
#[command]
pub fn get_current_model_info(app: tauri::AppHandle) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    let settings = state.settings.lock();
    let model = settings.transcription.default_model.clone();
    
    // å¦‚æœç”¨æˆ·é…ç½®çš„æ˜¯æ—§çš„whisperæ¨¡å‹ï¼Œè‡ªåŠ¨å›é€€åˆ°LuYinWangåœ¨çº¿æœåŠ¡
    let final_model = if model == "whisper-1" || model.starts_with("whisper-") {
        "luyingwang-online".to_string()
    } else {
        model
    };
    
    Ok(final_model)
}

/// å°†æ–‡æœ¬æ³¨å…¥åˆ°å½“å‰æ´»åŠ¨çš„åº”ç”¨
#[command]
pub async fn inject_text_to_active_app(text: String) -> Result<(), String> {
    #[cfg(target_os = "macos")]
    {
        use cocoa::base::{id, nil};
        use cocoa::foundation::{NSAutoreleasePool, NSString};
        use objc::{msg_send, sel, sel_impl};
        
        // å®‰å…¨æ£€æŸ¥ï¼šè·å–å½“å‰æ´»åŠ¨åº”ç”¨ï¼Œç¡®ä¿ä¸æ˜¯å‘è‡ªå·±æ³¨å…¥
        let current_app = get_active_app_info_for_voice().await.ok();
        if let Some(app_info) = current_app {
            if app_info.name.contains("Recording King") || 
               app_info.bundle_id.as_ref().map_or(false, |id| id.contains("recordingking")) {
                eprintln!("âš ï¸ è­¦å‘Šï¼šå°è¯•å‘è‡ªå·±æ³¨å…¥æ–‡æœ¬ï¼Œè·³è¿‡æ“ä½œä»¥é˜²æ­¢å´©æºƒ");
                return Err("æ— æ³•å‘ Recording King è‡ªèº«æ³¨å…¥æ–‡æœ¬".to_string());
            }
        }
        
        unsafe {
            let pool = NSAutoreleasePool::new(nil);
            
            // ä½¿ç”¨æ›´å¯é çš„ç²˜è´´æ¿æ–¹æ³•æ³¨å…¥æ–‡æœ¬
            // 1. å…ˆå¤‡ä»½å½“å‰å‰ªè´´æ¿å†…å®¹
            let pasteboard_class = objc::class!(NSPasteboard);
            let general_pasteboard: id = msg_send![pasteboard_class, generalPasteboard];
            
            // NSPasteboardTypeString å¸¸é‡
            let string_type = NSString::alloc(nil).init_str("public.utf8-plain-text");
            let old_contents: id = msg_send![general_pasteboard, stringForType:string_type];
            
            // 2. å°†æ–‡æœ¬å†™å…¥å‰ªè´´æ¿
            let text_string = NSString::alloc(nil).init_str(&text);
            let _: () = msg_send![general_pasteboard, clearContents];
            let _: bool = msg_send![general_pasteboard, setString:text_string forType:string_type];
            
            // 3. ä½¿ç”¨Cmd+Vç²˜è´´ - æ¯”keystrokeæ›´å¯é 
            let script = r#"tell application "System Events" to key code 9 using command down"#;
            
            let ns_script_class = objc::class!(NSAppleScript);
            let ns_script: id = msg_send![ns_script_class, alloc];
            let script_string = NSString::alloc(nil).init_str(script);
            let ns_script: id = msg_send![ns_script, initWithSource:script_string];
            
            if ns_script != nil {
                let _: id = msg_send![ns_script, executeAndReturnError:nil];
                
                // 4. å»¶è¿Ÿä¸€ç‚¹åæ¢å¤å‰ªè´´æ¿å†…å®¹ï¼ˆå¦‚æœä¹‹å‰æœ‰å†…å®¹ï¼‰
                std::thread::sleep(std::time::Duration::from_millis(100));
                if old_contents != nil {
                    let _: () = msg_send![general_pasteboard, clearContents];
                    let _: bool = msg_send![general_pasteboard, setString:old_contents forType:string_type];
                }
            }
            
            pool.drain();
        }
        
        Ok(())
    }
    
    #[cfg(not(target_os = "macos"))]
    {
        // å…¶ä»–å¹³å°çš„å®ç°
        Err("å½“å‰å¹³å°ä¸æ”¯æŒæ–‡æœ¬æ³¨å…¥".to_string())
    }
}

/// æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹åˆ›å»ºè½¬å½•é…ç½®
fn create_transcription_config(model_name: &str) -> TranscriptionConfig {
    match model_name {
        "luyingwang-online" => TranscriptionConfig {
            model_name: "luyin-api".to_string(),
            language: Some("auto".to_string()),
            temperature: Some(0.0),
            is_local: false,
            api_endpoint: None,
        },
        "gpt-4o-mini" => TranscriptionConfig {
            model_name: "gpt-4o-mini".to_string(),
            language: Some("auto".to_string()),
            temperature: Some(0.0),
            is_local: false,
            api_endpoint: None,
        },
        model_name if model_name.starts_with("whisper-") => TranscriptionConfig {
            model_name: model_name.to_string(),
            language: Some("zh".to_string()),
            temperature: Some(0.0),
            is_local: true,
            api_endpoint: None,
        },
        _ => {
            // é»˜è®¤ä½¿ç”¨LuYinWangåœ¨çº¿è½¬å½•æœåŠ¡
            println!("âš ï¸ æœªçŸ¥æ¨¡å‹ '{}', ä½¿ç”¨é»˜è®¤çš„LuYinWangåœ¨çº¿æœåŠ¡", model_name);
            TranscriptionConfig {
                model_name: "luyin-api".to_string(),
                language: Some("auto".to_string()),
                temperature: Some(0.0),
                is_local: false,
                api_endpoint: None,
            }
        }
    }
}