use serde::{Deserialize, Serialize};
use tauri::command;
use crate::types::TranscriptionConfig;
use crate::system::{ProgressiveTextInjector, ProgressiveInjectionConfig, TextInjectionConfig};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ActiveAppInfo {
    pub name: String,
    pub bundle_id: Option<String>,
}

/// è·å–å½“å‰æ´»åŠ¨åº”ç”¨ä¿¡æ¯
#[command]
pub async fn get_active_app_info_for_voice() -> Result<ActiveAppInfo, String> {
    #[cfg(target_os = "macos")]
    {
        use cocoa::base::{id, nil};
        use cocoa::foundation::{NSString, NSAutoreleasePool};
        use objc::{msg_send, sel, sel_impl};
        
        unsafe {
            let pool = NSAutoreleasePool::new(nil);
            let workspace: id = msg_send![objc::class!(NSWorkspace), sharedWorkspace];
            let active_app: id = msg_send![workspace, frontmostApplication];
            
            if active_app != nil {
                let name: id = msg_send![active_app, localizedName];
                let bundle_id: id = msg_send![active_app, bundleIdentifier];
                
                let app_name = if name != nil {
                    std::ffi::CStr::from_ptr(NSString::UTF8String(name))
                        .to_string_lossy()
                        .to_string()
                } else {
                    "Unknown".to_string()
                };
                
                let app_bundle_id = if bundle_id != nil {
                    Some(std::ffi::CStr::from_ptr(NSString::UTF8String(bundle_id))
                        .to_string_lossy()
                        .to_string())
                } else {
                    None
                };
                
                pool.drain();
                return Ok(ActiveAppInfo {
                    name: app_name,
                    bundle_id: app_bundle_id,
                });
            }
            pool.drain();
        }
    }
    
    Err("æ— æ³•è·å–æ´»åŠ¨åº”ç”¨ä¿¡æ¯".to_string())
}

/// å¼€å§‹è¯­éŸ³å½•éŸ³
#[command]
pub async fn start_voice_recording(
    app: tauri::AppHandle,
) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    
    // æ£€æŸ¥å½•éŸ³çŠ¶æ€
    {
        let is_recording = state.is_recording.lock();
        if *is_recording {
            return Ok("å½•éŸ³å·²åœ¨è¿›è¡Œä¸­".to_string());
        }
    }
    
    // å¯åŠ¨å½•éŸ³
    {
        let mut recorder = state.audio_recorder.lock();
        recorder.reset_silence_detection();
        recorder.start_recording()
            .map_err(|e| format!("å¯åŠ¨å½•éŸ³å¤±è´¥: {}", e))?;
    }
    
    // æ›´æ–°çŠ¶æ€
    {
        let mut is_recording = state.is_recording.lock();
        *is_recording = true;
    }
    
    // å¯åŠ¨VADç›‘æµ‹
    start_vad_monitor(app).await;
    
    Ok("å½•éŸ³å·²å¼€å§‹".to_string())
}

/// VADç›‘æµ‹ä»»åŠ¡
async fn start_vad_monitor(app: tauri::AppHandle) {
    use crate::AppState;
    use tauri::Manager;
    use std::sync::Arc;
    use std::time::Duration;
    
    let state = app.state::<AppState>();
    let app_handle = app.clone();
    let recorder_clone = Arc::clone(&state.audio_recorder);
    let is_recording_clone = Arc::clone(&state.is_recording);
    
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(Duration::from_millis(100));
        const MAX_SILENCE: Duration = Duration::from_secs(2);
        const MIN_DURATION: Duration = Duration::from_millis(500);
        
        let start_time = std::time::Instant::now();
        let mut has_sound = false;
        
        loop {
            interval.tick().await;
            
            let (is_recording, audio_level, silence_duration) = {
                let recorder = recorder_clone.lock();
                (
                    recorder.is_recording(),
                    recorder.get_current_audio_level().unwrap_or(0.0),
                    recorder.get_silence_duration(),
                )
            };
            
            if !is_recording {
                break;
            }
            
            if audio_level > 0.01 {
                has_sound = true;
            }
            
            // è‡ªåŠ¨åœæ­¢æ¡ä»¶
            let duration = start_time.elapsed();
            if duration > MIN_DURATION && has_sound && silence_duration > MAX_SILENCE {
                crate::commands::stop_voice_recording(app_handle.clone()).await.ok();
                break;
            }
            
            // å‘é€çŠ¶æ€æ›´æ–°
            app_handle.emit_all("vad_status", serde_json::json!({
                "is_speaking": audio_level > 0.01,
                "audio_level": audio_level,
                "silence_duration": silence_duration.as_millis(),
            })).ok();
        }
        
        let mut is_recording = is_recording_clone.lock();
        *is_recording = false;
    });
}

/// åœæ­¢è¯­éŸ³å½•éŸ³å¹¶è½¬å½•
#[command]
pub async fn stop_voice_recording(app: tauri::AppHandle) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    
    // æ£€æŸ¥å½•éŸ³çŠ¶æ€
    {
        let is_recording = state.is_recording.lock();
        if !*is_recording {
            return Ok(String::new());
        }
    }
    
    // åœæ­¢å½•éŸ³
    let (audio_data, sample_rate) = {
        let mut recorder = state.audio_recorder.lock();
        let sr = recorder.get_sample_rate();
        let audio = recorder.stop_recording()
            .map_err(|e| format!("åœæ­¢å½•éŸ³å¤±è´¥: {}", e))?;
        (audio, sr)
    };
    
    // é‡ç½®çŠ¶æ€
    {
        let mut is_recording = state.is_recording.lock();
        *is_recording = false;
    }
    
    if audio_data.is_empty() || audio_data.len() < sample_rate as usize {
        return Ok(String::new());
    }
    
    // è½¬å½•éŸ³é¢‘
    let result = transcribe_audio(app.clone(), audio_data, sample_rate).await?;
    
    Ok(result)
}

/// è½¬å½•éŸ³é¢‘
async fn transcribe_audio(
    app: tauri::AppHandle,
    audio_data: Vec<f32>,
    sample_rate: u32,
) -> Result<String, String> {
    use crate::AppState;
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    
    // åˆ›å»ºWAVæ–‡ä»¶
    let temp_file = create_temp_wav(&audio_data, sample_rate)?;
    
    // è·å–æ¨¡å‹é…ç½®
    let model = {
        let settings = state.settings.lock();
        settings.transcription.default_model.clone()
    };
    
    let config = create_transcription_config(&model);
    
    // è½¬å½•
    let result = state.transcription_service
        .transcribe_audio(temp_file.to_str().unwrap(), &config)
        .await
        .map_err(|e| format!("è½¬å½•å¤±è´¥: {}", e))?;
    
    let text = result.text.trim().to_string();
    
    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    std::fs::remove_file(&temp_file).ok();
    
    // ä¿å­˜åˆ°å†å²è®°å½•
    if !text.is_empty() {
        save_transcription_history(&app, &text, &model, audio_data.len() as f64 / sample_rate as f64).await;
    }
    
    Ok(text)
}

/// åˆ›å»ºä¸´æ—¶WAVæ–‡ä»¶
fn create_temp_wav(audio_data: &[f32], sample_rate: u32) -> Result<std::path::PathBuf, String> {
    let temp_dir = std::env::temp_dir();
    let temp_file = temp_dir.join(format!("voice_{}.wav", 
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs()
    ));
    
    // é‡é‡‡æ ·åˆ°16kHz
    let audio_16k = if sample_rate != 16000 {
        crate::commands::resample_audio(audio_data, sample_rate, 16000)
    } else {
        audio_data.to_vec()
    };
    
    crate::commands::create_wav_file(&temp_file, &audio_16k, 16000, 1)
        .map_err(|e| format!("åˆ›å»ºWAVæ–‡ä»¶å¤±è´¥: {}", e))?;
    
    Ok(temp_file)
}

/// ä¿å­˜è½¬å½•å†å²
async fn save_transcription_history(
    app: &tauri::AppHandle,
    text: &str,
    model: &str,
    duration: f64,
) {
    use crate::{AppState, types::TranscriptionEntry};
    use tauri::Manager;
    
    let state = app.state::<AppState>();
    
    let entry = TranscriptionEntry {
        id: uuid::Uuid::new_v4().to_string(),
        text: text.to_string(),
        timestamp: chrono::Utc::now().timestamp_millis(),
        duration,
        model: model.to_string(),
        confidence: 0.95,
        audio_file_path: None,
        created_at: Some(chrono::Utc::now().to_rfc3339()),
        updated_at: Some(chrono::Utc::now().to_rfc3339()),
        tags: None,
        metadata: None,
    };
    
    // ä¿å­˜åˆ°æ•°æ®åº“
    let db = &state.database;
    db.insert_transcription(&entry).ok();
    
    // å‘é€äº‹ä»¶
    app.emit_all("transcription_result", &entry).ok();
}

/// æ–‡æœ¬æ³¨å…¥åˆ°æ´»åŠ¨åº”ç”¨
#[command]
pub async fn inject_text_to_active_app(
    text: String,
    target_bundle_id: Option<String>,
) -> Result<(), String> {
    // å®‰å…¨æ£€æŸ¥
    if let Some(ref bundle_id) = target_bundle_id {
        if bundle_id.contains("recordingking") {
            return Err("æ— æ³•å‘Recording Kingè‡ªèº«æ³¨å…¥æ–‡æœ¬".to_string());
        }
    }
    
    #[cfg(target_os = "macos")]
    {
        inject_text_macos(&text).await
    }
    
    #[cfg(not(target_os = "macos"))]
    {
        Err("å½“å‰å¹³å°ä¸æ”¯æŒæ–‡æœ¬æ³¨å…¥".to_string())
    }
}

/// macOSæ–‡æœ¬æ³¨å…¥å®ç°
#[cfg(target_os = "macos")]
async fn inject_text_macos(text: &str) -> Result<(), String> {
    use cocoa::base::{id, nil};
    use cocoa::foundation::{NSAutoreleasePool, NSString};
    use objc::{msg_send, sel, sel_impl};
    use core_graphics::event::{CGEvent, CGEventFlags};
    use core_graphics::event_source::{CGEventSource, CGEventSourceStateID};
    
    unsafe {
        let pool = NSAutoreleasePool::new(nil);
        
        // 1. å¤‡ä»½å‰ªè´´æ¿
        let pasteboard: id = msg_send![objc::class!(NSPasteboard), generalPasteboard];
        let string_type = NSString::alloc(nil).init_str("NSStringPboardType");
        let old_contents: id = msg_send![pasteboard, stringForType:string_type];
        
        // 2. å†™å…¥æ–‡æœ¬
        let text_string = NSString::alloc(nil).init_str(text);
        let _: () = msg_send![pasteboard, clearContents];
        let success: bool = msg_send![pasteboard, setString:text_string forType:string_type];
        
        if !success {
            pool.drain();
            return Err("å†™å…¥å‰ªè´´æ¿å¤±è´¥".to_string());
        }
        
        // 3. ç­‰å¾…
        std::thread::sleep(std::time::Duration::from_millis(100));
        
        // 4. å‘é€Cmd+V
        if let Ok(source) = CGEventSource::new(CGEventSourceStateID::HIDSystemState) {
            if let Ok(key_down) = CGEvent::new_keyboard_event(source.clone(), 9, true) {
                key_down.set_flags(CGEventFlags::CGEventFlagCommand);
                key_down.post(core_graphics::event::CGEventTapLocation::HID);
                
                std::thread::sleep(std::time::Duration::from_millis(50));
                
                if let Ok(key_up) = CGEvent::new_keyboard_event(source, 9, false) {
                    key_up.set_flags(CGEventFlags::CGEventFlagCommand);
                    key_up.post(core_graphics::event::CGEventTapLocation::HID);
                }
            }
        }
        
        // 5. æ¢å¤å‰ªè´´æ¿
        std::thread::sleep(std::time::Duration::from_millis(200));
        if old_contents != nil {
            let _: () = msg_send![pasteboard, clearContents];
            let _: bool = msg_send![pasteboard, setString:old_contents forType:string_type];
        }
        
        pool.drain();
    }
    
    Ok(())
}

/// åˆ›å»ºè½¬å½•é…ç½®
fn create_transcription_config(model_name: &str) -> TranscriptionConfig {
    match model_name {
        "luyingwang-online" => TranscriptionConfig {
            model_name: "luyin-api".to_string(),
            language: Some("auto".to_string()),
            temperature: Some(0.0),
            is_local: false,
            api_endpoint: None,
        },
        "gpt-4o-mini" => TranscriptionConfig {
            model_name: "gpt-4o-mini".to_string(),
            language: Some("auto".to_string()),
            temperature: Some(0.0),
            is_local: false,
            api_endpoint: None,
        },
        _ => TranscriptionConfig {
            model_name: "luyin-api".to_string(),
            language: Some("auto".to_string()),
            temperature: Some(0.0),
            is_local: false,
            api_endpoint: None,
        }
    }
}

/// å¼€å§‹æµå¼è¯­éŸ³å½•éŸ³ï¼ˆå®æ—¶è½¬å½•å’Œé€å­—æ³¨å…¥ï¼‰
#[command]
pub async fn start_streaming_voice_input(
    target_bundle_id: Option<String>,
    app: tauri::AppHandle,
) -> Result<String, String> {
    use crate::AppState;
    use crate::audio::streaming_transcriptor::{StreamingVoiceTranscriptor, StreamingConfig};
    use tauri::Manager;
    use std::sync::Arc;
    
    let state = app.state::<AppState>();
    
    // æ£€æŸ¥æ˜¯å¦å·²åœ¨å½•éŸ³
    {
        let is_recording = state.is_recording.lock();
        if *is_recording {
            println!("âš ï¸ å·²åœ¨æµå¼å½•éŸ³ä¸­ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–");
            return Ok("æµå¼å½•éŸ³å·²åœ¨è¿›è¡Œä¸­".to_string());
        }
    }
    
    println!("ğŸ™ï¸ å¯åŠ¨æµå¼è¯­éŸ³è¾“å…¥ï¼Œç›®æ ‡åº”ç”¨: {:?}", target_bundle_id);
    
    // åˆ›å»ºæµå¼è½¬å½•é…ç½®
    let streaming_config = StreamingConfig {
        chunk_duration_ms: 500,      // 500mså—å®ç°å¿«é€Ÿå“åº”
        overlap_duration_ms: 100,    // 100msé‡å é¿å…ä¸¢å¤±è¾¹ç•Œè¯
        min_confidence: 0.6,         // é€‚ä¸­çš„ç½®ä¿¡åº¦é˜ˆå€¼
        silence_timeout_ms: 3000,    // 3ç§’é™éŸ³è¶…æ—¶
        max_partial_length: 200,     // æœ€å¤š200å­—ç¬¦éƒ¨åˆ†æ–‡æœ¬
    };
    
    // åˆ›å»ºæµå¼è½¬å½•å™¨
    let transcription_service = state.transcription_service.clone();
    let (mut transcriptor, mut event_receiver) = StreamingVoiceTranscriptor::new(
        streaming_config,
        transcription_service,
    );
    
    // å¯åŠ¨æµå¼è½¬å½•ï¼ˆæš‚æ—¶ä½¿ç”¨æ¨¡æ‹ŸéŸ³é¢‘è¾“å…¥ï¼‰
    // TODO: é›†æˆçœŸå®çš„éŸ³é¢‘æµè¾“å…¥
    match transcriptor.start_streaming(tokio::sync::mpsc::unbounded_channel().1).await {
        Ok(_) => {
            println!("âœ… æµå¼è½¬å½•å™¨å¯åŠ¨æˆåŠŸ");
        }
        Err(e) => {
            return Err(format!("å¯åŠ¨æµå¼è½¬å½•å¤±è´¥: {}", e));
        }
    }
    
    // è®¾ç½®å½•éŸ³çŠ¶æ€
    {
        let mut is_recording = state.is_recording.lock();
        *is_recording = true;
    }
    
    // å¯åŠ¨äº‹ä»¶å¤„ç†ä»»åŠ¡
    let app_handle = app.clone();
    let target_bundle_clone = target_bundle_id.clone();
    let is_recording_state = Arc::clone(&state.is_recording);
    
    tokio::spawn(async move {
        let mut accumulated_text = String::new();
        let mut last_streaming_text = String::new();
        
        while let Ok(event) = event_receiver.recv().await {
            use crate::audio::streaming_transcriptor::TranscriptionEvent;
            
            match event {
                TranscriptionEvent::StreamingTranscription { text, is_partial, confidence, .. } => {
                    // å‘é€å®æ—¶è½¬å½•äº‹ä»¶åˆ°å‰ç«¯
                    if let Err(e) = app_handle.emit_all("streaming_transcription", serde_json::json!({
                        "text": text,
                        "is_partial": is_partial,
                        "confidence": confidence
                    })) {
                        eprintln!("å‘é€æµå¼è½¬å½•äº‹ä»¶å¤±è´¥: {}", e);
                    }
                    
                    println!("ğŸ“ æµå¼è½¬å½•: '{}' (éƒ¨åˆ†={}, ç½®ä¿¡åº¦={:.2})", text, is_partial, confidence);
                    last_streaming_text = text;
                }
                
                TranscriptionEvent::FinalText { text, .. } => {
                    accumulated_text.push_str(&text);
                    accumulated_text.push(' ');
                    
                    // å‘é€æœ€ç»ˆè½¬å½•äº‹ä»¶
                    if let Err(e) = app_handle.emit_all("final_transcription", &text) {
                        eprintln!("å‘é€æœ€ç»ˆè½¬å½•äº‹ä»¶å¤±è´¥: {}", e);
                    }
                    
                    println!("âœ… æœ€ç»ˆè½¬å½•: '{}'", text);
                }
                
                TranscriptionEvent::StreamingComplete { full_text, .. } => {
                    // æµå¼è½¬å½•å®Œæˆ
                    println!("ğŸ æµå¼è½¬å½•å®Œæˆ: '{}'", full_text);
                    
                    if let Err(e) = app_handle.emit_all("streaming_complete", &full_text) {
                        eprintln!("å‘é€æµå¼å®Œæˆäº‹ä»¶å¤±è´¥: {}", e);
                    }
                    
                    break;
                }
                
                TranscriptionEvent::TranscriptionError { error, .. } => {
                    eprintln!("è½¬å½•é”™è¯¯: {}", error);
                    if let Err(e) = app_handle.emit_all("transcription_error", &error) {
                        eprintln!("å‘é€é”™è¯¯äº‹ä»¶å¤±è´¥: {}", e);
                    }
                }
                
                _ => {} // å¤„ç†å…¶ä»–äº‹ä»¶ç±»å‹
            }
        }
        
        // æ¸…ç†å½•éŸ³çŠ¶æ€
        {
            let mut state_recording = is_recording_state.lock();
            *state_recording = false;
        }
        
        println!("ğŸ”š æµå¼è¯­éŸ³è¾“å…¥äº‹ä»¶å¤„ç†å®Œæˆ");
    });
    
    Ok("æµå¼è¯­éŸ³è¾“å…¥å·²å¯åŠ¨ - Day 3-4 å®ç°å®Œæˆ".to_string())
}

/// å¼€å§‹æ¸è¿›å¼è¯­éŸ³è¾“å…¥ï¼ˆWeek 2 æ ¸å¿ƒåŠŸèƒ½ï¼‰
#[command]
pub async fn start_progressive_voice_input(
    target_bundle_id: Option<String>,
    app: tauri::AppHandle,
    enable_real_time_injection: Option<bool>,
) -> Result<String, String> {
    use crate::AppState;
    use crate::audio::streaming_transcriptor::{StreamingVoiceTranscriptor, StreamingConfig, AudioChunk};
    use tauri::Manager;
    use std::sync::Arc;
    use tokio::sync::mpsc;
    
    let state = app.state::<AppState>();
    
    // å¦‚æœæœªåœ¨å½•éŸ³ï¼Œåˆ™å¯åŠ¨å½•éŸ³å™¨
    {
        let is_recording = state.is_recording.lock();
        if !*is_recording {
            drop(is_recording);
            let mut recorder = state.audio_recorder.lock();
            recorder.reset_silence_detection();
            recorder.start_recording().map_err(|e| format!("å¯åŠ¨å½•éŸ³å¤±è´¥: {}", e))?;
            // æ ‡è®°å½•éŸ³çŠ¶æ€
            let mut rec_flag = state.is_recording.lock();
            *rec_flag = true;
        }
    }
    
    println!("ğŸš€ å¯åŠ¨æ¸è¿›å¼è¯­éŸ³è¾“å…¥ï¼Œç›®æ ‡åº”ç”¨: {:?}", target_bundle_id);
    
    // è·å–ç›®æ ‡åº”ç”¨ä¿¡æ¯
    let target_app = if let Some(bundle_id) = &target_bundle_id {
        match get_active_app_info_for_voice().await {
            Ok(app_info) => {
                if app_info.bundle_id.as_ref().map(|b| b.contains(bundle_id)).unwrap_or(false) {
                    Some(crate::system::ApplicationInfo {
                        name: app_info.name,
                        bundle_id: app_info.bundle_id.unwrap_or_else(|| bundle_id.clone()),
                        process_id: 0,
                    })
                } else {
                    None
                }
            }
            Err(_) => None,
        }
    } else {
        None
    };
    
    // åˆ›å»ºæµå¼è½¬å½•é…ç½®
    let streaming_config = StreamingConfig {
        chunk_duration_ms: 100,      // æ›´å¿«å“åº”ç”¨äºæ¸è¿›å¼æ³¨å…¥
        overlap_duration_ms: 50,     // å‡å°‘é‡å æé«˜æ€§èƒ½
        min_confidence: 0.65,        // é€‚ä¸­çš„ç½®ä¿¡åº¦é˜ˆå€¼
        silence_timeout_ms: 2500,    // ç¨çŸ­çš„é™éŸ³è¶…æ—¶
        max_partial_length: 150,     // é€‚ä¸­çš„éƒ¨åˆ†æ–‡æœ¬é•¿åº¦
    };
    
    // åˆ›å»ºæ¸è¿›å¼æ³¨å…¥é…ç½®
    let progressive_config = ProgressiveInjectionConfig {
        enabled: true,
        min_inject_length: 1,        // æ›´æ•æ„Ÿçš„æœ€å°é•¿åº¦
        inject_interval_ms: 150,     // æ›´é¢‘ç¹çš„æ³¨å…¥é—´éš”
        max_queue_length: 30,
        enable_backspace_correction: true,
        min_confidence_threshold: 0.6,
        final_only: !enable_real_time_injection.unwrap_or(true), // é»˜è®¤å¯ç”¨å®æ—¶æ³¨å…¥
        smart_prefix_merging: true,
    };
    
    let injection_config = TextInjectionConfig {
        auto_inject_enabled: true,
        inject_delay: std::time::Duration::from_millis(50),
        use_keyboard_simulation: false,
        preserve_clipboard: true,
        duplicate_detection: true,
        shortcut_delay: std::time::Duration::from_millis(25),
        target_app_filter: target_bundle_id.map(|id| vec![id]).unwrap_or_default(),
    };
    
    // åˆ›å»ºæµå¼è½¬å½•å™¨
    let transcription_service = state.transcription_service.clone();
    let (mut transcriptor, mut event_receiver) = StreamingVoiceTranscriptor::new(
        streaming_config,
        transcription_service,
    );
    
    // è¿æ¥çœŸå®éŸ³é¢‘ï¼šä» AudioRecorder æµç›‘å¬ï¼Œå‘é€åˆ° transcriptor çš„éŸ³é¢‘é€šé“
    let (audio_tx, audio_rx) = mpsc::unbounded_channel::<AudioChunk>();
    {
        let recorder = state.audio_recorder.clone();
        tokio::spawn(async move {
            // ä½¿ç”¨ crossbeam é€šé“ä»å½•éŸ³å™¨è·å–æ ·æœ¬å—
            let rx = recorder.lock().add_stream_listener();
            let mut chunk_id: u64 = 0;
            loop {
                match rx.recv() {
                    Ok(samples) => {
                        // è·å–é‡‡æ ·ç‡
                        let sr = recorder.lock().get_sample_rate();
                        chunk_id += 1;
                        let _ = audio_tx.send(AudioChunk {
                            data: samples,
                            sample_rate: sr,
                            timestamp: std::time::Instant::now(),
                            chunk_id,
                        });
                    }
                    Err(_) => {
                        break;
                    }
                }
            }
        });
    }
    
    // å¯åŠ¨æµå¼è½¬å½•ï¼ˆä½¿ç”¨çœŸå®éŸ³é¢‘é€šé“ï¼‰
    match transcriptor.start_streaming(audio_rx).await {
        Ok(_) => {
            println!("âœ… æµå¼è½¬å½•å™¨å¯åŠ¨æˆåŠŸï¼ˆå·²æ¥å…¥å½•éŸ³æ•°æ®ï¼‰");
        }
        Err(e) => {
            return Err(format!("å¯åŠ¨æµå¼è½¬å½•å¤±è´¥: {}", e));
        }
    }
    
    // åˆ›å»ºæ¸è¿›å¼æ–‡æœ¬æ³¨å…¥å™¨
    let mut progressive_injector = ProgressiveTextInjector::new(
        progressive_config,
        injection_config,
    );
    
    // å¯åŠ¨æ¸è¿›å¼æ³¨å…¥ç›‘å¬
    match progressive_injector.start_listening(event_receiver, target_app.clone()).await {
        Ok(_) => {
            println!("âœ… æ¸è¿›å¼æ³¨å…¥ç›‘å¬å¯åŠ¨æˆåŠŸ");
        }
        Err(e) => {
            return Err(format!("å¯åŠ¨æ¸è¿›å¼æ³¨å…¥å¤±è´¥: {}", e));
        }
    }
    
    // è®¾ç½®å½•éŸ³çŠ¶æ€
    {
        let mut is_recording = state.is_recording.lock();
        *is_recording = true;
    }
    
    // å¯åŠ¨çŠ¶æ€ç›‘æ§ä»»åŠ¡ï¼šå½“è½¬å½•ä¸æ³¨å…¥å‡ç»“æŸæ—¶ï¼Œåœæ­¢å½•éŸ³
    let app_handle = app.clone();
    let is_recording_state = Arc::clone(&state.is_recording);
    tokio::spawn(async move {
        let mut check_interval = tokio::time::interval(std::time::Duration::from_millis(500));
        loop {
            check_interval.tick().await;
            let transcriptor_active = transcriptor.is_running();
            let injector_active = progressive_injector.is_active();
            if !transcriptor_active && !injector_active {
                // åœæ­¢å½•éŸ³å™¨
                {
                    let mut recorder = app_handle.state::<AppState>().audio_recorder.lock();
                    let _ = recorder.stop_recording();
                }
                // æ¸…ç†å½•éŸ³çŠ¶æ€
                let mut state_recording = is_recording_state.lock();
                *state_recording = false;
                // å‘é€å®Œæˆäº‹ä»¶
                if let Err(e) = app_handle.emit_all("progressive_voice_input_complete", serde_json::json!({
                    "message": "æ¸è¿›å¼è¯­éŸ³è¾“å…¥å·²å®Œæˆ",
                    "injected_text": progressive_injector.get_last_injected_text(),
                    "queue_length": progressive_injector.queue_length(),
                })) {
                    eprintln!("å‘é€å®Œæˆäº‹ä»¶å¤±è´¥: {}", e);
                }
                break;
            }
            // çŠ¶æ€æ›´æ–°
            if let Err(e) = app_handle.emit_all("progressive_voice_input_status", serde_json::json!({
                "transcriptor_active": transcriptor_active,
                "injector_active": injector_active,
                "queue_length": progressive_injector.queue_length(),
                "last_injected": progressive_injector.get_last_injected_text(),
            })) {
                eprintln!("å‘é€çŠ¶æ€äº‹ä»¶å¤±è´¥: {}", e);
            }
        }
        println!("ğŸ”š æ¸è¿›å¼è¯­éŸ³è¾“å…¥ç›‘æ§ä»»åŠ¡å®Œæˆ");
    });
    
    Ok("æ¸è¿›å¼è¯­éŸ³è¾“å…¥å·²å¯åŠ¨ - å·²æ¥å…¥çœŸå®å½•éŸ³æ•°æ® ğŸš€".to_string())
}