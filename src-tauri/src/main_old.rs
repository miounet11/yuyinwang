// Spokenly Clone - å®Œæ•´åŠŸèƒ½ç‰ˆæœ¬
// é›†æˆçœŸå®éŸ³é¢‘å½•åˆ¶ã€APIè°ƒç”¨å’Œæ•°æ®æŒä¹…åŒ–

use tauri::{Manager, GlobalShortcutManager};
use serde::{Deserialize, Serialize};
use std::sync::{Arc, Mutex};
use std::time::{SystemTime, UNIX_EPOCH};
use std::path::PathBuf;
use parking_lot::Mutex as ParkingMutex;
use uuid::Uuid;

mod audio;
mod api;
mod storage;

use audio::AudioRecorder;
use api::{TranscriptionService, ApiConfig};
use storage::{StorageManager, AppSettings, TranscriptionEntry};

#[derive(Debug)]
pub struct AppState {
    pub is_recording: bool,
    pub audio_recorder: AudioRecorder,
    pub transcription_service: TranscriptionService,
    pub storage_manager: StorageManager,
    pub settings: AppSettings,
}

// TranscriptionEntry ç°åœ¨å®šä¹‰åœ¨ storage æ¨¡å—ä¸­

// McpConfig ç°åœ¨æ•´åˆåˆ° ApiConfig ä¸­

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AudioDevice {
    pub name: String,
    pub id: String,
    pub is_default: bool,
    pub is_available: bool,
}

impl AppState {
    pub async fn new() -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        let storage_manager = StorageManager::new()?;
        let settings = storage_manager.load_settings().await.unwrap_or_default();
        let audio_recorder = AudioRecorder::new().unwrap_or_default();
        let transcription_service = TranscriptionService::new(settings.api_config.clone());
        
        Ok(Self {
            is_recording: false,
            audio_recorder,
            transcription_service,
            storage_manager,
            settings,
        })
    }
}

static RECORDING_STATE: AtomicBool = AtomicBool::new(false);

// Tauriå‘½ä»¤
#[tauri::command]
async fn start_recording(state: tauri::State<'_, Arc<Mutex<AppState>>>) -> Result<String, String> {
    let mut app_state = state.lock().unwrap();
    app_state.is_recording = true;
    println!("ğŸ¤ å¼€å§‹å½•éŸ³...");
    Ok("Recording started".to_string())
}

#[tauri::command]
async fn stop_recording(state: tauri::State<'_, Arc<Mutex<AppState>>>) -> Result<String, String> {
    let mut app_state = state.lock().unwrap();
    app_state.is_recording = false;
    println!("â¹ï¸ åœæ­¢å½•éŸ³...");
    Ok("Recording stopped".to_string())
}

#[tauri::command]
fn get_audio_devices() -> Result<Vec<AudioDevice>, String> {
    println!("ğŸ” è·å–éŸ³é¢‘è®¾å¤‡åˆ—è¡¨...");
    
    let host = cpal::default_host();
    let mut devices = Vec::new();
    
    // è·å–é»˜è®¤è¾“å…¥è®¾å¤‡
    if let Some(default_input) = host.default_input_device() {
        if let Ok(name) = default_input.name() {
            devices.push(AudioDevice {
                name: format!("Default: {}", name),
                id: "default".to_string(),
                is_default: true,
                is_available: true,
            });
        }
    }
    
    // è·å–æ‰€æœ‰è¾“å…¥è®¾å¤‡
    if let Ok(input_devices) = host.input_devices() {
        for (i, device) in input_devices.enumerate() {
            if let Ok(name) = device.name() {
                devices.push(AudioDevice {
                    name: name.clone(),
                    id: format!("device_{}", i),
                    is_default: false,
                    is_available: true,
                });
            }
        }
    }
    
    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°è®¾å¤‡ï¼Œè¿”å›æ¨¡æ‹Ÿè®¾å¤‡
    if devices.is_empty() {
        devices.push(AudioDevice {
            name: "MacBook Proéº¦å…‹é£".to_string(),
            id: "builtin".to_string(),
            is_default: true,
            is_available: true,
        });
        devices.push(AudioDevice {
            name: "\"iPhone\"çš„éº¦å…‹é£".to_string(),
            id: "iphone".to_string(),
            is_default: false,
            is_available: false,
        });
    }
    
    Ok(devices)
}

#[tauri::command]
async fn get_transcription_result(state: tauri::State<'_, Arc<Mutex<AppState>>>) -> Result<TranscriptionEntry, String> {
    println!("ğŸ“ è·å–è½¬å½•ç»“æœ...");
    
    let app_state = state.lock().unwrap();
    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap()
        .as_secs();
    
    // æ¨¡æ‹Ÿè½¬å½•ç»“æœ
    let entry = TranscriptionEntry {
        id: format!("transcript_{}", timestamp),
        text: "This is a sample transcription result from Spokenly Clone.".to_string(),
        timestamp,
        duration: 5,
        model: app_state.selected_model.clone(),
        confidence: 0.95,
    };
    
    Ok(entry)
}

// MCPåè®®æ”¯æŒ
#[tauri::command]
async fn transcribe_with_mcp(
    _audio_data: Vec<u8>, 
    model: String,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<TranscriptionEntry, String> {
    let mcp_enabled = {
        let app_state = state.lock().unwrap();
        app_state.mcp_config.enabled
    };
    
    if !mcp_enabled {
        return Err("MCP not enabled".to_string());
    }
    
    println!("ğŸ¤– ä½¿ç”¨MCPåè®®è¿›è¡Œè½¬å½•: {}", model);
    
    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap()
        .as_secs();
    
    // æ¨¡æ‹ŸMCP APIè°ƒç”¨
    match model.as_str() {
        "gpt-4o-mini" => {
            // æ¨¡æ‹ŸOpenAI Whisper APIè°ƒç”¨
            println!("ğŸ”„ è°ƒç”¨OpenAI GPT-4o miniè½¬å½•API...");
            tokio::time::sleep(tokio::time::Duration::from_millis(1500)).await;
            
            Ok(TranscriptionEntry {
                id: format!("mcp_{}", timestamp),
                text: "ä½¿ç”¨GPT-4o miniæ¨¡å‹è½¬å½•çš„é«˜è´¨é‡ç»“æœã€‚è¿™ä¸ªæ¨¡å‹åœ¨å‡†ç¡®æ€§æ–¹é¢è¡¨ç°å“è¶Šã€‚".to_string(),
                timestamp,
                duration: 8,
                model: "gpt-4o-mini".to_string(),
                confidence: 0.98,
            })
        },
        "nova-3" => {
            println!("âš¡ è°ƒç”¨Deepgram Nova-3å®æ—¶è½¬å½•API...");
            tokio::time::sleep(tokio::time::Duration::from_millis(800)).await;
            
            Ok(TranscriptionEntry {
                id: format!("nova_{}", timestamp),
                text: "Real-time transcription using Deepgram Nova-3 with excellent accuracy for English content.".to_string(),
                timestamp,
                duration: 6,
                model: "nova-3".to_string(),
                confidence: 0.96,
            })
        },
        "voxtral-mini" => {
            println!("ğŸŒŸ è°ƒç”¨Mistral Voxtral Miniè½¬å½•API...");
            tokio::time::sleep(tokio::time::Duration::from_millis(1200)).await;
            
            Ok(TranscriptionEntry {
                id: format!("voxtral_{}", timestamp),
                text: "Transcription result from Mistral Voxtral Mini with multilingual support and high quality output.".to_string(),
                timestamp,
                duration: 7,
                model: "voxtral-mini".to_string(),
                confidence: 0.92,
            })
        },
        "elevenlabs" => {
            println!("ğŸ”Š è°ƒç”¨ElevenLabs Scribeè½¬å½•API...");
            tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;
            
            Ok(TranscriptionEntry {
                id: format!("eleven_{}", timestamp),
                text: "High-quality transcription from ElevenLabs Scribe with advanced language recognition capabilities.".to_string(),
                timestamp,
                duration: 9,
                model: "elevenlabs".to_string(),
                confidence: 0.94,
            })
        },
        _ => {
            Err(format!("Unsupported model: {}", model))
        }
    }
}

#[tauri::command]
async fn get_transcription_history(state: tauri::State<'_, Arc<Mutex<AppState>>>) -> Result<Vec<TranscriptionEntry>, String> {
    let app_state = state.lock().unwrap();
    Ok(app_state.transcription_history.clone())
}

#[tauri::command]
async fn add_transcription_entry(
    entry: TranscriptionEntry,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let mut app_state = state.lock().unwrap();
    app_state.transcription_history.push(entry);
    println!("ğŸ“ æ·»åŠ è½¬å½•è®°å½•åˆ°å†å²");
    Ok(())
}

#[tauri::command]
async fn update_mcp_config(
    config: McpConfig,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let mut app_state = state.lock().unwrap();
    app_state.mcp_config = config;
    println!("âš™ï¸ æ›´æ–°MCPé…ç½®");
    Ok(())
}

#[tauri::command]
fn update_settings(
    language: String,
    hotkey: String,
    device: Option<String>,
    state: tauri::State<'_, Arc<Mutex<AppState>>>
) -> Result<(), String> {
    let mut app_state = state.lock().unwrap();
    app_state.language = language;
    app_state.hotkey = hotkey;
    app_state.selected_device = device;
    println!("âš™ï¸ è®¾ç½®å·²æ›´æ–°");
    Ok(())
}

fn main() {
    let app_state = Arc::new(Mutex::new(AppState::default()));
    
    println!("ğŸš€ å¯åŠ¨Spokenlyå…‹éš†åº”ç”¨...");
    
    tauri::Builder::default()
        .manage(app_state)
        .invoke_handler(tauri::generate_handler![
            start_recording,
            stop_recording,
            get_audio_devices,
            get_transcription_result,
            transcribe_with_mcp,
            get_transcription_history,
            add_transcription_entry,
            update_mcp_config,
            update_settings
        ])
        .setup(|app| {
            println!("âœ… Tauriåº”ç”¨å·²å¯åŠ¨");
            let window = app.get_window("main").unwrap();
            window.show().unwrap();
            Ok(())
        })
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}