// æµå¼è¯­éŸ³è½¬å½•å™¨ - Recording King v5.8+ æ ¸å¿ƒæ¨¡å—
// å®ç°å¦‚è¾“å…¥æ³•èˆ¬çš„å®æ—¶è½¬å½•ä½“éªŒ

use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, broadcast};
use serde::{Serialize, Deserialize};
use crate::transcription::TranscriptionService;
use crate::errors::{AppResult, AppError};

/// è½¬å½•äº‹ä»¶ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum TranscriptionEvent {
    /// æµå¼è½¬å½•ç»“æœ (å®æ—¶æ˜¾ç¤ºï¼Œå¦‚è¾“å…¥æ³•)
    StreamingTranscription { 
        text: String, 
        is_partial: bool,
        confidence: f64,
        timestamp: u64,
    },
    /// éƒ¨åˆ†è½¬å½•ç»“æœ (å®æ—¶æ˜¾ç¤º)
    PartialText { 
        text: String, 
        confidence: f64,
        timestamp: u64,
    },
    /// æœ€ç»ˆè½¬å½•ç»“æœ (å®Œæˆçš„å¥å­)
    FinalText { 
        text: String, 
        duration: Duration,
        timestamp: u64,
    },
    /// æµå¼è½¬å½•å®Œæˆ
    StreamingComplete { 
        full_text: String,
        total_duration: Duration,
    },
    /// è½¬å½•é”™è¯¯
    TranscriptionError { 
        error: String,
        timestamp: u64,
    },
    /// å½•éŸ³çŠ¶æ€å˜åŒ–
    RecordingStatusChanged { 
        is_recording: bool,
        timestamp: u64,
    },
}

/// æµå¼éŸ³é¢‘é…ç½®
#[derive(Debug, Clone)]
pub struct StreamingConfig {
    pub chunk_duration_ms: u64,    // éŸ³é¢‘å—æŒç»­æ—¶é—´ (é»˜è®¤100ms)
    pub overlap_duration_ms: u64,  // é‡å æ—¶é—´é¿å…ä¸¢å¤±è¾¹ç•Œè¯ (é»˜è®¤50ms)
    pub min_confidence: f64,        // æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤0.7)
    pub silence_timeout_ms: u64,   // é™éŸ³è¶…æ—¶ (é»˜è®¤2000ms)
    pub max_partial_length: usize,  // æœ€å¤§éƒ¨åˆ†è½¬å½•é•¿åº¦ (é»˜è®¤100å­—ç¬¦)
}

impl Default for StreamingConfig {
    fn default() -> Self {
        Self {
            chunk_duration_ms: 100,
            overlap_duration_ms: 50,
            min_confidence: 0.7,
            silence_timeout_ms: 2000,
            max_partial_length: 100,
        }
    }
}

/// éŸ³é¢‘å—æ•°æ®
#[derive(Debug, Clone)]
pub struct AudioChunk {
    pub data: Vec<f32>,
    pub sample_rate: u32,
    pub timestamp: Instant,
    pub chunk_id: u64,
}

/// æµå¼è¯­éŸ³è½¬å½•å™¨
pub struct StreamingVoiceTranscriptor {
    config: StreamingConfig,
    transcription_service: Arc<TranscriptionService>,
    event_sender: broadcast::Sender<TranscriptionEvent>,
    audio_receiver: Option<mpsc::UnboundedReceiver<AudioChunk>>,
    is_active: Arc<Mutex<bool>>,
    current_chunk_id: Arc<Mutex<u64>>,
    partial_text_buffer: Arc<Mutex<String>>,
    last_activity: Arc<Mutex<Instant>>,
}

impl StreamingVoiceTranscriptor {
    /// åˆ›å»ºæ–°çš„æµå¼è½¬å½•å™¨
    pub fn new(
        config: StreamingConfig,
        transcription_service: Arc<TranscriptionService>,
    ) -> (Self, broadcast::Receiver<TranscriptionEvent>) {
        let (event_sender, event_receiver) = broadcast::channel(1000);
        
        let transcriptor = Self {
            config,
            transcription_service,
            event_sender,
            audio_receiver: None,
            is_active: Arc::new(Mutex::new(false)),
            current_chunk_id: Arc::new(Mutex::new(0)),
            partial_text_buffer: Arc::new(Mutex::new(String::new())),
            last_activity: Arc::new(Mutex::new(Instant::now())),
        };
        
        (transcriptor, event_receiver)
    }
    
    /// å¯åŠ¨æµå¼è½¬å½•
    pub async fn start_streaming(
        &mut self,
        mut audio_receiver: mpsc::UnboundedReceiver<AudioChunk>,
    ) -> AppResult<()> {
        {
            let mut is_active = self.is_active.lock().unwrap();
            if *is_active {
                return Err(AppError::StreamingError("æµå¼è½¬å½•å·²åœ¨è¿è¡Œä¸­".to_string()));
            }
            *is_active = true;
        }
        
        // å‘é€å½•éŸ³çŠ¶æ€å˜åŒ–äº‹ä»¶
        let _ = self.event_sender.send(TranscriptionEvent::RecordingStatusChanged {
            is_recording: true,
            timestamp: chrono::Utc::now().timestamp_millis() as u64,
        });
        
        println!("ğŸ™ï¸ æµå¼è¯­éŸ³è½¬å½•å¯åŠ¨");
        
        // å¯åŠ¨ä¸»å¤„ç†å¾ªç¯
        let event_sender = self.event_sender.clone();
        let transcription_service = self.transcription_service.clone();
        let config = self.config.clone();
        let is_active = self.is_active.clone();
        let current_chunk_id = self.current_chunk_id.clone();
        let partial_text_buffer = self.partial_text_buffer.clone();
        let last_activity = self.last_activity.clone();
        
        tokio::spawn(async move {
            Self::processing_loop(
                audio_receiver,
                event_sender,
                transcription_service,
                config,
                is_active,
                current_chunk_id,
                partial_text_buffer,
                last_activity,
            ).await;
        });
        
        Ok(())
    }
    
    /// åœæ­¢æµå¼è½¬å½•
    pub async fn stop_streaming(&mut self) -> AppResult<String> {
        {
            let mut is_active = self.is_active.lock().unwrap();
            if !*is_active {
                return Ok("æµå¼è½¬å½•æœªåœ¨è¿è¡Œ".to_string());
            }
            *is_active = false;
        }
        
        // è·å–æœ€ç»ˆçš„å®Œæ•´æ–‡æœ¬
        let final_text = {
            let buffer = self.partial_text_buffer.lock().unwrap();
            buffer.clone()
        };
        
        // å‘é€æµå¼å®Œæˆäº‹ä»¶
        let _ = self.event_sender.send(TranscriptionEvent::StreamingComplete {
            full_text: final_text.clone(),
            total_duration: Duration::from_secs(0), // TODO: è®¡ç®—å®é™…æŒç»­æ—¶é—´
        });
        
        // å‘é€å½•éŸ³çŠ¶æ€å˜åŒ–äº‹ä»¶
        let _ = self.event_sender.send(TranscriptionEvent::RecordingStatusChanged {
            is_recording: false,
            timestamp: chrono::Utc::now().timestamp_millis() as u64,
        });
        
        println!("ğŸ›‘ æµå¼è¯­éŸ³è½¬å½•åœæ­¢");
        Ok(final_text)
    }
    
    /// ä¸»è¦å¤„ç†å¾ªç¯
    async fn processing_loop(
        mut audio_receiver: mpsc::UnboundedReceiver<AudioChunk>,
        event_sender: broadcast::Sender<TranscriptionEvent>,
        transcription_service: Arc<TranscriptionService>,
        config: StreamingConfig,
        is_active: Arc<Mutex<bool>>,
        current_chunk_id: Arc<Mutex<u64>>,
        partial_text_buffer: Arc<Mutex<String>>,
        last_activity: Arc<Mutex<Instant>>,
    ) {
        let mut accumulated_audio = Vec::new();
        let mut last_transcription_time = Instant::now();
        
        while let Some(chunk) = audio_receiver.recv().await {
            // æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­å¤„ç†
            {
                let is_active = is_active.lock().unwrap();
                if !*is_active {
                    break;
                }
            }
            
            // æ›´æ–°æ´»åŠ¨æ—¶é—´
            {
                let mut last_activity = last_activity.lock().unwrap();
                *last_activity = Instant::now();
            }
            
            // ç´¯ç§¯éŸ³é¢‘æ•°æ®
            accumulated_audio.extend_from_slice(&chunk.data);
            
            // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è½¬å½•é—´éš”
            if last_transcription_time.elapsed() >= Duration::from_millis(config.chunk_duration_ms) {
                // å¤„ç†ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®
                if !accumulated_audio.is_empty() {
                    Self::process_audio_chunk(
                        &accumulated_audio,
                        chunk.sample_rate,
                        &event_sender,
                        &transcription_service,
                        &config,
                        &current_chunk_id,
                        &partial_text_buffer,
                    ).await;
                    
                    // ä¿ç•™é‡å éƒ¨åˆ†é¿å…ä¸¢å¤±è¾¹ç•Œè¯
                    let overlap_samples = (chunk.sample_rate as u64 * config.overlap_duration_ms / 1000) as usize;
                    if accumulated_audio.len() > overlap_samples {
                        accumulated_audio.drain(..accumulated_audio.len() - overlap_samples);
                    } else {
                        accumulated_audio.clear();
                    }
                }
                
                last_transcription_time = Instant::now();
            }
            
            // æ£€æŸ¥é™éŸ³è¶…æ—¶
            let should_timeout = {
                let last_activity = last_activity.lock().unwrap();
                last_activity.elapsed() > Duration::from_millis(config.silence_timeout_ms)
            };
            
            if should_timeout {
                println!("ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³è¶…æ—¶ï¼Œåœæ­¢æµå¼è½¬å½•");
                break;
            }
        }
        
        // å¤„ç†å‰©ä½™çš„éŸ³é¢‘æ•°æ®
        if !accumulated_audio.is_empty() {
            Self::process_audio_chunk(
                &accumulated_audio,
                16000, // é»˜è®¤é‡‡æ ·ç‡
                &event_sender,
                &transcription_service,
                &config,
                &current_chunk_id,
                &partial_text_buffer,
            ).await;
        }
        
        println!("ğŸ”š æµå¼è½¬å½•å¤„ç†å¾ªç¯ç»“æŸ");
    }
    
    /// å¤„ç†éŸ³é¢‘å—
    async fn process_audio_chunk(
        audio_data: &[f32],
        sample_rate: u32,
        event_sender: &broadcast::Sender<TranscriptionEvent>,
        transcription_service: &Arc<TranscriptionService>,
        config: &StreamingConfig,
        current_chunk_id: &Arc<Mutex<u64>>,
        partial_text_buffer: &Arc<Mutex<String>>,
    ) {
        // ç”Ÿæˆchunk ID
        let chunk_id = {
            let mut id = current_chunk_id.lock().unwrap();
            *id += 1;
            *id
        };
        
        println!("ğŸ”„ å¤„ç†éŸ³é¢‘å— #{}, æ ·æœ¬æ•°: {}", chunk_id, audio_data.len());
        
        // åˆ›å»ºè½¬å½•é…ç½® - ä½¿ç”¨å¿«é€Ÿæ¨¡å‹å®ç°å®æ—¶å“åº”
        let transcription_config = crate::types::TranscriptionConfig {
            model_name: "whisper-tiny".to_string(), // ä½¿ç”¨æœ€å¿«çš„æ¨¡å‹
            language: Some("zh".to_string()),
            temperature: Some(0.0),
            is_local: true,
            api_endpoint: None,
        };
        
        // å®é™…è½¬å½•éŸ³é¢‘å—
        match transcription_service.transcribe_audio_chunk(audio_data, sample_rate, &transcription_config).await {
            Ok(result) => {
                let confidence = result.confidence.unwrap_or(0.8);
                let text = result.text.trim().to_string();
                
                // è¿‡æ»¤ç©ºæˆ–æ— æ„ä¹‰çš„è½¬å½•ç»“æœ
                if text.is_empty() || text.len() < 2 {
                    println!("â­ï¸ è·³è¿‡ç©ºè½¬å½•ç»“æœ");
                    return;
                }
                
                println!("ğŸ“ è½¬å½•ç»“æœ: '{}' (ç½®ä¿¡åº¦: {:.2})", text, confidence);
                
                if confidence >= config.min_confidence {
                    // å‘é€æµå¼è½¬å½•äº‹ä»¶ - è¿™æ˜¯å®æ—¶æ˜¾ç¤ºçš„æ–‡æœ¬
                    let _ = event_sender.send(TranscriptionEvent::StreamingTranscription {
                        text: text.clone(),
                        is_partial: confidence < 0.9, // ç½®ä¿¡åº¦ä½äº0.9è®¤ä¸ºæ˜¯éƒ¨åˆ†ç»“æœ
                        confidence,
                        timestamp: chrono::Utc::now().timestamp_millis() as u64,
                    });
                    
                    // æ›´æ–°éƒ¨åˆ†æ–‡æœ¬ç¼“å†²åŒº
                    {
                        let mut buffer = partial_text_buffer.lock().unwrap();
                        if !buffer.is_empty() {
                            buffer.push(' ');
                        }
                        buffer.push_str(&text);
                        
                        // é™åˆ¶ç¼“å†²åŒºé•¿åº¦
                        if buffer.len() > config.max_partial_length {
                            let chars: Vec<char> = buffer.chars().collect();
                            let start_pos = chars.len().saturating_sub(config.max_partial_length);
                            *buffer = chars[start_pos..].iter().collect();
                        }
                    }
                    
                    // å¦‚æœç½®ä¿¡åº¦å¾ˆé«˜ï¼Œä¹Ÿå‘é€ä½œä¸ºæœ€ç»ˆè½¬å½•
                    if confidence >= 0.85 {
                        let _ = event_sender.send(TranscriptionEvent::FinalText {
                            text,
                            duration: std::time::Duration::from_millis(100), // ä¼°è®¡å¤„ç†æ—¶é—´
                            timestamp: chrono::Utc::now().timestamp_millis() as u64,
                        });
                    }
                } else {
                    println!("âš ï¸ è½¬å½•ç½®ä¿¡åº¦è¿‡ä½ ({:.2}), è·³è¿‡", confidence);
                }
            }
            Err(e) => {
                eprintln!("âŒ è½¬å½•éŸ³é¢‘å—å¤±è´¥: {}", e);
                let _ = event_sender.send(TranscriptionEvent::TranscriptionError {
                    error: e.to_string(),
                    timestamp: chrono::Utc::now().timestamp_millis() as u64,
                });
            }
        }
    }
    
    /// æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
    pub fn is_running(&self) -> bool {
        *self.is_active.lock().unwrap()
    }
    
    /// è·å–å½“å‰éƒ¨åˆ†æ–‡æœ¬
    pub fn get_current_partial_text(&self) -> String {
        self.partial_text_buffer.lock().unwrap().clone()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::sync::mpsc;
    
    #[tokio::test]
    async fn test_streaming_transcriptor_creation() {
        let config = StreamingConfig::default();
        let transcription_service = Arc::new(
            TranscriptionService::new(reqwest::Client::new(), None)
        );
        
        let (transcriptor, mut receiver) = StreamingVoiceTranscriptor::new(
            config,
            transcription_service,
        );
        
        assert!(!transcriptor.is_running());
        assert_eq!(transcriptor.get_current_partial_text(), "");
    }
    
    #[tokio::test]
    async fn test_audio_chunk_processing() {
        let config = StreamingConfig::default();
        let transcription_service = Arc::new(
            TranscriptionService::new(reqwest::Client::new(), None)
        );
        
        let (mut transcriptor, mut receiver) = StreamingVoiceTranscriptor::new(
            config,
            transcription_service,
        );
        
        let (audio_sender, audio_receiver) = mpsc::unbounded_channel();
        
        // å‘é€æµ‹è¯•éŸ³é¢‘å—
        let test_chunk = AudioChunk {
            data: vec![0.1; 1600], // 100msçš„16kHzéŸ³é¢‘
            sample_rate: 16000,
            timestamp: Instant::now(),
            chunk_id: 1,
        };
        
        audio_sender.send(test_chunk).unwrap();
        
        // å¯åŠ¨è½¬å½•ä½†ä¸å®é™…å¤„ç†ï¼ˆç”±äºæˆ‘ä»¬è¿˜æ²¡æœ‰çœŸæ­£çš„è½¬å½•æœåŠ¡ï¼‰
        // è¿™é‡Œåªæ˜¯æµ‹è¯•ç»“æ„çš„æ­£ç¡®æ€§
        
        assert!(!transcriptor.is_running());
    }
}