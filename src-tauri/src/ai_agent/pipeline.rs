// AI Agent Pipeline ç®¡ç†å™¨
// å®ç°æ™ºèƒ½é“¾å¼å¤„ç†ã€å¹¶å‘æ‰§è¡Œå’Œé”™è¯¯æ¢å¤æœºåˆ¶

use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use parking_lot::Mutex;
use tokio::sync::{mpsc, Semaphore};
use uuid::Uuid;
use serde::{Deserialize, Serialize};
use crate::errors::{AppError, AppResult};
use super::processors::AIProcessor;
use super::types::{AIAgentType, AIAgentRequest};

/// Pipelineæ‰§è¡Œç­–ç•¥
#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub enum PipelineStrategy {
    /// é¡ºåºæ‰§è¡Œ
    Sequential,
    /// å¹¶è¡Œæ‰§è¡Œ
    Parallel,
    /// æ™ºèƒ½é€‰æ‹©ï¼ˆæ ¹æ®ä»»åŠ¡ç±»å‹å’Œèµ„æºæƒ…å†µè‡ªåŠ¨å†³å®šï¼‰
    Smart,
}

/// Agentä»»åŠ¡é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentTask {
    pub id: String,
    pub agent_type: String,
    pub input_text: String,
    pub config: HashMap<String, String>,
    pub dependencies: Vec<String>, // ä¾èµ–çš„å…¶ä»–ä»»åŠ¡ID
    pub priority: u8, // 0-255ï¼Œæ•°å€¼è¶Šé«˜ä¼˜å…ˆçº§è¶Šé«˜
    pub timeout_seconds: Option<u64>,
    pub retry_count: u8,
}

impl AgentTask {
    pub fn new(agent_type: &str, input_text: &str) -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            agent_type: agent_type.to_string(),
            input_text: input_text.to_string(),
            config: HashMap::new(),
            dependencies: Vec::new(),
            priority: 128, // é»˜è®¤ä¸­ç­‰ä¼˜å…ˆçº§
            timeout_seconds: Some(30),
            retry_count: 3,
        }
    }
    
    pub fn with_dependency(mut self, task_id: &str) -> Self {
        self.dependencies.push(task_id.to_string());
        self
    }
    
    pub fn with_priority(mut self, priority: u8) -> Self {
        self.priority = priority;
        self
    }
    
    pub fn with_config(mut self, key: &str, value: &str) -> Self {
        self.config.insert(key.to_string(), value.to_string());
        self
    }
}

/// Pipelineæ‰§è¡Œç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PipelineResult {
    pub pipeline_id: String,
    pub tasks: Vec<TaskResult>,
    pub execution_time: Duration,
    pub total_tokens_used: u32,
    pub success_rate: f64,
    pub errors: Vec<String>,
    pub performance_stats: PerformanceStats,
}

impl PipelineResult {
    pub fn is_successful(&self) -> bool {
        self.success_rate >= 0.8 // 80%æˆåŠŸç‡è®¤ä¸ºæ˜¯æˆåŠŸ
    }
    
    pub fn get_final_output(&self) -> Option<&str> {
        // è¿”å›æœ€åä¸€ä¸ªæˆåŠŸä»»åŠ¡çš„è¾“å‡º
        self.tasks
            .iter()
            .filter(|t| t.success)
            .last()
            .map(|t| t.output.as_str())
    }
}

/// å•ä¸ªä»»åŠ¡æ‰§è¡Œç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskResult {
    pub task_id: String,
    pub agent_type: String,
    pub success: bool,
    pub output: String,
    pub execution_time: Duration,
    pub tokens_used: u32,
    pub error: Option<String>,
    pub retry_attempts: u8,
}

/// æ€§èƒ½ç»Ÿè®¡æ•°æ®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceStats {
    pub avg_task_duration: Duration,
    pub max_concurrent_tasks: u32,
    pub memory_usage_mb: f64,
    pub api_calls_count: u32,
    pub cache_hit_rate: f64,
}

/// Pipelineæ‰§è¡Œä¸Šä¸‹æ–‡
#[derive(Debug, Clone)]
pub struct ExecutionContext {
    pub pipeline_id: String,
    pub start_time: Instant,
    pub strategy: PipelineStrategy,
    pub max_concurrent_tasks: usize,
    pub task_results: Arc<Mutex<HashMap<String, TaskResult>>>,
    pub execution_stats: Arc<Mutex<PerformanceStats>>,
}

/// AI Agent Pipelineç®¡ç†å™¨
#[derive(Debug)]
pub struct AgentPipelineManager {
    // AIå¤„ç†å™¨å®ä¾‹
    ai_processor: Arc<AIProcessor>,
    
    // æ‰§è¡Œæ§åˆ¶
    semaphore: Arc<Semaphore>,
    max_concurrent_tasks: usize,
    
    // ç¼“å­˜å’Œæ€§èƒ½ç›‘æ§
    result_cache: Arc<Mutex<HashMap<String, String>>>,
    performance_history: Arc<Mutex<Vec<PerformanceStats>>>,
    
    // é…ç½®
    default_timeout: Duration,
    enable_caching: bool,
}

impl AgentPipelineManager {
    /// åˆ›å»ºæ–°çš„Pipelineç®¡ç†å™¨
    pub async fn new(
        ai_processor: Arc<AIProcessor>,
        max_concurrent_tasks: usize,
    ) -> AppResult<Self> {
        Ok(Self {
            ai_processor,
            semaphore: Arc::new(Semaphore::new(max_concurrent_tasks)),
            max_concurrent_tasks,
            result_cache: Arc::new(Mutex::new(HashMap::new())),
            performance_history: Arc::new(Mutex::new(Vec::new())),
            default_timeout: Duration::from_secs(30),
            enable_caching: true,
        })
    }
    
    /// æ‰§è¡ŒPipeline
    pub async fn execute_pipeline(
        &self,
        tasks: Vec<AgentTask>,
        strategy: PipelineStrategy,
    ) -> AppResult<PipelineResult> {
        let pipeline_id = Uuid::new_v4().to_string();
        let start_time = Instant::now();
        
        println!("ğŸš€ å¼€å§‹æ‰§è¡ŒPipeline: {} (ç­–ç•¥: {:?})", pipeline_id, strategy);
        
        // åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        let context = ExecutionContext {
            pipeline_id: pipeline_id.clone(),
            start_time,
            strategy,
            max_concurrent_tasks: self.max_concurrent_tasks,
            task_results: Arc::new(Mutex::new(HashMap::new())),
            execution_stats: Arc::new(Mutex::new(PerformanceStats {
                avg_task_duration: Duration::from_millis(0),
                max_concurrent_tasks: 0,
                memory_usage_mb: 0.0,
                api_calls_count: 0,
                cache_hit_rate: 0.0,
            })),
        };
        
        // éªŒè¯å’Œæ’åºä»»åŠ¡
        let validated_tasks = self.validate_and_sort_tasks(tasks)?;
        
        // æ ¹æ®ç­–ç•¥æ‰§è¡Œä»»åŠ¡
        let task_results = match strategy {
            PipelineStrategy::Sequential => {
                self.execute_sequential(&context, validated_tasks).await?
            }
            PipelineStrategy::Parallel => {
                self.execute_parallel(&context, validated_tasks).await?
            }
            PipelineStrategy::Smart => {
                self.execute_smart(&context, validated_tasks).await?
            }
        };
        
        // æ„å»ºç»“æœ
        let execution_time = start_time.elapsed();
        let success_count = task_results.iter().filter(|r| r.success).count();
        let success_rate = success_count as f64 / task_results.len() as f64;
        
        let pipeline_result = PipelineResult {
            pipeline_id,
            tasks: task_results.clone(),
            execution_time,
            total_tokens_used: task_results.iter().map(|t| t.tokens_used).sum(),
            success_rate,
            errors: task_results
                .iter()
                .filter_map(|t| t.error.clone())
                .collect(),
            performance_stats: context.execution_stats.lock().clone(),
        };
        
        // æ›´æ–°æ€§èƒ½å†å²
        self.performance_history.lock().push(pipeline_result.performance_stats.clone());
        
        println!("âœ… Pipelineæ‰§è¡Œå®Œæˆ: {:.2}%æˆåŠŸç‡, è€—æ—¶: {:?}", 
                 success_rate * 100.0, execution_time);
        
        Ok(pipeline_result)
    }
    
    /// éªŒè¯å’Œæ’åºä»»åŠ¡ï¼ˆæŒ‰ä¾èµ–å…³ç³»å’Œä¼˜å…ˆçº§ï¼‰
    fn validate_and_sort_tasks(&self, tasks: Vec<AgentTask>) -> AppResult<Vec<AgentTask>> {
        // æ£€æŸ¥å¾ªç¯ä¾èµ–
        self.check_circular_dependencies(&tasks)?;
        
        // æ‹“æ‰‘æ’åºï¼ˆç¡®ä¿ä¾èµ–ä»»åŠ¡å…ˆæ‰§è¡Œï¼‰
        let mut sorted_tasks = Vec::new();
        let mut remaining_tasks: Vec<AgentTask> = tasks;
        let mut task_map: HashMap<String, AgentTask> = HashMap::new();
        
        // å»ºç«‹ä»»åŠ¡æ˜ å°„
        for task in &remaining_tasks {
            task_map.insert(task.id.clone(), task.clone());
        }
        
        while !remaining_tasks.is_empty() {
            let mut progress = false;
            let mut i = 0;
            
            while i < remaining_tasks.len() {
                let task = &remaining_tasks[i];
                
                // æ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦å·²å®Œæˆ
                let dependencies_satisfied = task.dependencies
                    .iter()
                    .all(|dep_id| {
                        sorted_tasks.iter().any(|t: &AgentTask| &t.id == dep_id)
                    });
                
                if dependencies_satisfied {
                    sorted_tasks.push(remaining_tasks.remove(i));
                    progress = true;
                } else {
                    i += 1;
                }
            }
            
            if !progress {
                return Err(AppError::ValidationError(
                    "æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–æˆ–æ— æ•ˆçš„ä¾èµ–å…³ç³»".to_string()
                ));
            }
        }
        
        // åœ¨ç›¸åŒä¾èµ–å±‚çº§å†…æŒ‰ä¼˜å…ˆçº§æ’åº
        sorted_tasks.sort_by(|a, b| b.priority.cmp(&a.priority));
        
        Ok(sorted_tasks)
    }
    
    /// æ£€æŸ¥å¾ªç¯ä¾èµ–
    fn check_circular_dependencies(&self, tasks: &[AgentTask]) -> AppResult<()> {
        // æ„å»ºä¾èµ–å›¾
        let mut graph: HashMap<String, Vec<String>> = HashMap::new();
        for task in tasks {
            graph.insert(task.id.clone(), task.dependencies.clone());
        }
        
        // DFSæ£€æµ‹å¾ªç¯
        for task_id in graph.keys() {
            let mut visited = std::collections::HashSet::new();
            if self.has_cycle(&graph, task_id, &mut visited) {
                return Err(AppError::ValidationError(
                    format!("æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–ï¼Œæ¶‰åŠä»»åŠ¡: {}", task_id)
                ));
            }
        }
        
        Ok(())
    }
    
    /// DFSå¾ªç¯æ£€æµ‹
    fn has_cycle(
        &self,
        graph: &HashMap<String, Vec<String>>,
        node: &str,
        visited: &mut std::collections::HashSet<String>,
    ) -> bool {
        if visited.contains(node) {
            return true;
        }
        
        visited.insert(node.to_string());
        
        if let Some(deps) = graph.get(node) {
            for dep in deps {
                if self.has_cycle(graph, dep, visited) {
                    return true;
                }
            }
        }
        
        visited.remove(node);
        false
    }
    
    /// é¡ºåºæ‰§è¡Œä»»åŠ¡
    async fn execute_sequential(
        &self,
        context: &ExecutionContext,
        tasks: Vec<AgentTask>,
    ) -> AppResult<Vec<TaskResult>> {
        let mut results = Vec::new();
        
        for task in tasks {
            let result = self.execute_single_task(context, &task).await;
            results.push(result);
        }
        
        Ok(results)
    }
    
    /// å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
    async fn execute_parallel(
        &self,
        context: &ExecutionContext,
        tasks: Vec<AgentTask>,
    ) -> AppResult<Vec<TaskResult>> {
        let mut handles = Vec::new();
        let (tx, mut rx) = mpsc::unbounded_channel::<TaskResult>();
        
        // å¯åŠ¨æ‰€æœ‰ä»»åŠ¡
        for task in tasks {
            let context_clone = context.clone();
            let tx = tx.clone();
            let self_clone = self.clone();
            
            let handle = tokio::spawn(async move {
                let result = self_clone.execute_single_task(&context_clone, &task).await;
                let _ = tx.send(result);
            });
            
            handles.push(handle);
        }
        
        drop(tx); // å…³é—­å‘é€ç«¯
        
        // æ”¶é›†ç»“æœ
        let mut results = Vec::new();
        while let Some(result) = rx.recv().await {
            results.push(result);
        }
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for handle in handles {
            let _ = handle.await;
        }
        
        // æŒ‰ä»»åŠ¡IDæ’åºç»“æœ
        results.sort_by(|a, b| a.task_id.cmp(&b.task_id));
        
        Ok(results)
    }
    
    /// æ™ºèƒ½æ‰§è¡Œç­–ç•¥
    async fn execute_smart(
        &self,
        context: &ExecutionContext,
        tasks: Vec<AgentTask>,
    ) -> AppResult<Vec<TaskResult>> {
        // åˆ†æä»»åŠ¡ç‰¹å¾å¹¶å†³å®šæ‰§è¡Œç­–ç•¥
        let analysis = self.analyze_tasks(&tasks);
        
        if analysis.has_dependencies {
            // æœ‰ä¾èµ–å…³ç³»æ—¶ä½¿ç”¨åˆ†å±‚å¹¶è¡Œæ‰§è¡Œ
            self.execute_layered_parallel(context, tasks).await
        } else if analysis.total_estimated_time > Duration::from_secs(10) {
            // é¢„è®¡è€—æ—¶è¾ƒé•¿æ—¶ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œ
            self.execute_parallel(context, tasks).await
        } else {
            // ç®€å•ä»»åŠ¡ä½¿ç”¨é¡ºåºæ‰§è¡Œ
            self.execute_sequential(context, tasks).await
        }
    }
    
    /// åˆ†å±‚å¹¶è¡Œæ‰§è¡Œï¼ˆæŒ‰ä¾èµ–å±‚çº§åˆ†ç»„å¹¶è¡Œï¼‰
    async fn execute_layered_parallel(
        &self,
        context: &ExecutionContext,
        tasks: Vec<AgentTask>,
    ) -> AppResult<Vec<TaskResult>> {
        let mut all_results = Vec::new();
        let mut remaining_tasks = tasks;
        
        while !remaining_tasks.is_empty() {
            // æ‰¾å‡ºå½“å‰å¯ä»¥æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆæ— æœªå®Œæˆçš„ä¾èµ–ï¼‰
            let mut ready_tasks = Vec::new();
            let mut i = 0;
            
            while i < remaining_tasks.len() {
                let task = &remaining_tasks[i];
                let dependencies_satisfied = task.dependencies
                    .iter()
                    .all(|dep_id| {
                        all_results.iter().any(|r: &TaskResult| &r.task_id == dep_id && r.success)
                    });
                
                if dependencies_satisfied {
                    ready_tasks.push(remaining_tasks.remove(i));
                } else {
                    i += 1;
                }
            }
            
            if ready_tasks.is_empty() {
                break; // é¿å…æ— é™å¾ªç¯
            }
            
            // å¹¶è¡Œæ‰§è¡Œå½“å‰å±‚çš„ä»»åŠ¡
            let layer_results = self.execute_parallel(context, ready_tasks).await?;
            all_results.extend(layer_results);
        }
        
        Ok(all_results)
    }
    
    /// æ‰§è¡Œå•ä¸ªä»»åŠ¡
    async fn execute_single_task(
        &self,
        _context: &ExecutionContext,
        task: &AgentTask,
    ) -> TaskResult {
        let start_time = Instant::now();
        let mut retry_attempts = 0;
        
        // æ£€æŸ¥ç¼“å­˜
        if self.enable_caching {
            let cache_key = format!("{}:{}", task.agent_type, task.input_text);
            if let Some(cached_result) = self.result_cache.lock().get(&cache_key) {
                return TaskResult {
                    task_id: task.id.clone(),
                    agent_type: task.agent_type.clone(),
                    success: true,
                    output: cached_result.clone(),
                    execution_time: Duration::from_millis(1), // ç¼“å­˜å‘½ä¸­
                    tokens_used: 0,
                    error: None,
                    retry_attempts: 0,
                };
            }
        }
        
        // æ‰§è¡Œä»»åŠ¡ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        while retry_attempts <= task.retry_count {
            // è·å–ä¿¡å·é‡è®¸å¯
            let _permit = self.semaphore.acquire().await.unwrap();
            
            // åˆ›å»ºAIä»£ç†è¯·æ±‚
            let agent_type = match task.agent_type.as_str() {
                "enhance" => AIAgentType::TextEnhancement,
                "translate" => AIAgentType::Translation,
                "summarize" => AIAgentType::Summarization,
                "email" => AIAgentType::Custom,
                "code_comment" => AIAgentType::Custom,
                _ => return TaskResult {
                    task_id: task.id.clone(),
                    agent_type: task.agent_type.clone(),
                    success: false,
                    output: String::new(),
                    execution_time: start_time.elapsed(),
                    tokens_used: 0,
                    error: Some(format!("æœªçŸ¥çš„Agentç±»å‹: {}", task.agent_type)),
                    retry_attempts,
                },
            };
            
            let ai_request = AIAgentRequest {
                text: task.input_text.clone(),
                agent_type,
                options: task.config.clone(),
                context: None,
            };
            
            let result = self.ai_processor.process(ai_request).await
                .map(|response| response.processed_text);
            
            let execution_time = start_time.elapsed();
            
            match result {
                Ok(output) => {
                    // ç¼“å­˜æˆåŠŸç»“æœ
                    if self.enable_caching {
                        let cache_key = format!("{}:{}", task.agent_type, task.input_text);
                        self.result_cache.lock().insert(cache_key, output.clone());
                    }
                    
                    return TaskResult {
                        task_id: task.id.clone(),
                        agent_type: task.agent_type.clone(),
                        success: true,
                        output,
                        execution_time,
                        tokens_used: 100, // ä¼°ç®—å€¼ï¼Œå®é™…åº”ä»APIå“åº”è·å–
                        error: None,
                        retry_attempts,
                    };
                }
                Err(e) => {
                    retry_attempts += 1;
                    if retry_attempts > task.retry_count {
                        return TaskResult {
                            task_id: task.id.clone(),
                            agent_type: task.agent_type.clone(),
                            success: false,
                            output: String::new(),
                            execution_time,
                            tokens_used: 0,
                            error: Some(e.to_string()),
                            retry_attempts,
                        };
                    }
                    
                    // é‡è¯•å‰ç­‰å¾…
                    tokio::time::sleep(Duration::from_millis(1000 * retry_attempts as u64)).await;
                }
            }
        }
        
        // ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
        unreachable!()
    }
    
    /// åˆ†æä»»åŠ¡ç‰¹å¾
    fn analyze_tasks(&self, tasks: &[AgentTask]) -> TaskAnalysis {
        let has_dependencies = tasks.iter().any(|t| !t.dependencies.is_empty());
        let total_estimated_time = Duration::from_secs(tasks.len() as u64 * 3); // æ¯ä»»åŠ¡ä¼°ç®—3ç§’
        let complexity_score = tasks.len() as f64 + 
                              tasks.iter().map(|t| t.dependencies.len()).sum::<usize>() as f64;
        
        TaskAnalysis {
            has_dependencies,
            total_estimated_time,
            complexity_score,
            parallelizable_count: tasks.iter().filter(|t| t.dependencies.is_empty()).count(),
        }
    }
    
    /// æ¸…ç†ç¼“å­˜
    pub fn clear_cache(&self) {
        self.result_cache.lock().clear();
        println!("ğŸ§¹ Agent Pipelineç¼“å­˜å·²æ¸…ç†");
    }
    
    /// è·å–æ€§èƒ½ç»Ÿè®¡
    pub fn get_performance_history(&self) -> Vec<PerformanceStats> {
        self.performance_history.lock().clone()
    }
}

/// ä¸ºæ”¯æŒcloneè€Œå®ç°çš„Clone trait
impl Clone for AgentPipelineManager {
    fn clone(&self) -> Self {
        Self {
            ai_processor: self.ai_processor.clone(),
            semaphore: Arc::new(Semaphore::new(self.max_concurrent_tasks)),
            max_concurrent_tasks: self.max_concurrent_tasks,
            result_cache: self.result_cache.clone(),
            performance_history: self.performance_history.clone(),
            default_timeout: self.default_timeout,
            enable_caching: self.enable_caching,
        }
    }
}

/// ä»»åŠ¡åˆ†æç»“æœ
#[derive(Debug)]
struct TaskAnalysis {
    has_dependencies: bool,
    total_estimated_time: Duration,
    complexity_score: f64,
    parallelizable_count: usize,
}

/// Pipelineæ„å»ºå™¨ï¼ˆä¾¿äºåˆ›å»ºå¤æ‚Pipelineï¼‰
#[derive(Debug)]
pub struct PipelineBuilder {
    tasks: Vec<AgentTask>,
    strategy: PipelineStrategy,
}

impl PipelineBuilder {
    pub fn new() -> Self {
        Self {
            tasks: Vec::new(),
            strategy: PipelineStrategy::Smart,
        }
    }
    
    pub fn add_task(mut self, task: AgentTask) -> Self {
        self.tasks.push(task);
        self
    }
    
    pub fn with_strategy(mut self, strategy: PipelineStrategy) -> Self {
        self.strategy = strategy;
        self
    }
    
    pub fn add_enhancement_task(mut self, text: &str) -> Self {
        self.tasks.push(AgentTask::new("enhance", text));
        self
    }
    
    pub fn add_translation_task(mut self, text: &str, target_lang: &str) -> Self {
        let task = AgentTask::new("translate", text)
            .with_config("target_language", target_lang);
        self.tasks.push(task);
        self
    }
    
    pub fn add_summary_task(mut self, text: &str) -> Self {
        self.tasks.push(AgentTask::new("summarize", text));
        self
    }
    
    pub async fn execute(self, manager: &AgentPipelineManager) -> AppResult<PipelineResult> {
        manager.execute_pipeline(self.tasks, self.strategy).await
    }
}

impl Default for PipelineBuilder {
    fn default() -> Self {
        Self::new()
    }
}