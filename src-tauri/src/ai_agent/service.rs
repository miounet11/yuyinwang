use std::sync::Arc;
use std::collections::HashMap;
use reqwest::Client;
use crate::errors::{AppError, AppResult};
use crate::types::AIPrompt;
use super::types::{
    AIAgentType, AIAgentRequest, AIAgentResponse, 
    ChainProcessingRequest, ChainProcessingResponse, 
    AgentConfig
};
use super::processors::AIProcessor;

#[derive(Debug)]
pub struct AIAgentService {
    processor: Arc<AIProcessor>,
    prompts: Arc<tokio::sync::RwLock<Vec<AIPrompt>>>,
}

impl AIAgentService {
    pub fn new(client: Client, api_key: String, config: AgentConfig) -> Self {
        Self {
            processor: Arc::new(AIProcessor::new(client, api_key, config)),
            prompts: Arc::new(tokio::sync::RwLock::new(Vec::new())),
        }
    }

    /// å¤„ç†å•ä¸ªAIä»£ç†è¯·æ±‚
    pub async fn process_agent_request(&self, request: AIAgentRequest) -> AppResult<AIAgentResponse> {
        println!("ğŸ¤– å¼€å§‹AIä»£ç†å¤„ç†: {:?}", request.agent_type);
        
        // éªŒè¯è¯·æ±‚
        self.validate_request(&request)?;
        
        // å¤„ç†è¯·æ±‚
        let result = self.processor.process(request).await?;
        
        if result.success {
            println!("âœ… AIä»£ç†å¤„ç†æˆåŠŸï¼Œè€—æ—¶: {}ms", result.processing_time_ms);
        } else {
            println!("âŒ AIä»£ç†å¤„ç†å¤±è´¥: {:?}", result.error);
        }
        
        Ok(result)
    }

    /// é“¾å¼å¤„ç†è¯·æ±‚
    pub async fn process_chain(&self, request: ChainProcessingRequest) -> AppResult<ChainProcessingResponse> {
        let total_start = std::time::Instant::now();
        println!("ğŸ”— å¼€å§‹é“¾å¼AIå¤„ç†ï¼Œæ­¥éª¤æ•°: {}", request.chain.len());
        
        let mut results = Vec::new();
        let mut current_text = request.text.clone();
        
        for (index, step) in request.chain.iter().enumerate() {
            println!("ğŸ”— æ‰§è¡Œæ­¥éª¤ {}/{}: {:?}", index + 1, request.chain.len(), step.agent_type);
            
            // æ£€æŸ¥æ¡ä»¶æ‰§è¡Œ
            if let Some(condition) = &step.condition {
                if !self.evaluate_condition(condition, &current_text) {
                    println!("â­ï¸ è·³è¿‡æ­¥éª¤ {} (æ¡ä»¶ä¸æ»¡è¶³): {}", index + 1, condition);
                    continue;
                }
            }
            
            let agent_request = AIAgentRequest {
                text: current_text.clone(),
                agent_type: step.agent_type.clone(),
                options: step.options.clone(),
                context: request.context.clone(),
            };
            
            match self.processor.process(agent_request).await {
                Ok(response) => {
                    if response.success {
                        current_text = response.processed_text.clone();
                        println!("âœ… æ­¥éª¤ {} å®Œæˆï¼Œè€—æ—¶: {}ms", index + 1, response.processing_time_ms);
                    } else {
                        println!("âŒ æ­¥éª¤ {} å¤±è´¥: {:?}", index + 1, response.error);
                        return Ok(ChainProcessingResponse {
                            success: false,
                            original_text: request.text,
                            final_text: current_text,
                            steps: results,
                            total_processing_time_ms: total_start.elapsed().as_millis() as u64,
                            error: response.error,
                        });
                    }
                    results.push(response);
                },
                Err(e) => {
                    println!("âŒ æ­¥éª¤ {} æ‰§è¡Œé”™è¯¯: {}", index + 1, e);
                    return Ok(ChainProcessingResponse {
                        success: false,
                        original_text: request.text,
                        final_text: current_text,
                        steps: results,
                        total_processing_time_ms: total_start.elapsed().as_millis() as u64,
                        error: Some(e.to_string()),
                    });
                }
            }
        }
        
        let total_time = total_start.elapsed().as_millis() as u64;
        println!("âœ… é“¾å¼å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {}ms", total_time);
        
        Ok(ChainProcessingResponse {
            success: true,
            original_text: request.text,
            final_text: current_text,
            steps: results,
            total_processing_time_ms: total_time,
            error: None,
        })
    }

    /// ä½¿ç”¨æç¤ºè¯å¤„ç†æ–‡æœ¬
    pub async fn process_with_prompt(
        &self, 
        text: String, 
        prompt_id: String,
    ) -> AppResult<AIAgentResponse> {
        let prompts = self.prompts.read().await;
        let prompt = prompts.iter()
            .find(|p| p.id == prompt_id)
            .ok_or_else(|| AppError::ValidationError(format!("æç¤ºè¯ä¸å­˜åœ¨: {}", prompt_id)))?;
        
        let mut options = HashMap::new();
        options.insert("system_prompt".to_string(), prompt.prompt_text.clone());
        
        let request = AIAgentRequest {
            text,
            agent_type: self.parse_agent_type(&prompt.agent_type)?,
            options,
            context: None,
        };
        
        self.process_agent_request(request).await
    }

    /// æ·»åŠ æç¤ºè¯
    pub async fn add_prompt(&self, prompt: AIPrompt) -> AppResult<()> {
        let mut prompts = self.prompts.write().await;
        
        // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„æç¤ºè¯
        if prompts.iter().any(|p| p.id == prompt.id) {
            return Err(AppError::ValidationError(format!("æç¤ºè¯IDå·²å­˜åœ¨: {}", prompt.id)));
        }
        
        prompts.push(prompt);
        Ok(())
    }

    /// æ›´æ–°æç¤ºè¯
    pub async fn update_prompt(&self, prompt: AIPrompt) -> AppResult<()> {
        let mut prompts = self.prompts.write().await;
        
        if let Some(existing) = prompts.iter_mut().find(|p| p.id == prompt.id) {
            *existing = prompt;
            Ok(())
        } else {
            Err(AppError::ValidationError(format!("æç¤ºè¯ä¸å­˜åœ¨: {}", prompt.id)))
        }
    }

    /// åˆ é™¤æç¤ºè¯
    pub async fn remove_prompt(&self, prompt_id: &str) -> AppResult<()> {
        let mut prompts = self.prompts.write().await;
        let initial_len = prompts.len();
        prompts.retain(|p| p.id != prompt_id);
        
        if prompts.len() == initial_len {
            Err(AppError::ValidationError(format!("æç¤ºè¯ä¸å­˜åœ¨: {}", prompt_id)))
        } else {
            Ok(())
        }
    }

    /// è·å–æ‰€æœ‰æç¤ºè¯
    pub async fn get_prompts(&self) -> Vec<AIPrompt> {
        self.prompts.read().await.clone()
    }

    /// è·å–æŒ‡å®šç±»å‹çš„æç¤ºè¯
    pub async fn get_prompts_by_type(&self, agent_type: &str) -> Vec<AIPrompt> {
        let prompts = self.prompts.read().await;
        prompts.iter()
            .filter(|p| p.agent_type == agent_type)
            .cloned()
            .collect()
    }

    /// åˆå§‹åŒ–é»˜è®¤æç¤ºè¯
    pub async fn initialize_default_prompts(&self) -> AppResult<()> {
        let default_prompts = self.create_default_prompts();
        let mut prompts = self.prompts.write().await;
        prompts.extend(default_prompts);
        Ok(())
    }

    /// æµ‹è¯•AIæœåŠ¡è¿æ¥
    pub async fn test_connection(&self) -> AppResult<bool> {
        self.processor.test_connection().await
    }

    /// éªŒè¯è¯·æ±‚
    fn validate_request(&self, request: &AIAgentRequest) -> AppResult<()> {
        if request.text.trim().is_empty() {
            return Err(AppError::ValidationError("è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º".to_string()));
        }
        
        if request.text.len() > 10000 {
            return Err(AppError::ValidationError("è¾“å…¥æ–‡æœ¬è¿‡é•¿ï¼Œæœ€å¤§æ”¯æŒ10000å­—ç¬¦".to_string()));
        }
        
        Ok(())
    }

    /// è¯„ä¼°æ¡ä»¶
    fn evaluate_condition(&self, condition: &str, text: &str) -> bool {
        match condition {
            "not_empty" => !text.trim().is_empty(),
            "has_code" => text.contains("```") || text.contains("function") || text.contains("class"),
            "is_long" => text.len() > 500,
            "is_short" => text.len() <= 500,
            _ => true, // é»˜è®¤æ¡ä»¶ä¸ºçœŸ
        }
    }

    /// è§£æä»£ç†ç±»å‹
    fn parse_agent_type(&self, agent_type_str: &str) -> AppResult<AIAgentType> {
        match agent_type_str {
            "text-enhancer" => Ok(AIAgentType::TextEnhancement),
            "translator" => Ok(AIAgentType::Translation),
            "summarizer" => Ok(AIAgentType::Summarization),
            "grammar-check" => Ok(AIAgentType::GrammarCorrection),
            "tone-adjuster" => Ok(AIAgentType::ToneAdjustment),
            "keyword-extractor" => Ok(AIAgentType::KeywordExtraction),
            "code-explainer" => Ok(AIAgentType::CodeExplanation),
            "speech-to-text" => Ok(AIAgentType::SpeechToText),
            "auto-input" => Ok(AIAgentType::AutoInput),
            "formatter" => Ok(AIAgentType::Formatter),
            "custom" => Ok(AIAgentType::Custom),
            _ => Err(AppError::ValidationError(format!("ä¸æ”¯æŒçš„ä»£ç†ç±»å‹: {}", agent_type_str))),
        }
    }

    /// åˆ›å»ºé»˜è®¤æç¤ºè¯
    fn create_default_prompts(&self) -> Vec<AIPrompt> {
        use uuid::Uuid;
        use std::time::{SystemTime, UNIX_EPOCH};
        
        let timestamp = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
        
        vec![
            AIPrompt {
                id: Uuid::new_v4().to_string(),
                name: "æ–‡æœ¬å¢å¼º".to_string(),
                description: "ä¼˜åŒ–å’Œå¢å¼ºæ–‡æœ¬å†…å®¹ï¼Œä½¿å…¶æ›´æ¸…æ™°å‡†ç¡®".to_string(),
                agent_type: "text-enhancer".to_string(),
                prompt_text: "è¯·ä¼˜åŒ–ä»¥ä¸‹æ–‡æœ¬ï¼Œä½¿å…¶æ›´æ¸…æ™°ã€å‡†ç¡®å’Œä¸“ä¸šï¼š".to_string(),
                is_active: true,
                created_at: timestamp,
                updated_at: timestamp,
            },
            AIPrompt {
                id: Uuid::new_v4().to_string(),
                name: "ç¿»è¯‘".to_string(),
                description: "å°†æ–‡æœ¬ç¿»è¯‘ä¸ºç›®æ ‡è¯­è¨€".to_string(),
                agent_type: "translator".to_string(),
                prompt_text: "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘ä¸ºæŒ‡å®šçš„ç›®æ ‡è¯­è¨€ï¼Œä¿æŒåŸæ„å’Œè¯­è°ƒï¼š".to_string(),
                is_active: true,
                created_at: timestamp,
                updated_at: timestamp,
            },
            AIPrompt {
                id: Uuid::new_v4().to_string(),
                name: "æ‘˜è¦".to_string(),
                description: "ç”Ÿæˆå†…å®¹çš„ç®€æ´æ‘˜è¦".to_string(),
                agent_type: "summarizer".to_string(),
                prompt_text: "è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆç®€æ´æ˜äº†çš„æ‘˜è¦ï¼Œçªå‡ºè¦ç‚¹ï¼š".to_string(),
                is_active: true,
                created_at: timestamp,
                updated_at: timestamp,
            },
        ]
    }
}